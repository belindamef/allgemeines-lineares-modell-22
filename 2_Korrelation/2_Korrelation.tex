% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
  8pt,
  ignorenonframetext,
]{beamer}
\usepackage{pgfpages}
\setbeamertemplate{caption}[numbered]
\setbeamertemplate{caption label separator}{: }
\setbeamercolor{caption name}{fg=normal text.fg}
\beamertemplatenavigationsymbolsempty
% Prevent slide breaks in the middle of a paragraph
\widowpenalties 1 10000
\raggedbottom
\setbeamertemplate{part page}{
  \centering
  \begin{beamercolorbox}[sep=16pt,center]{part title}
    \usebeamerfont{part title}\insertpart\par
  \end{beamercolorbox}
}
\setbeamertemplate{section page}{
  \centering
  \begin{beamercolorbox}[sep=12pt,center]{part title}
    \usebeamerfont{section title}\insertsection\par
  \end{beamercolorbox}
}
\setbeamertemplate{subsection page}{
  \centering
  \begin{beamercolorbox}[sep=8pt,center]{part title}
    \usebeamerfont{subsection title}\insertsubsection\par
  \end{beamercolorbox}
}
\AtBeginPart{
  \frame{\partpage}
}
\AtBeginSection{
  \ifbibliography
  \else
    \frame{\sectionpage}
  \fi
}
\AtBeginSubsection{
  \frame{\subsectionpage}
}
\usepackage{amsmath,amssymb}
\usepackage{lmodern}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\newif\ifbibliography
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
\usepackage{caption}
% Make caption package work with longtable
\makeatletter
\def\fnum@table{\tablename~\thetable}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
% type setting
% ------------------------------------------------------------------------------
\usepackage[german]{babel}     

% fonts
% ------------------------------------------------------------------------------
\usefonttheme{professionalfonts}

% slide title and horizontal line
% ------------------------------------------------------------------------------
\setbeamertemplate{frametitle}{%
    \vskip-30pt \color{black}\large%
    \begin{minipage}[b][23pt]{120mm}%
    \flushleft\insertframetitle%
    \end{minipage}%
}

\setbeamertemplate{headline}										
{
\vskip10pt\hfill\hspace{3.5mm} 										 
\vskip15pt\color{black}\rule{\textwidth}{0.4pt} 					 
}

% slide number
% ---------------------------------------------------------------
\setbeamertemplate{navigation symbols}{}
\setbeamertemplate{footline}
{
\vskip5pt
\vskip2pt
\makebox[123mm]{\hspace{7.5mm}
\hfill Allgemeines Lineares Modell $\vert$ 
\copyright $ $ 2022 Dirk Ostwald CC BY-NC-SA 4.0 $\vert$ 
Folie \insertframenumber}
\vskip4pt
}

% block color scheme
% ------------------------------------------------------------------------------
% colors
\definecolor{white}{RGB}{255,255,255}
\definecolor{grey}{RGB}{235,235,235}
\definecolor{lightgrey}{RGB}{245,245,245}
\definecolor{LightBlue}{RGB}{220,220,255}
\definecolor{darkblue}{RGB}{51, 51, 153}

% definitions and theorems
\setbeamercolor{block title}{fg = black, bg = grey}
\setbeamercolor{block body}{fg = black, bg = lightgrey}

% general line spacing 
% ------------------------------------------------------------------------------
\linespread{1.3}

% local line spacing
% ------------------------------------------------------------------------------
\usepackage{setspace}

% colors
% -----------------------------------------------------------------------------
\usepackage{color}

% justified text
% ------------------------------------------------------------------------------
\usepackage{ragged2e}
\usepackage{etoolbox}
\apptocmd{\frame}{}{\justifying}{}

% bullet point lists
% -----------------------------------------------------------------------------
\setbeamertemplate{itemize item}[circle]
\setbeamertemplate{itemize subitem}[circle]
\setbeamertemplate{itemize subsubitem}[circle]
\setbeamercolor{itemize item}{fg = black}
\setbeamercolor{itemize subitem}{fg = black}
\setbeamercolor{itemize subsubitem}{fg = black}
\setbeamercolor{enumerate item}{fg = black}
\setbeamercolor{enumerate subitem}{fg = black}
\setbeamercolor{enumerate subsubitem}{fg = black}
\setbeamerfont{itemize/enumerate body}{}
\setbeamerfont{itemize/enumerate subbody}{size = \normalsize}
\setbeamerfont{itemize/enumerate subsubbody}{size = \normalsize}

% color links
% ------------------------------------------------------------------------------
\usepackage{hyperref}
\definecolor{urls}{RGB}{204,0,0}
\hypersetup{colorlinks, citecolor = darkblue, urlcolor = urls}


% additional math commands
% ------------------------------------------------------------------------------
\usepackage{bm}                                         
\newcommand{\niton}{\not\owns}
\DeclareMathOperator*{\intinf}{\int_{-\infty}^{\infty}}


% text highlighting
% ------------------------------------------------------------------------------
\usepackage{soul}
\makeatletter
\let\HL\hl
\renewcommand\hl{%
  \let\set@color\beamerorig@set@color
  \let\reset@color\beamerorig@reset@color
  \HL}
\makeatother

% equation highlighting
% -----------------------------------------------------------------------------
\newcommand{\highlight}[2][yellow]{\mathchoice%
  {\colorbox{#1}{$\displaystyle#2$}}%
  {\colorbox{#1}{$\textstyle#2$}}%
  {\colorbox{#1}{$\scriptstyle#2$}}%
  {\colorbox{#1}{$\scriptscriptstyle#2$}}}%

% additional mathematical operators
% ------------------------------------------------------------------------------
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}

\ifluatex
  \usepackage{selnolig}  % disable illegal ligatures
\fi

\author{}
\date{\vspace{-2.5em}}

\begin{document}

\begin{frame}[plain]{}
\protect\hypertarget{section}{}
\center

\begin{center}\includegraphics[width=0.2\linewidth]{2_Abbildungen/alm_2_otto} \end{center}

\vspace{2mm}

\huge

Allgemeines Lineares Modell \vspace{6mm}

\large

BSc Psychologie SoSe 2022

\vspace{6mm}
\normalsize

Prof.~Dr.~Dirk Ostwald
\end{frame}

\begin{frame}[plain]{}
\protect\hypertarget{section-1}{}
\center
\huge
\vfill

\noindent (2) Korrelation \vfill
\end{frame}

\begin{frame}{}
\protect\hypertarget{section-2}{}
\setstretch{2.2}
\vfill
\large

Grundlagen

Korrelation und Bestimmtheitsmaß

Korrelation und lineare Abhängigkeit

Korrelation und Regression

Partielle Korrelation

Selbstkontrollfragen

\vfill
\end{frame}

\begin{frame}{}
\protect\hypertarget{section-3}{}
\setstretch{2.2}
\vfill
\large

\textbf{Grundlagen}

Korrelation und Bestimmtheitsmaß

Korrelation und lineare Abhängigkeit

Korrelation und Regression

Partielle Korrelation

Selbstkontrollfragen

\vfill
\end{frame}

\begin{frame}{Grundlagen}
\protect\hypertarget{grundlagen}{}
\large

Anwendungsszenario \vspace{2mm}

\begin{center}\includegraphics[width=0.8\linewidth]{2_Abbildungen/alm_2_beispielszenario} \end{center}
\end{frame}

\begin{frame}{Grundlagen}
\protect\hypertarget{grundlagen-1}{}
Beispieldatensatz

\center
\footnotesize

\(i = 1,...,20\) Patient:innen, \(y_i\) Symptomreduktion bei Patient:in
\(i\), \(x_i\) Anzahl Therapiestunden von Patient:in \(i\)

\setstretch{1}

\begin{longtable}[]{@{}rr@{}}
\toprule
y\_i & x\_i \\
\midrule
\endhead
-3.15 & 1 \\
2.52 & 2 \\
-1.18 & 3 \\
3.06 & 4 \\
1.70 & 5 \\
2.91 & 6 \\
3.92 & 7 \\
2.31 & 8 \\
4.63 & 9 \\
10.91 & 10 \\
17.56 & 11 \\
11.52 & 12 \\
12.31 & 13 \\
12.12 & 14 \\
12.13 & 15 \\
20.37 & 16 \\
25.26 & 17 \\
27.75 & 18 \\
24.93 & 19 \\
32.49 & 20 \\
\bottomrule
\end{longtable}
\end{frame}

\begin{frame}{Grundlagen}
\protect\hypertarget{grundlagen-2}{}
Beispieldatensatz

\begin{center}\includegraphics[width=0.55\linewidth]{2_Abbildungen/alm_2_beispieldatensatz} \end{center}

\center

\textcolor{darkblue}{Wie stark hängen Anzahl Therapiestunden und Symptomreduktion zusammen?}
\end{frame}

\begin{frame}{Grundlagen}
\protect\hypertarget{grundlagen-3}{}
\small
\begin{definition}[Korrelation]
\justifying
Die \textit{Korrelation} zweier Zufallsvariablen $X$ und $Y$ ist definiert als
\begin{equation}
\rho(X,Y) := \frac{\mathbb{C}(X,Y)}{\mathbb{S}(X)\mathbb{S}(Y)}
\end{equation}
wobei $\mathbb{C}(X,Y)$ die Kovarianz von $X$ und $Y$ und $\mathbb{V}(X)$ und
$\mathbb{V}(Y)$ die Varianzen von $X$ und $Y$, respektive, bezeichnen.
\end{definition}

\footnotesize

Bemerkungen

\begin{itemize}
\tightlist
\item
  \(\rho(X,Y)\) wird auch \textit{Korrelationskoeffizient} von \(X\) und
  \(Y\) genannt.
\item
  Wir haben bereits gesehen, dass \(-1 \le \rho(X,Y) \le 1\) gilt.
\item
  Wenn \(\rho(X,Y) = 0\) ist, werden \(X\) und \(Y\)
  \textit{unkorreliert} genannt.
\item
  Wir haben bereits gesehen, dass aus der Unabhängigkeit von \(X\) und
  \(Y\), folgt dass \(\rho(X,Y) = 0\).
\item
  Aus \(\rho(X,Y) = 0\) folgt aber wie bereits gesehen die
  Unabhängigkeit von \(X\) und \(Y\) im Allgemeinen nicht.
\end{itemize}
\end{frame}

\begin{frame}{Grundlagen}
\protect\hypertarget{grundlagen-4}{}
\footnotesize
\begin{definition}[Stichprobenkorrelation]
\justifying
$\{(x_1,y_1),...,(x_n,y_n)\} \subset \mathbb{R}$ sei eine Wertemenge. Weiterhin seien:
\begin{itemize}
\item Die Stichprobenmittel der $x_i$ und $y_i$ definiert als
\begin{equation}
\bar{x} := \frac{1}{n}\sum_{i=1}^n x_i
\mbox{ und }
\bar{y} := \frac{1}{n}\sum_{i=1}^n y_i.
\end{equation}
\item Die Stichprobenstandardabweichungen $x_i$ und $y_i$ definiert als
\begin{equation}
s_x := \sqrt{\frac{1}{n-1}(x_i - \bar{x})^2}
\mbox{ und }
s_y := \sqrt{\frac{1}{n-1}(y_i - \bar{y})^2}.
\end{equation}
\item Die Stichprobenkovarianz der $(x_1,y_1),...,(x_n,y_n)$ definiert als
\begin{equation}
c_{xy} := \frac{1}{n-1}\sum_{i=1}^n (x_i - \bar{x}_n)(y_i - \bar{y}_n).
\end{equation}
\end{itemize}
Dann ist die \textit{Stichprobenkorrelation} der $(x_1,y_1),...,(x_n,y_n)$ definiert als
\begin{equation}
r_{xy} := \frac{c_{xy}}{s_xs_y}
\end{equation}
und  wird auch \textit{Stichprobenkorrelationskoeffizient} genannt.
\end{definition}
\end{frame}

\begin{frame}[fragile]{Grundlagen}
\protect\hypertarget{grundlagen-5}{}
Beispiel \vspace{2mm} \tiny \setstretch{1.2}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Laden des Beispieldatensatzes}
\NormalTok{fname }\OtherTok{=} \FunctionTok{file.path}\NormalTok{(}\FunctionTok{getwd}\NormalTok{(), }\StringTok{"2\_Daten"}\NormalTok{, }\StringTok{"2\_Korrelation\_Beispieldatensatz.csv"}\NormalTok{)     }\CommentTok{\# Dateipfad}
\NormalTok{D     }\OtherTok{=} \FunctionTok{read.table}\NormalTok{(fname, }\AttributeTok{sep =} \StringTok{","}\NormalTok{, }\AttributeTok{header =} \ConstantTok{TRUE}\NormalTok{)                              }\CommentTok{\# Laden als Dataframe}
\NormalTok{x\_i   }\OtherTok{=}\NormalTok{ D}\SpecialCharTok{$}\NormalTok{x\_i                                                                    }\CommentTok{\# x\_i Werte }
\NormalTok{y\_i   }\OtherTok{=}\NormalTok{ D}\SpecialCharTok{$}\NormalTok{y\_i                                                                    }\CommentTok{\# y\_i Werte}
\NormalTok{n     }\OtherTok{=} \FunctionTok{length}\NormalTok{(x\_i)                                                              }\CommentTok{\# n}

\CommentTok{\# "Manuelle" Berechnung der Stichprobenkorrelation}
\NormalTok{x\_bar }\OtherTok{=}\NormalTok{ (}\DecValTok{1}\SpecialCharTok{/}\NormalTok{n)}\SpecialCharTok{*}\FunctionTok{sum}\NormalTok{(x\_i)                                                           }\CommentTok{\# \textbackslash{}bar\{x\}}
\NormalTok{y\_bar }\OtherTok{=}\NormalTok{ (}\DecValTok{1}\SpecialCharTok{/}\NormalTok{n)}\SpecialCharTok{*}\FunctionTok{sum}\NormalTok{(y\_i)                                                           }\CommentTok{\# \textbackslash{}bar\{y\}}
\NormalTok{s\_x   }\OtherTok{=} \FunctionTok{sqrt}\NormalTok{(}\DecValTok{1}\SpecialCharTok{/}\NormalTok{(n}\DecValTok{{-}1}\NormalTok{)}\SpecialCharTok{*}\FunctionTok{sum}\NormalTok{((x\_i }\SpecialCharTok{{-}}\NormalTok{ x\_bar)}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{))                                       }\CommentTok{\# s\_x}
\NormalTok{s\_y   }\OtherTok{=} \FunctionTok{sqrt}\NormalTok{(}\DecValTok{1}\SpecialCharTok{/}\NormalTok{(n}\DecValTok{{-}1}\NormalTok{)}\SpecialCharTok{*}\FunctionTok{sum}\NormalTok{((y\_i }\SpecialCharTok{{-}}\NormalTok{ y\_bar)}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{))                                       }\CommentTok{\# s\_y }
\NormalTok{c\_xy  }\OtherTok{=} \DecValTok{1}\SpecialCharTok{/}\NormalTok{(n}\DecValTok{{-}1}\NormalTok{) }\SpecialCharTok{*} \FunctionTok{sum}\NormalTok{((x\_i }\SpecialCharTok{{-}}\NormalTok{ x\_bar) }\SpecialCharTok{*}\NormalTok{ (y\_i }\SpecialCharTok{{-}}\NormalTok{ y\_bar))                             }\CommentTok{\# c\_\{xy\}}
\NormalTok{r\_xy  }\OtherTok{=}\NormalTok{ c\_xy}\SpecialCharTok{/}\NormalTok{(s\_x }\SpecialCharTok{*}\NormalTok{ s\_y)                                                         }\CommentTok{\# r\_\{xy\}}
\FunctionTok{print}\NormalTok{(r\_xy)                                                                      }\CommentTok{\# Ausgabe}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
> [1] 0.938
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Automatische Berechnung mit cor()}
\NormalTok{r\_xy  }\OtherTok{=} \FunctionTok{cor}\NormalTok{(x\_i,y\_i)                                                             }\CommentTok{\# r\_\{xy\}}
\FunctionTok{print}\NormalTok{(r\_xy)                                                                      }\CommentTok{\# Ausgabe}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
> [1] 0.938
\end{verbatim}

\center

\(\Rightarrow\) Anzahl Therapiestunden und Symptomreduktion sind
hochkorreliert.
\end{frame}

\begin{frame}{Grundlagen}
\protect\hypertarget{grundlagen-6}{}
Mechanik der Kovariationsterme

\begin{center}\includegraphics[width=0.8\linewidth]{2_Abbildungen/alm_2_korrelationsterme} \end{center}

\center
\footnotesize

Häufige richtungsgleiche Abweichung der \(x_i\) und \(y_i\) von ihren
Mittelwerten \(\Rightarrow\) Positive Korrelation

Häufige richtungsungleiche Abweichung der \(x_i\) und \(y_i\) von ihren
Mittelwerten \(\Rightarrow\) Negative Korrelation

Keine häufigen richtungsgleichen oder -entgegengesetzten Abweichungen
\(\Rightarrow\) Keine Korrelation
\end{frame}

\begin{frame}{Grundlagen}
\protect\hypertarget{grundlagen-7}{}
\vspace{2mm}

Beispiele

\begin{center}\includegraphics[width=0.6\linewidth]{2_Abbildungen/alm_2_korrelationsbeispiele} \end{center}
\end{frame}

\begin{frame}{Grundlagen}
\protect\hypertarget{grundlagen-8}{}
\footnotesize
\begin{theorem}[Stichprobenkorrelation bei linear-affinen Transformationen]
\justifying
\normalfont
Für eine Wertemenge $\{(x_i,y_i)\}_{i = 1,...n} \subset \mathbb{R}^2$ sei
$\{(\tilde{x}_i,\tilde{y}_i)\}_{i = 1,...n} \subset \mathbb{R}^2$ eine linear-affin
transformierte Wertemenge mit
\begin{equation}
(\tilde{x}_i, \tilde{y}_i) = (a_x x_i + b_x, a_y y_i + b_y), a_x,a_y \neq 0.
\end{equation}
Dann gilt
\begin{equation}
|r_{\tilde{x}\tilde{y}}| = |r_{xy}|.
\end{equation}
\end{theorem}

Bemerkungen

\begin{itemize}
\tightlist
\item
  Der Betrag der Stichprobenkorrelation ändert sich bei linear-affiner
  Datentransformation nicht.
\item
  Man sagt, dass die Stichprobenkorrelation im Gegensatz zur
  Stichprobenkovarianz \textit{maßstabsunabhängig} ist.
\end{itemize}
\end{frame}

\begin{frame}{Grundlagen}
\protect\hypertarget{grundlagen-9}{}
\footnotesize
\vspace{1mm}

\underline{Beweis}

Es gilt \tiny \begin{align}
\begin{split}
r_{\tilde{x}\tilde{y}} 
& := \frac{\frac{1}{n-1}\sum_{i=1}^n (\tilde{x}_i - \bar{\tilde{x}})(\tilde{y}_i - \bar{\tilde{y}})}
        {\sqrt{\frac{1}{n-1}(\sum_{i=1}^n\tilde{x}_i - \bar{\tilde{x}})^2} \sqrt{\frac{1}{n-1}(\sum_{i=1}^n\tilde{y}_i - \bar{\tilde{y}})^2}}
\\
&  = \frac{\sum_{i=1}^n (a_x x_i + b_x - (a_x\bar{x} + b_x))(a_y y_i + b_y - (a_y \bar{y} + b_y))}
          {\sqrt{\sum_{i=1}^n (a_x x_i + b_x - (a_x \bar{x} + b_x))^2}\sqrt{\sum_{i=1}^n (a_y y_i + b_y - (a_y \bar{y} + b_y))^2}}
\\
&  = \frac{a_x a_y\sum_{i=1}^n (x_i-\bar{x})(y_i-\bar{y})}
          {\sqrt{a_x^2\sum_{i=1}^n (x_i  - \bar{x})^2}\sqrt{a_y^2\sum_{i=1}^n (y_i - \bar{y})^2}}
\\
&  = \frac{a_x a_y}{|a_x||a_y|}
     \frac{\sum_{i=1}^n (x_i-\bar{x})(y_i-\bar{y})}
          {\sqrt{\sum_{i=1}^n (x_i  - \bar{x})^2}\sqrt{\sum_{i=1}^n (y_i - \bar{y})^2}}
\\
&  = \frac{a_x a_y}{|a_x||a_y|}\frac{c_{xy}}{s_x s_y}
\\
&  = \frac{a_x a_y}{|a_x||a_y|}r_{xy}.
\end{split}
\end{align} \footnotesize Also folgt, durch Durchspielen aller möglichen
Vorzeichenfälle, dass \begin{equation}
|r_{\tilde{x}\tilde{y}}| = |r_{xy}|.
\end{equation} \(\hfill\Box\)
\end{frame}

\begin{frame}{}
\protect\hypertarget{section-4}{}
\setstretch{2.2}
\vfill
\large

Grundlagen

\textbf{Korrelation und Bestimmtheitsmaß}

Korrelation und lineare Abhängigkeit

Korrelation und Regression

Partielle Korrelation

Selbstkontrollfragen

\vfill
\end{frame}

\begin{frame}{Korrelation und Bestimmtheitsmaß}
\protect\hypertarget{korrelation-und-bestimmtheitsmauxdf}{}
Überblick \setstretch{2} \footnotesize

Das sogenannte Bestimmtheitsmaß \(\mbox{R}^2\) ist eine beliebte
Statistik.

Numerisch ist \(\mbox{R}^2\) das Quadrat des
Stichprobenkorrelationskoeffizienten.

Ist die Stichprobenkorrelation \(r_{xy} = 0.5\), dann ist
\(\mbox{R}^2 = 0.25\), ist \(r_{xy} = -0.5\), dann ist
\(\mbox{R}^2 = 0.25\).

\(\Rightarrow \mbox{R}^2\) enthält also weniger Information über die
Rohdaten als \(r_{xy}\), da das Vorzeichen wegfällt.

\(\Rightarrow\) \textit{Perse} ist die Angabe von \(\mbox{R}^2\)
anstelle von \(r_{xy}\) im Kontext der Korrelation zweier Variablen
wenig sinnvoll.

Ein tieferes Verständnis von \(\mbox{R}^2\) erlaubt jedoch

\begin{enumerate}
[(1)]
\tightlist
\item
  Einen Einstieg in das Konzept von Quadratsummenzerlegungen, einem
  wichtigen ALM Evaluationsprinzip.
\item
  Einen Einstieg in das Verständnis der Zusammenhänge von
  Ausgleichsgerade und Stichprobenkorrelation.
\item
  Einen ersten Einblick in die Tatsache, dass Korrelationen (nur)
  linear-affine Zusammenhänge quantifizieren.
\end{enumerate}
\end{frame}

\begin{frame}{Korrelation und Bestimmtheitsmaß}
\protect\hypertarget{korrelation-und-bestimmtheitsmauxdf-1}{}
\small
\begin{definition}[Erklärte Werte und Residuen einer Ausgleichsgerade]
\justifying
Gegeben seien eine Wertemenge $\{(x_1,y_1), ..., (x_n,y_n)\} \subset \mathbb{R}^2$
und die zu dieser Wertemenge gehörende Ausgleichsgerade
\begin{equation}
f_{\hat{\beta}} : \mathbb{R} \to \mathbb{R}, x \mapsto f_{\hat{\beta}}(x) := \hat{\beta}_0 + \hat{\beta}_1x
\end{equation}
Dann werden für $i = 1,...,n$
\begin{equation}
\hat{y}_i := \hat{\beta}_0 + \hat{\beta}_1x_i
\end{equation}
die durch die Ausgleichsgerade \textit{erklärten Werte} genannt und
\begin{equation}
\hat{\varepsilon}_i := y_i - \hat{y}_i
\end{equation}
die \textit{Residuen} der Ausgleichsgerade genannt.
\end{definition}
\end{frame}

\begin{frame}{Korrelation und Bestimmtheitsmaß}
\protect\hypertarget{korrelation-und-bestimmtheitsmauxdf-2}{}
Erklärte Werte und Residuen

\begin{center}\includegraphics[width=0.55\linewidth]{2_Abbildungen/alm_2_erklaertewerte_residuen} \end{center}

\vspace{-5mm}
\center

\(\bullet \, (x_i, y_i)\) \hspace{2mm} \textcolor{blue}{$\bullet$}
\((\bar{x},\bar{y})\) \hspace{2mm} \textbf{---} \(f_{\hat{\beta}}(x)\)
\hspace{2mm} \textcolor{lightgray}{$\bullet$} \(\hat{y}_i\) \hspace{2mm}
\textcolor{lightgray}{\textbf{---}} \(\hat{\varepsilon}_i\) \hspace{2mm}
\(i = 1,...,n\)
\end{frame}

\begin{frame}{Korrelation und Bestimmtheitsmaß}
\protect\hypertarget{korrelation-und-bestimmtheitsmauxdf-3}{}
\small
\begin{theorem}[Quadratsummenzerlegung bei Ausgleichsgerade]
\justifying
\normalfont
Für eine Wertemenge $\{(x_1,y_1), ..., (x_n,y_n)\} \subset \mathbb{R}^2$ und ihre
zugehörige Ausgleichsgerade $f_{\hat{\beta}}$ seien für
\begin{equation}
\bar{y} := \frac{1}{n}\sum_{i=1}^n y_i \mbox{ und }
\hat{y}_i := \hat{\beta}_0 + \hat{\beta}_1x_i, \mbox{ für } i= 1,...,n
\end{equation}
das Stichprobenmittel der $y$-Werte und die durch die Ausgleichsgerade erklärten Werte,
respektive. Weiterhin seien

\center
\vspace{1mm}
\begin{tabular}{ll}
$\mbox{SQT} := \sum_{i = 1}^n (y_i - \bar{y})^2$          & die \textit{Total Sum of Squares}      \\\\
$\mbox{SQE} := \sum_{i = 1}^n (\hat{y}_i - \bar{y})^2$    & die \textit{Explained Sum of Squares}  \\\\
$\mbox{SQR} := \sum_{i = 1}^n (y_i - \hat{y}_i)^2$        & die \textit{Residual Sum of Squares}   \\
\end{tabular}
\vspace{1mm}
\flushleft
Dann gilt
\begin{equation}
\mbox{SQT} = \mbox{SQE} + \mbox{SQR}
\end{equation}
\end{theorem}
\end{frame}

\begin{frame}{Korrelation und Bestimmtheitsmaß}
\protect\hypertarget{korrelation-und-bestimmtheitsmauxdf-4}{}
\footnotesize
\setstretch{1.4}

Bemerkungen

\begin{itemize}
\item SQT repräsentiert die Gesamtstreung der $y_i$-Werte um ihren Mittelwert $\bar{y}$.
\item SQE repräsentiert die Streuung der erklärten Werte $\hat{y}_i$ um ihren Mittelwert
\item[] $\Rightarrow$ Große Werte von SQE repräsentieren eine große absolute Steigung der $y_i$ mit den $x_i$
\item[] $\Rightarrow$ Kleine Werte von SQE repräsentieren eine kleine absolute Steigung der $y_i$ mit den $x_i$
\item SQE ist also ein Maß für die Stärke des linearen Zusammenhangs der $x$- und $y$-Werte
\item SQR ist die Summe der quadrierten Residuen, es gilt
\begin{equation}
\mbox{SQR} := \sum_{i = 1}^n (y_i - \hat{y}_i)^2 := \sum_{i=1}^n \hat{\varepsilon}_i^2
\end{equation}
\item[] $\Rightarrow$ Große Werte von SQR repräsentieren große Abweichungen der erklärten von den beobachteten $y$-Werten
\item[] $\Rightarrow$ Kleine Werte von SQR repräsentieren geringe Abweichungen der erklärten von den beobachteten $y$-Werten
\item SQR ist also ein Maß für die Güte der Beschreibung der Datenmenge durch die Ausgleichsgerade.
\end{itemize}
\end{frame}

\begin{frame}{Korrelation und Bestimmtheitsmaß}
\protect\hypertarget{korrelation-und-bestimmtheitsmauxdf-5}{}
\vspace{2mm}
\footnotesize
\setstretch{1}

\underline{Beweis} \begin{align}
\begin{split}
\mbox{SQT}
& = \sum_{i=1}^n (y_i - \bar{y})^2 \\
& = \sum_{i=1}^n (y_i - \hat{y}_i  + \hat{y}_i - \bar{y})^2 \\
& = \sum_{i=1}^n ((y_i - \hat{y}_i)  + (\hat{y}_i - \bar{y}))^2 \\
& = \sum_{i=1}^n \left((y_i - \hat{y}_i)^2  + 2(y_i - \hat{y}_i)(\hat{y}_i - \bar{y}) + (\hat{y}_i - \bar{y})^2\right) \\
& = \sum_{i=1}^n(\hat{y}_i - \bar{y})^2  + 2\sum_{i=1}^n(y_i - \hat{y}_i)(\hat{y}_i - \bar{y})  + \sum_{i=1}^n (y_i - \hat{y}_i)^2\\
& = \mbox{SQE}  + 2\sum_{i=1}^n(y_i - \hat{y}_i)(\hat{y}_i - \bar{y})  + \mbox{SQR} \\
& = \mbox{SQE} + \mbox{SQR}
\end{split}
\end{align}
\end{frame}

\begin{frame}{Korrelation und Bestimmtheitsmaß}
\protect\hypertarget{korrelation-und-bestimmtheitsmauxdf-6}{}
\footnotesize

\underline{Beweis (fortgeführt)}

Dabei ergibt sich die letzte Gleichung mit \begin{equation}
\bar{\hat{y}}
:= \frac{1}{n}\sum_{i=1}^n \hat{y}_i
= \frac{1}{n}\sum_{i=1}^n(\hat{\beta}_0 + \hat{\beta}_1x_i)
= \hat{\beta}_0 + \hat{\beta}_1\bar{x}
= \bar{y} - \hat{\beta}_1\bar{x} + \hat{\beta}_1\bar{x}
= \bar{y}
\end{equation} und damit auch \begin{equation}
\bar{\hat{y}} = \bar{y}
\Leftrightarrow
\frac{1}{n}\sum_{i=1}^n\hat{y}_i = \frac{1}{n}\sum_{i=1}^n y_i
\Leftrightarrow
\sum_{i=1}^n\hat{y}_i = \sum_{i=1}^n y_i
\Leftrightarrow
\bar{y}\sum_{i=1}^n\hat{y}_i = \bar{y}\sum_{i=1}^n y_i
\end{equation} sowie \begin{equation}
\bar{\hat{y}} = \bar{y}
\Leftrightarrow
\frac{1}{n}\sum_{i=1}^n\hat{y}_i = \frac{1}{n}\sum_{i=1}^n y_i
\Leftrightarrow
\sum_{i=1}^n y_i = \sum_{i=1}^n\hat{y}_i
\Leftrightarrow
\sum_{i=1}^n y_i \hat{y}_i = \sum_{i=1}^n\hat{y}_i\hat{y}_i
\end{equation} aus
\end{frame}

\begin{frame}{Korrelation und Bestimmtheitsmaß}
\protect\hypertarget{korrelation-und-bestimmtheitsmauxdf-7}{}
\footnotesize

\underline{Beweis (fortgeführt)} \begin{align}
\begin{split}
\sum_{i=1}^n(y_i - \hat{y}_i)(\hat{y}_i - \bar{y})
& = \sum_{i=1}^n (y_i\hat{y}_i - y_i\bar{y} - \hat{y}_i\hat{y}_i + \hat{y}_i\bar{y}) \\
& = \sum_{i=1}^n y_i\hat{y}_i - \sum_{i=1}^n y_i\bar{y} - \sum_{i=1}^n \hat{y}_i\hat{y}_i + \sum_{i=1}^n \hat{y}_i\bar{y} \\
& = \sum_{i=1}^n y_i\hat{y}_i - \sum_{i=1}^n \hat{y}_i\hat{y}_i + \bar{y}\sum_{i=1}^n \hat{y}_i - \bar{y}\sum_{i=1}^n y_i \\
& = 0 + 0 \\
& = 0
\end{split}
\end{align} \(\hfill\Box\)
\end{frame}

\begin{frame}{Korrelation und Bestimmtheitsmaß}
\protect\hypertarget{korrelation-und-bestimmtheitsmauxdf-8}{}
\footnotesize
\begin{definition}[Bestimmtheitsmaß $\mbox{R}^2$]
\justifying
Für eine Wertemenge $\{(x_1,y_1), ..., (x_n,y_n)\} \subset \mathbb{R}^2$ und ihre
zugehörige Ausgleichsgerade $f_{\hat{\beta}}$ sowie die zugehörigen Explained Sum of Squares $\mbox{SQE}$
und Total Sum of Squares $\mbox{SQT}$ heißt
\begin{equation}
\mbox{R}^2 := \frac{\mbox{SQE}}{\mbox{SQT}}
\end{equation}
\textit{Bestimmtheitsmaß} oder \textit{Determinationskoeffizient}.
\end{definition}

\begin{theorem}[Stichprobenkorrelation und Bestimmtheitsmaß]
\justifying
\normalfont
Für eine Wertemenge $\{(x_1,y_1), ..., (x_n,y_n)\} \subset \mathbb{R}^2$ sei
$\mbox{R}^2$ das Bestimmtheitsmaß und $r_{xy}$ sei die Stichprobenkorrelation.
Dann gilt
\begin{equation}
\mbox{R}^2 = r_{xy}^2.
\end{equation}
\end{theorem}
\end{frame}

\begin{frame}{Korrelation und Bestimmtheitsmaß}
\protect\hypertarget{korrelation-und-bestimmtheitsmauxdf-9}{}
\footnotesize

\setstretch{1.8}

Bemerkungen

\begin{itemize}
\item  Mit $-1 \le r_{xy} \le 1$ folgt aus dem Theorem direkt, dass $0 \le \mbox{R}^2 \le 1$.
\item  Es gilt $\mbox{R}^2 = 0$ genau dann, wenn $\mbox{SQE} = 0$ ist
\item[] $\Rightarrow$ Für $\mbox{R}^2 = 0$ ist die erklärte Streuung der Daten durch die Ausgleichsgerade gleich null.
\item[] $\Rightarrow$$\mbox{R}^2 = 0$ beschreibt also den Fall einer denkbar schlechten Erklärung der Daten durch die Ausgleichsgerade.
\item Es gilt $\mbox{R}^2 = 1$ genau dann, wenn $\mbox{SQE} = \mbox{SQT}$ ist.
\item[] $\Rightarrow$ Für $\mbox{R}^2 = 0$ ist also die Gesamtstreuung gleich der durch die Ausgleichsgerade erklärten Streuung.
\item[] $\Rightarrow$ $\mbox{R}^2 = 1$ beschreibt also den Fall das sämtliche Datenvariabilität durch die Ausgleichsgerade erklärt wird.
\end{itemize}
\end{frame}

\begin{frame}{Korrelation und Bestimmheitsmaß}
\protect\hypertarget{korrelation-und-bestimmheitsmauxdf}{}
\vspace{2mm}
\footnotesize

\underline{Beweis}

Wir halten zunächst fest, dass mit \begin{equation}
\bar{\hat{y}}
:= \frac{1}{n}\sum_{i=1}^n \hat{y}_i
= \frac{1}{n}\sum_{i=1}^n(\hat{\beta}_0 + \hat{\beta}_1x_i)
= \hat{\beta}_0 + \hat{\beta}_1\bar{x}
= \bar{y} - \hat{\beta}_1\bar{x} + \hat{\beta}_1\bar{x}
= \bar{y}
\end{equation} folgt, dass \begin{align}
\begin{split}
\mbox{SQE}
& = \sum_{i=1}^n (\hat{y}_i - \bar{y})^2            \\
& = \sum_{i=1}^n (\hat{y}_i - \bar{\hat{y}})^2      \\
& = \sum_{i=1}^n (\hat{\beta}_0 + \hat{\beta}_1x_i - \hat{\beta}_0 - \hat{\beta}_1 \bar{x})^2      \\
& = \sum_{i=1}^n (\hat{\beta}_1(x_i - \bar{x}))^2      \\
& = \hat{\beta}_1^2\sum_{i=1}^n (x_i - \bar{x})^2      \\
\end{split}
\end{align}
\end{frame}

\begin{frame}{Korrelation und Bestimmheitsmaß}
\protect\hypertarget{korrelation-und-bestimmheitsmauxdf-1}{}
\vspace{2mm}
\footnotesize

\underline{Beweis}

Damit ergibt sich dann \begin{align}
\begin{split}
\mbox{R}^2
& = \frac{\mbox{SQE}}{\mbox{SQT}}                                                 \\
& = \frac{\sum_{i=1}^n (\hat{y}_i - \bar{y})^2}{\sum_{i = 1}^n (y_i - \bar{y})^2} \\
& = \hat{\beta}_1^2\frac{\sum_{i=1}^n (x_i - \bar{x})^2}{\sum_{i = 1}^n (y_i - \bar{y})^2} \\
& = \frac{c_{xy}^2}{s_x^4} \frac{\frac{1}{n-1}\sum_{i=1}^n (x_i - \bar{x})^2}{\frac{1}{n-1}\sum_{i = 1}^n (y_i - \bar{y})^2} \\
& = \frac{c_{xy}^2}{s_x^4} \frac{s_x^2}{s_y^2} \\
& = \frac{c_{xy}^2}{s_x^2s_y^2} \\
& = \left(\frac{c_{xy}}{s_xs_y}\right)^2 \\
& = r_{xy}^2.
\end{split}
\end{align} \(\hfill\Box\)
\end{frame}

\begin{frame}{Korrelation und Bestimmheitsmaß}
\protect\hypertarget{korrelation-und-bestimmheitsmauxdf-2}{}
\vspace{2mm}

Beispiele

\begin{center}\includegraphics[width=0.6\linewidth]{2_Abbildungen/alm_2_r2beispiele} \end{center}
\end{frame}

\begin{frame}{}
\protect\hypertarget{section-5}{}
\setstretch{2.2}
\vfill
\large

Grundlagen

Korrelation und Bestimmtheitsmaß

\textbf{Korrelation und lineare Abhängigkeit}

Korrelation und Regression

Partielle Korrelation

Selbstkontrollfragen

\vfill
\end{frame}

\begin{frame}{Korrelation und lineare Abhängigkeit}
\protect\hypertarget{korrelation-und-lineare-abhuxe4ngigkeit}{}
Funktionale Abhängigkeiten und Stichprobenkorrelation

\vspace{1cm}

\begin{center}\includegraphics[width=1\linewidth]{2_Abbildungen/alm_2_rlinearitaet} \end{center}
\vspace{-5mm}

\(\,\) \hspace{1cm} \(y_i = x_i + \varepsilon_i\) \hspace{1.9cm}
\(y_i = x_i^2 + \varepsilon_i\) \hspace{1.2cm}
\(y_i = 8 \cos(2x_i) + \varepsilon_i\)

\center

\(\quad\,\,\,\varepsilon_i \sim N(0,1)\)
\end{frame}

\begin{frame}{Korrelation und lineare Abhängigkeit}
\protect\hypertarget{korrelation-und-lineare-abhuxe4ngigkeit-1}{}
\small
\begin{theorem}[Korrelation und linear-affine Abhängigkeit]
\justifying
\normalfont
$X$ und $Y$ seien zwei Zufallsvariablen mit positiver Varianz.  Dann besteht genau
dann eine lineare-affine Abhängigkeit der Form
\begin{equation}
Y = \beta_0 + \beta_1X \mbox{ mit } \beta_0,\beta_1\in \mathbb{R}
\end{equation}
zwischen $X$ und $Y$, wenn
\begin{equation}
\rho(X,Y) = 1 \mbox{ oder } \rho(X,Y) = -1
\end{equation}
gilt.
\end{theorem}

\footnotesize

Bemerkungen

\begin{itemize}
\tightlist
\item
  Die lineare Abhängigkeit \(Y = \beta_0 + \beta_1X\) impliziert eine
  lineare Abhängigkeit \(X = \tilde{\beta}_0 + \tilde{\beta}_1Y\), denn
  \begin{equation}
  Y = \beta_0 + \beta_1X
  \Leftrightarrow
  -\beta_0 + Y = \beta_1X
  \Leftrightarrow
  X = -\frac{\beta_0}{\beta_1} + \frac{1}{\beta_1}Y
  \Leftrightarrow
  X = \tilde{\beta}_0 + \tilde{\beta}_1 Y
  \end{equation} mit \begin{equation}
  \tilde{\beta}_0 = -\frac{\beta_0}{\beta_1} \mbox{ und } \tilde{\beta}_1 = \frac{1}{\beta_1}.
  \end{equation}
\end{itemize}
\end{frame}

\begin{frame}{Korrelation und lineare Abhängigkeit}
\protect\hypertarget{korrelation-und-lineare-abhuxe4ngigkeit-2}{}
\footnotesize

\underline{Beweis} \setstretch{1.0}

Wir beschränken uns auf den Beweis der Aussage, dass aus
\(Y = \beta_0 + \beta_1 X\) folgt, dass \(\rho(X,Y) = \pm 1\) ist. Dazu
halten wir zunächst fest, dass mit den Theoremen zu den Eigenschaften
von Erwartungswert und Varianz gilt, dass \begin{equation}
\mathbb{E}(Y) = \beta_0 + \beta_1\mathbb{E}(X)
\mbox{ und }
\mathbb{V}(Y) = \beta_1^2 \mathbb{V}(X).
\end{equation} Wegen \(\mathbb{V}(X) > 0\) und \(\mathbb{V}(Y) > 0\)
gilt damit \(\beta_1 \neq 0\). Es folgt dann \begin{equation}
\beta_1 > 0 \Rightarrow \mathbb{S}(Y) = \beta_1 \mathbb{S}(X) > 0
\mbox{ und }
\beta_1< 0 \Rightarrow \mathbb{S}(Y) = -\beta_1 \mathbb{S}(X) > 0.
\end{equation} Weiterhin gilt \begin{align}
\begin{split}
Y - \mathbb{E}(Y)
& = \beta_0 + \beta_1X - \mathbb{E}(Y)                      \\
& = \beta_0 + \beta_1X - \beta_0 - \beta_1\mathbb{E}(X)     \\
& = \beta_1X - \beta_1\mathbb{E}(X)                         \\
& = \beta_1(X -\mathbb{E}(X)).
\end{split}
\end{align} Für die Kovarianz von \(X\) und \(Y\) ergibt sich also
\begin{align}
\begin{split}
\mathbb{C}(X,Y)
& = \mathbb{E}\left((Y - \mathbb{E}(Y))(X - \mathbb{E}(X))\right) \\
& = \mathbb{E}\left(\beta_1(X - \mathbb{E}(X))(X - \mathbb{E}(X))\right) \\
& = \beta_1\mathbb{E}\left((X - \mathbb{E}(X))^2\right) \\
& = \beta_1\mathbb{V}(X).
\end{split}
\end{align} Damit ergibt für die Korrelation von \(X\) und \(Y\)
\begin{equation}
\rho(X,Y)
= \frac{\mathbb{C}(X,Y)}{\mathbb{S}(X)\mathbb{S}(Y)}
= \pm \frac{\beta_1\mathbb{V}(X)}{\mathbb{S}(X)\beta_1 \mathbb{S}(X)}
= \pm \frac{\beta_1\mathbb{V}(X)}{\beta_1\mathbb{V}(X)}
= \pm 1.
\end{equation}
\end{frame}

\begin{frame}{}
\protect\hypertarget{section-6}{}
\setstretch{2.2}
\vfill
\large

Grundlagen

Korrelation und lineare Abhängigkeit

\textbf{Korrelation und Regression}

Korrelation und Bestimmtheitsmaß

Partielle Korrelation

Selbstkontrollfragen

\vfill
\end{frame}

\begin{frame}{Korrelation und Regression}
\protect\hypertarget{korrelation-und-regression}{}
Überblick

\footnotesize

Der fundamentale Unterschied zwischen ``Korrelation'' und ``Regression''
ist, dass

\begin{itemize}
\tightlist
\item
  bei Korrelation sowohl die UV (die \(x\)'s) als auch die AV (die
  \(y\)'s) als Zufallsvariablen modelliert werden,
\item
  bei Regression dagegen lediglich die AV als Zufallsvariable modelliert
  wird und die UV als vorgegeben gilt.
\end{itemize}

Dieser Tatsache unbenommen, kann man auf gegebene Daten prinzipiell
natürlich sowohl ``Korrelation'' als auch ``Regression'' anwenden. Das
Ergebnis einer Regressionsanalyse lässt sich in das Ergebnis einer
Korrelationsanalyse umrechnen. Die zusätzlich Durchführung einer
Korrelationsanalyse bei durchgeführter Regressionsanalyse erzeugt kein
mehr an Information oder Verständnis über den Zusammenhang von UV und
AV.

Für ein tieferes Verständnis dieser Zusammenhänge ist ein
Regressionsmodell nötig, indem auch die UV eine Zufallsvariable ist. In
Abgrenzung zum Modell der einfachen linearen Regression, in dem die UV
keine Zufallsvariable ist, bezeichnen wir dieses Modell als
\textit{Regression}. Letztlich gerät die Terminologie hier an eine
Grenze und es muss jeweils geprüft bzw. geschlossen werden, welches
Modell Datenanalysten nun tatsächlich vorschwebt.
\end{frame}

\begin{frame}{Korrelation und Regression}
\protect\hypertarget{korrelation-und-regression-1}{}
\small
\begin{definition}[Regressionsgerade zweier Zufallsvariablen]
\justifying
$X$ und $Y$ seien zwei Zufallsvariablen. Dann heißt
\begin{equation}
Y  = \beta_0 + \beta_1 X \mbox{ mit }
\end{equation}
mit
\begin{equation}
\beta_1 := \frac{\mathbb{C}(X,Y)}{\mathbb{V}(X)} \mbox{ und }\beta_0 := \mathbb{E}(Y) - \beta_1\mathbb{E}(X)
\end{equation}
die \textit{Regressionsgerade der Zufallsvariablen $X$ auf $Y$}, $\beta_0$ und
$\beta_1$ heißen die zugehörigen \textit{Regressionskoeffizienten}, und die
Zufallsvariable
\begin{equation}
E := Y - \beta_0 - \beta_1 X
\end{equation}
heißt die \textit{Residualvariable}.
\end{definition}

\footnotesize

Bemerkungen

\begin{itemize}
\tightlist
\item
  \(X\) und \(Y\) sind Zufallsvariablen, \(\beta_0\) und \(\beta_1\)
  sind keine Zufallsvariablen.
\end{itemize}
\end{frame}

\begin{frame}{Korrelation und Regression}
\protect\hypertarget{korrelation-und-regression-2}{}
\small
\begin{theorem}[Optimalität der Regressionsgerade zweier Zufallsvariablen]
\justifying
\normalfont
Unter allen Geraden der Form
\begin{equation}
Y  = \beta_0 + \beta_1 X
\end{equation}
ist die Gerade mit
\begin{equation}
\beta_1 := \frac{\mathbb{C}(X,Y)}{\mathbb{V}(X)} \mbox{ und } \beta_0 :=  \mathbb{E}(Y) - \beta_1\mathbb{E}(X)
\end{equation}
diejenige, für die
\begin{equation}
\tilde{q}: \mathbb{R}^2 \to \mathbb{R}, (\beta_0, \beta_1) \mapsto \tilde{q}(\beta_0,\beta_1) := \mathbb{E}\left((Y - (\beta_0 + \beta_1 X)^2\right)
\end{equation}
ein Minimum hat.
\end{theorem}
\end{frame}

\begin{frame}{Korrelation und Regression}
\protect\hypertarget{korrelation-und-regression-3}{}
\tiny
\setstretch{1}
\tiny
\setlength{\abovedisplayskip}{3pt}
\setlength{\belowdisplayskip}{3pt}

\underline{Beweis}

Wir halten zunächst fest, dass \begin{align}
\begin{split}
\tilde{q}(\beta_0,\beta_1)
& = \mathbb{E}\left(Y - \beta_0 - \beta_1 X \right) \\
& = \mathbb{E}\left(Y - \beta_1 X - \beta_0 + \beta\mathbb{E}(X) - \beta_1\mathbb{E}(X) + \mathbb{E}(Y) - \mathbb{E}(Y) \right) \\
& = \mathbb{E}\left((Y - \mathbb{E}(Y)) - \beta_1(X - \mathbb{E}(X)) + (\mathbb{E}(Y) - \beta_1\mathbb{E}(X) - \beta_0)\right) \\
\end{split}
\end{align} Ausmultiplizieren und Anwendung des Theorems zu den
Eigenschaften des Erwartungswerts ergibt dann \begin{equation}
\tilde{q}(\beta_0,\beta_1) = \mathbb{V}(Y) + \beta_1^2 \mathbb{V}(X) - 2 \beta_1 \mathbb{C}(X,Y) + \left(\mathbb{E}(Y) - \beta_1 \mathbb{E}(X) - \beta_0\right)^2
\end{equation} Berechnen der partiellen Ableitungen von \(\tilde{q}\)
hinsichtlich von \(\beta_0\) und \(\beta_1\) ergibt dann
\begin{equation}\label{eq:partial_beta_0}
\frac{\partial}{\partial \beta_0}\tilde{q}(\beta_0,\beta_1) = -2\left(\mathbb{E}(Y) - \beta_1 \mathbb{E}(X) - \beta_0\right)
\end{equation} und \begin{equation}
\frac{\partial}{\partial \beta_1}\tilde{q}(\beta_0,\beta_1) = 2\beta_1\mathbb{V}(X) - 2\mathbb{C}(X,Y) - 2\mathbb{E}(X)\left(\mathbb{E}(Y) - \beta_1\mathbb{E} - \beta_0\right)
\end{equation} Nullsetzen von \eqref{eq:partial_beta_0} ergibt dann als
notwendige Bedingungen für ein Minimum von \(\tilde{q}\) \begin{align}
\begin{split}
\frac{\partial}{\partial \beta_0}\tilde{q}(\beta_0^*,\beta_1^*)     = 0
& \Leftrightarrow
\mathbb{E}(Y) - \beta_1^* \mathbb{E}(X) - \beta_0^* = 0 \\
\frac{\partial}{\partial \beta_1}\tilde{q}(\beta_0^*,\beta_1*)  = 0
& \Leftrightarrow
2\beta_1^*\mathbb{V}(X) - 2\mathbb{C}(X,Y) - 2\mathbb{E}(X)\left(\mathbb{E}(Y) - \beta_1^*\mathbb{E} - \beta_0^*\right) = 0
\end{split}
\end{align} Die erste Gleichung impliziert dann für die zweite
Gleichung, dass \begin{equation}
2\beta_1^*\mathbb{V}(X) - 2\mathbb{C}(X,Y) = 0 \Leftrightarrow \beta_1^* = \frac{\mathbb{C}(X,Y)}{\mathbb{V}(X)}
\end{equation} Einsetzen in die erste Gleichung ergibt dann
\begin{align}
\begin{split}
\mathbb{E}(Y) - \beta_1^* \mathbb{E}(X) - \beta_0^* & = 0
\Leftrightarrow
\beta_0^*   = \mathbb{E}(Y) - \beta_1^* \mathbb{E}(X) \\
\end{split}
\end{align}
\end{frame}

\begin{frame}{Korrelation und Regression}
\protect\hypertarget{korrelation-und-regression-4}{}
\footnotesize
\begin{theorem}[Zusammenhang von Korrelation und Regression]
\normalfont
\justifying
$X$ und $Y$ seien zwei Zufallsvariablen,
\begin{equation}
Y = \beta_0 + \beta_1 X
\mbox{ mit }
\beta_1 := \frac{\mathbb{C}(X,Y)}{\mathbb{V}(X)}
\mbox{ und }
\beta_0 := \mathbb{E}(Y) -\tilde{\beta}_1\mathbb{E}(X)
\end{equation}
sei die Regressionsgerade der Zufallsvariablen $Y$ bezüglich der Zufallsvariablen
$X$ mit den Regressionskoeffizienten  $\beta_0$ und $\beta_1$ und
\begin{equation}
X = \tilde{\beta}_0 + \tilde{\beta_1} Y
\mbox{ mit }
\tilde{\beta}_1 := \frac{\mathbb{C}(X,Y)}{\mathbb{V}(Y)}
\mbox{ und }
\tilde{\beta}_0 := \mathbb{E}(X) -\tilde{\beta}_1\mathbb{E}(Y)
\end{equation}
sei die Regressionsgerade der Zufallsvariablen $X$ bezüglich der Zufallsvariablen
$Y$ mit den Regressionskoeffizienten $\tilde{\beta}_0$ und $\tilde{\beta}_1$. Dann gilt
\begin{equation}
\beta_1 \tilde{\beta}_1
= \frac{\mathbb{C}(X,Y)}{\mathbb{V}(X)}\frac{\mathbb{C}(X,Y)}{\mathbb{V}(Y)}
= \frac{\mathbb{C}(X,Y)^2}{\mathbb{V}(X)\mathbb{V}(Y)}
= \rho(X,Y)^2.
\end{equation}
\end{theorem}

Bemerkungen

\begin{itemize}
\tightlist
\item
  \(\rho(X,Y)\) kann aus den Regressionskoeffizienten von \(X\) auf
  \(Y\) und von \(Y\) auf \(X\) errechnet werden.
\end{itemize}
\end{frame}

\begin{frame}{Korrelation und Regression}
\protect\hypertarget{korrelation-und-regression-5}{}
\footnotesize
\begin{definition}[Stichprobenregressionsgerade]
\justifying
$(X_1,Y_1), ..., (X_n,Y_n)$ sei eine Stichprobe von zweidimensionale Zufallsvektoren
mit identischen unabhängigen Verteilungen. Weiterhin sei für $i = 1,...,n$
\begin{equation}
Y_1 = \beta_0 + \beta_1 X_1
\mbox{ mit }
\beta_1 := \frac{\mathbb{C}(X_1,Y_1)}{\mathbb{V}(X_1)}
\mbox{ und }
\beta_0 := \beta_1\mathbb{E}(X_1) + \mathbb{E}(Y_1)
\end{equation}
die Regressionsgerade der Zufallsvariablen $Y_1$ bezüglich der Zufallsvariablen
$X_1$ mit den Regressionskoeffizienten  $\beta_0$ und $\beta_1$. Schließlich seien
\begin{itemize}
\item $\bar{x}$  und $\bar{y}$ die Stichprobenmittel von Realisierungen der Komponenten der Stichprobe,
\item $s_X^2$ und $s_Y^2$ die Stichprobenvarianzen von Realisierungen der Komponenten der Stichprobe und
\item $c_{X,Y}$ die Stichprobenkovarianz  von Realisierungen der Stichprobe.
\end{itemize}
Dann heißt für $x \in \mathbb{R}$
\begin{equation}
y = b_0 + b_1 x
\mbox{ mit }
b_1 := \frac{c_{X,Y}}{s_X^2}
\mbox{ und }
b_0 := \bar{y} - b_1\bar{x}
\end{equation}
die Regressionsgerade der $y$-Werte bezüglich der $x_i$ Werte in der Stichprobe.
\end{definition}
\end{frame}

\begin{frame}[fragile]{Korrelation und Regression}
\protect\hypertarget{korrelation-und-regression-6}{}
Simulation einer Regressionsgerade

\tiny
\setstretch{1}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(MASS)                                   }\CommentTok{\# multivariate Normalverteilungen}

\CommentTok{\# Modellformulierung}
\NormalTok{n      }\OtherTok{=} \FloatTok{1e2}                                     \CommentTok{\# Anzahl an Stichprobenvektoren}
\NormalTok{C\_XY   }\OtherTok{=} \DecValTok{1}                                      \CommentTok{\# Kovarianz von X und Y}
\NormalTok{EX     }\OtherTok{=} \DecValTok{2}                                      \CommentTok{\# Erwartungswert von X}
\NormalTok{EY     }\OtherTok{=} \DecValTok{1}                                      \CommentTok{\# Erwartungswert von Y}
\NormalTok{VX     }\OtherTok{=} \DecValTok{2}                                      \CommentTok{\# Varianz von X}
\NormalTok{VY     }\OtherTok{=} \DecValTok{2}                                      \CommentTok{\# Varianz von Y}
\NormalTok{beta\_1 }\OtherTok{=}\NormalTok{ C\_XY}\SpecialCharTok{/}\NormalTok{VX                                }\CommentTok{\# Regressionskoeffizient}
\NormalTok{beta\_0 }\OtherTok{=} \SpecialCharTok{{-}}\NormalTok{beta\_1}\SpecialCharTok{*}\NormalTok{EX }\SpecialCharTok{+}\NormalTok{ EY                        }\CommentTok{\# Regressionskoeffizient}

\CommentTok{\# Realisierungsgeneration}
\NormalTok{mu     }\OtherTok{=} \FunctionTok{c}\NormalTok{(EX, EY)                              }\CommentTok{\# Erwartungswertparameter}
\NormalTok{Sigma  }\OtherTok{=} \FunctionTok{matrix}\NormalTok{(}\FunctionTok{c}\NormalTok{(VX, C\_XY, C\_XY,VY), }\AttributeTok{nrow =} \DecValTok{2}\NormalTok{) }\CommentTok{\# Kovarianzmatrixparameter}
\NormalTok{xy     }\OtherTok{=} \FunctionTok{mvrnorm}\NormalTok{(n, mu, Sigma)}

\CommentTok{\# Stichprobenstatistiken}
\NormalTok{x\_bar  }\OtherTok{=} \FunctionTok{mean}\NormalTok{(xy[,}\DecValTok{1}\NormalTok{])                           }\CommentTok{\# Stichprobenmittel  der x\_1,...,x\_n}
\NormalTok{y\_bar  }\OtherTok{=} \FunctionTok{mean}\NormalTok{(xy[,}\DecValTok{2}\NormalTok{])                           }\CommentTok{\# Stichprobenmittel  der y\_1,...,y\_n}
\NormalTok{s2X    }\OtherTok{=} \FunctionTok{var}\NormalTok{(xy[,}\DecValTok{1}\NormalTok{])                            }\CommentTok{\# Stichprobenvarianz der x\_1,...,x\_n}
\NormalTok{s2Y    }\OtherTok{=} \FunctionTok{var}\NormalTok{(xy[,}\DecValTok{2}\NormalTok{])                            }\CommentTok{\# Stichprobenvarianz der y\_1,...,y\_n}
\NormalTok{c\_xy   }\OtherTok{=} \FunctionTok{cov}\NormalTok{(xy[,}\DecValTok{1}\NormalTok{],xy[,}\DecValTok{2}\NormalTok{])                     }\CommentTok{\# Stichprobenkovarianz}

\CommentTok{\# Stichprobenregressionsgeradenparameter}
\NormalTok{b\_1    }\OtherTok{=}\NormalTok{ c\_xy}\SpecialCharTok{/}\NormalTok{s2X                               }\CommentTok{\# Stichprobenregressionskoeffizient}
\NormalTok{b\_0    }\OtherTok{=} \SpecialCharTok{{-}}\NormalTok{b\_1}\SpecialCharTok{*}\NormalTok{x\_bar }\SpecialCharTok{+}\NormalTok{ y\_bar                     }\CommentTok{\# Stichprobenregressionskoeffizient}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
> beta_0   : 0 
> beta_1   : 0.5 
> b_0      : 0.136 
> b_1      : 0.514
\end{verbatim}
\end{frame}

\begin{frame}{Korrelation und Regression}
\protect\hypertarget{korrelation-und-regression-7}{}
Simulation einer Regressionsgerade \vspace{3mm}

\begin{center}\includegraphics[width=0.6\linewidth]{2_Abbildungen/alm_2_stichprobenregression} \end{center}
\end{frame}

\begin{frame}{}
\protect\hypertarget{section-7}{}
\setstretch{2.2}
\vfill
\large

Grundlagen

Korrelation und lineare Abhängigkeit

Korrelation und Regression

Korrelation und Bestimmtheitsmaß

\textbf{Partielle Korrelation}

Selbstkontrollfragen

\vfill
\end{frame}

\begin{frame}{}
\protect\hypertarget{section-8}{}
\setstretch{2.2}
\vfill
\large

Grundlagen

Korrelation und lineare Abhängigkeit

Korrelation und Regression

Korrelation und Bestimmtheitsmaß

Partielle Korrelation

\textbf{Selbstkontrollfragen}

\vfill
\end{frame}

\begin{frame}{}
\protect\hypertarget{section-9}{}
\setstretch{2.2}
\vfill
\large

Grundlagen

Korrelation und Bestimmtheitsmaß

Korrelation und lineare Abhängigkeit

Korrelation und Regression

Partielle Korrelation

\textbf{Selbstkontrollfragen}

\vfill
\end{frame}

\begin{frame}{Selbstkontrollfragen}
\protect\hypertarget{selbstkontrollfragen}{}
\setstretch{1.8}
\tiny
\justifying

\begin{enumerate}
\tightlist
\item
  Geben Sie die Definition der Korrelation zweier Zufallsvariablen
  wieder.
\item
  Geben Sie die Definitionen von Stichprobenmittel, -standardabweichung,
  -kovarianz und -korrelation wieder.
\item
  Erläutern Sie anhand der Mechanik der Kovariationsterme, wann eine
  Stichprobenkorrelation einen hohen absoluten Wert annimmt, einen hohen
  positiven Wert annimmt, einen hohen negativen Wert annimmt und einen
  niedrigen Wert annimmt.
\item
  Berechnen Sie die Korrelation von Anzahl der Therapiestunden und
  Symptomreduktion anhand der Daten in Beispieldatensatz.csv.
\item
  Geben Sie das Theorem zur Stichprobenkorrelation bei linear-affinen
  Transformationen wieder.
\item
  Erläutern Sie das Theorem zur Stichprobenkorrelation bei
  linear-affinen Transformationen.
\item
  Geben Sie die Definitionen von erklärten Werten und Residuen einer
  Ausgleichsgerade wieder.
\item
  Geben Sie das Theorem zur Quadratsummenzerlegung bei einer
  Ausgleichsgerade wieder.
\item
  Erläutern Sie die intuitiven Bedeutungen von
  \(\mbox{SQT}, \mbox{SQE}\) und \(\mbox{SQR}\).
\item
  Geben Sie die Definition des Bestimmtheitsmaßes \(\mbox{R}^2\) wieder.
\item
  Geben Sie das Theorem zum Zusammenhang von Stichprobenkorrelation und
  Bestimmtheitsmaß wieder.
\item
  Erläutern Sie die Bedeutung von hohen und niedrigen \(\mbox{R}^2\)
  Werten im Lichte der Ausgleichsgerade.
\item
  Berechnen Sie in einem R-Skript \(\mbox{R}^2\) für die Daten in der
  Datei Beispieldatensatz.csv anhand der Definition von \(\mbox{R}^2\).
  Überprüfen Sie Ihr Ergebnis anhand des Theorems zum Zusammenhang von
  Stichprobenkorrelation und Bestimmheitsmaß.
\item
  Geben Sie das Theorem zum Zusammenhang von Korrelation und
  linear-affiner Abhängigkeit wieder.
\item
  Geben Sie die Definition der Regressionsgerade zweier Zufallsvariablen
  wieder.
\item
  Geben Sie das Theorem zur Optimalität der Regressionsgerade zweier
  Zufallsvariablen wieder.
\item
  Geben Sie das Theorem zum Zusammenhang von Korrelation und Regression
  an.
\item
  Erläutern Sie, wie aus den Ergebnissen einer Regressionananlyse das
  Ergebnis einer Korrelationsanalyse errechnet werden kann.
\end{enumerate}
\end{frame}

\end{document}
