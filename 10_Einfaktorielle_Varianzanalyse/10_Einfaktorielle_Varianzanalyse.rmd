---
fontsize: 8pt
bibliography: 10_Referenzen.bib
citation_package: natbib
output:
  beamer_presentation:
    keep_tex: true
    includes:
      in_header: 10_header.tex
---


```{r, include = F}
source("10_R_common.R")
fdir        = file.path(getwd(), "10_Abbildungen")                                # Abbildungsverzeichnis
```


#  {.plain}
\center
```{r, echo = FALSE, out.width = "20%"}
knitr::include_graphics("10_Abbildungen/alm_10_otto.png")
```

\vspace{2mm}

\huge
Allgemeines Lineares Modell
\vspace{6mm}

\large
BSc Psychologie SoSe 2022

\vspace{6mm}
\normalsize
Prof. Dr. Dirk Ostwald

# {.plain}
\center
\huge
\vfill
\noindent (10) Einfaktorielle Varianzanalyse
\vfill

#
\large
\setstretch{2.7}
\vfill
Anwendungsszenario

Modellformulierung

Modellschätzung

Modellevaluation

Selbstkontrollfragen
\vfill

#
\large
\setstretch{2.7}
\vfill
**Anwendungsszenario**

Modellformulierung

Modellschätzung

Modellevaluation

Selbstkontrollfragen
\vfill

# Anwendungsszenario
\small

**\textcolor{darkblue}{Zwei oder mehr Gruppen}** (Stichproben) randomisierter experimenteller Einheiten.

Annahme der unabhängigen und identischen Normalverteilung $N(\mu_i,\sigma^2)$ der Daten.

$\mu_i$ und $\sigma^2$ unbekannt.

Absicht des inferentiellen Testens der Nullhypothese identischer Gruppenerwartungswerte.

\begin{center}
$\Rightarrow$ Generalisierung des Zweistichproben-T-Tests bei unabhängigen Stichproben mit
einfacher Nullhypothese für mehr als Zweistichproben
\end{center}

\vspace{2mm}
**\textcolor{darkblue}{Anwendungsbeispiele}**


PrePost-BDI Differenzwertanalyse für drei Gruppen von Patient:innen (F2F, ONL, WLC)

* Inferentielle Evidenz für Gruppenerwartungswertunterschiede?
* Evidenz für unterschiedliche Therapiewirksamkeit?

Tense Arousal Differenzwertanalyse bei vier Filmclip-basierten Emotionsinduktionsbedingungen

* Inferentielle Evidenz für Gruppenerwartungswertunterschiede?
* Evidenz für unterschiedliche Tense Arousal Induktion?

# Anwendungsszenario

```{r, eval = F, echo = F}
# Initialisierung
library(writexl)                                                                 # Excel Output
set.seed(1)                                                                      # Random number generator seed

# Simulationsparameter
n_c    = 3                                                                       # Anzahl Gruppen
n_i    = 40                                                                      # Anzahl Proband:innen pro Gruppe
n      = n_c*n_i                                                                 # Gesamtanzahl Datenpunte


# Simulationsparameter
mu_pre = c(31, 32, 29)                                                           # \mu pre F2F, ONL, WLC
mu_pos = c(27, 26, 30)                                                           # \mu post F2F, ONL, WLC
sigsqr = 10                                                                      # \sigma^2

# Datensimulation
D            = data.frame("ID" = 1:n)                                            # Dataframe Initialisierung und ID Variable
D$Condition  = c(rep("F2F",n_i), rep("ONL", n_i), rep("WLC", n_i))               # Bedingung
D$PreBDI     = c(round(rnorm(n_i, mu_pre[1], sqrt(sigsqr))),                     # PreBDI
                 round(rnorm(n_i, mu_pre[2], sqrt(sigsqr))),
                 round(rnorm(n_i, mu_pre[3], sqrt(sigsqr))))
D$PostBDI    = c(round(rnorm(n_i, mu_pos[1], sqrt(sigsqr))),                     # PostBDI
                 round(rnorm(n_i, mu_pos[2], sqrt(sigsqr))),
                 round(rnorm(n_i, mu_pos[3], sqrt(sigsqr))))
D$BDI        = -(D$PostBDI - D$PreBDI)                                           # -(PostBDI - PreBDI) = PreBDI - PostBDI
D$Age        = round(runif(n,20,80))                                             # Uniform verteilte Alterswerte
D$Duration   = round(runif(n,12,24))                                             # Uniform Therapiedauerwerte


# Datenspeicherung
write_xlsx(D, file.path(getwd()       , "10_Daten", "10_Einfaktorielle_Varianzanalyse_Daten.xlsx"))
write.csv( D, file = file.path(getwd(), "10_Daten", "10_Einfaktorielle_Varianzanalyse_Daten.csv"))
```

\vspace{3mm}
\small
\textcolor{darkblue}{Dateneinlesen}
\setstretch{.9}
\tiny
\vspace{1mm}
```{r}
fname       = file.path(getwd(), "10_Daten", "10_Einfaktorielle_Varianzanalyse_Daten.csv")
D           = read.table(fname, sep = ",", header = TRUE)
```
\vspace{-1mm}
```{r, echo = F}
# table visualization
knitr::kable(D[c(1:10, 41:50, 81:90),2:8],
             align      = "ccc",
             "pipe")
```


# Anwendungsszenario
\textcolor{darkblue}{Boxplot}
\vspace{3mm}
\tiny
\setstretch{1}
```{r, eval = F}
# Dateneinlesen
fname       = file.path(getwd(), "10_Daten", "10_Einfaktorielle_Varianzanalyse_Daten.csv")
D           = read.table(fname, sep = ",", header = TRUE)

# Abbildungsparameter
par(                                        # für Details siehe ?par
family      = "sans",                       # Serif-freier Fonttyp
pty         = "m",                          # Maximale Abbildungsregion
bty         = "l",                          # L förmige Box
lwd         = 1,                            # Liniendicke
las         = 1,                            # Horizontale Achsenbeschriftung
font.main   = 1,                            # Non-Bold Titel
cex         = 1,                            # Textvergrößerungsfaktor
cex.main    = 1.2)                          # Titeltextvergrößerungsfaktor

# Boxplot
boxplot(BDI ~ Condition, data = D)          # BDI ~ Condition enkodiert die Datengruppierung

# PDF Speicherung
dev.copy2pdf(
file        = file.path(getwd(), "10_Abbildungen", "alm_10_aov_1_boxplot.pdf"),
width       = 7,
height      = 4)
```

# Anwendungsszenario
\textcolor{darkblue}{Boxplot}
\vspace{4mm}

```{r, echo = FALSE, out.width = "95%"}
knitr::include_graphics("10_Abbildungen/alm_10_aov_1_boxplot.pdf")
```

# Anwendungsszenario
\textcolor{darkblue}{Balkendiagramm}
\vspace{1mm}
\tiny
\setstretch{.8}

```{r, eval = F}
# Datenselektion
fname       = file.path(getwd(), "10_Daten", "10_Einfaktorielle_Varianzanalyse_Daten.csv")
D           = read.table(fname, sep = ",", header = TRUE)

# Datenselektion
A           = data.frame(                          # neuer Dataframe
              F2F = D$BDI[D$Condition == "F2F"],   # F2F BDI Daten
              ONL = D$BDI[D$Condition == "ONL"],   # ONL BDI Daten
              WLC = D$BDI[D$Condition == "WLC"])   # WLC BDI Daten

# Deskriptive Statistiken
groupmeans  = colMeans(A)                          # Gruppenmittelwerte
groupstds   = apply(A,2,sd)                        # Gruppenstandardabweichungen

# Balkendiagramm
par(                                               # für Details siehe ?par
family      = "sans",                              # Serif-freier Fonttyp
pty         = "m",                                 # Maximale Abbildungsregion
bty         = "l",                                 # L förmige Box
lwd         = 1,                                   # Liniendicke
las         = 1)                                   # Horizontale Achsenbeschriftung
x = barplot(                                       # Ausgabe der x-Ordinaten (?barplot für Details)
groupmeans,
ylim        = c(-5,15),
col         = "gray90",
ylab        = "BDI",
xlab        = "Condition")
arrows(                                            # für Details siehe ?arrows
x0          = x,                                   # arrow start x-ordinate
y0          = groupmeans - groupstds,              # arrow start y-ordinate
x1          = x,                                   # arrow end   x-ordinate
y1          = groupmeans + groupstds,              # arrow end   y-ordinate
code        = 3,                                   # Pfeilspitzen beiderseits
angle       = 90,                                  # Pfeilspitzenwinkel -> Linie
length      = 0.05)                                # Linielänge

# PDF Speicherung
dev.copy2pdf(
file        = file.path(getwd(), "10_Abbildungen", "alm_10_aov_1_barplot.pdf"),
width       = 7,
height      = 4)

```
# Anwendungsszenario
\textcolor{darkblue}{Balkendiagramm}
\vspace{1mm}

\center
Gruppenmittelwerte $\pm$ Gruppenstandardabweichungen

\vspace{3mm}

```{r, echo = FALSE, out.width = "95%"}
knitr::include_graphics("10_Abbildungen/alm_10_aov_1_barplot.pdf")
```

#
\large
\setstretch{2.7}
\vfill
Anwendungsszenario

**Modellformulierung**

Modellschätzung

Modellevaluation

Selbstkontrollfragen
\vfill

# Modellformulierung
\footnotesize
\begin{definition}[EVA Modell in Erwartungswertparameterdarstellung]
\justifying
$y_{ij}$ mit $i= 1,...,p$ und $j = 1,...,n_i$ seien Zufallsvariablen, die
die Datenpunkte eines EVA Szenarios modellieren. Dann hat das
\textit{EVA Modell in Erwartungswertparameterdarstellung} die strukturelle Form
\begin{equation}
y_{ij} = \mu_i + \varepsilon_{ij}
\mbox{ mit } \varepsilon_{ij} \sim N(0,\sigma^2)
\mbox{ u.i.v. für } i = 1,...,p, j = 1,...,n_i \mbox{ mit } \mu_i \in \mathbb{R}, \sigma^2 > 0.
\end{equation}
und die Datenverteilungsform
\begin{equation}\label{eq:aov_1_klassisch}
y_{ij} \sim N(\mu_i,\sigma^2) \mbox{ u.i.v. für } i = 1,...,p, j = 1,...,n_i \mbox{ mit } \mu_i \in \mathbb{R}, \sigma^2 > 0.
\end{equation}
Wenn $n_i := m$ für alle $i = 1,...,p$ heißt das EVA Szenario \textit{balanciert}.
\end{definition}


Bemerkungen

* \justifying Die Äquivalenz der beiden Modellformulierungen folgt aus den
  Ergebnissen in Einheit (5) Modellformulierung
* Es handelt sich um die Generalisierung des Zweistichproben-T-Test Modells für
  unabhängige Stichproben unter Annahme identischer Varianzparameter von $p = 2$
  auf ein beliebiges $p \in \mathbb{N}$.
* Bei balancierten Varianzanalyseszenarien besteht jede Datengruppe aus der gleichen
  Anzahl von Datenpunkten.

# Modellformulierung
\textcolor{darkblue}{Motivation der Effektdarstellung}

\footnotesize
Die Erwartungswertparameterdarstellung des EVA Modells ist ein valides ALM, das
sich in dieser Form auch in der Literatur findet (z.B. @georgii_2009, Kapitel 12.4).
Im Sinne der Konsistenz mit mehrfaktoriellen Varianzanalysemodellen bietet sich
jedoch eine Reparameterisierung der Erwartungswertparameter an. Kern dieser
Reparameterisierung ist es, den Erwartungswertparameter der $i$ten Gruppe als
Summe eines *gruppenübergreifenden Erwartungswertparameters* $\mu_0 \in \mathbb{R}$
und eines *gruppenspezifischen Effektparameters* $\alpha_i \in \mathbb{R}$ zu modellieren,
\begin{equation}\label{eq:uber}
\mu_i := \mu_0 + \alpha_i \mbox{ für } i = 1,...,p.
\end{equation}
Dabei modelliert $\alpha_i$ den Unterschied (die Differenz) zwischen dem $i$ten
Erwartungswertparameter $\mu_i$ und dem gruppenübergreifenden Erwartungswertparameter
$\mu_0$,
\begin{equation}
\alpha_i = \mu_i - \mu_0 \mbox{ für } i = 1,...,p.
\end{equation}
Allerdings hat die in dieser Form vorgenommene Reparameterisierung einen entscheidenen
Nachteil: es werden $p$ Erwartungswertparameter $\mu_i, i = 1,...,p$ durch die $p + 1$
Parameter $\mu_0$ und $\alpha_i, i = 1,...,p$ dargestellt. Diese Darstellung ist im
Allgemeinen nicht eindeutig. Zum Beispiel können die Erwartungswertparameter
$\mu_1 = 3, \mu_2 = 5, \mu_3 = 6$ sowohl durch den gruppenspezifischen Erwartungswertparameter
$\mu_0 = 0$ und die gruppenspezifischen Effektparameter $\alpha_1 = 3, \alpha_2 = 5, \alpha_3 = 6$
als auch durch den gruppenspezifischen Erwartungswertparameter $\mu_0 = 1$ und die
gruppenspezifischen Effektparameter $\alpha_1 = 2, \alpha_2 = 4, \alpha_3 = 5$ dargestellt
werden. Man sagt in diesem Kontext auch, dass das EVA Modell mit \eqref{eq:uber}
*überparameterisiert* ist.

# Modellformulierung
\textcolor{darkblue}{Motivation der Effektdarstellung}

\footnotesize
Datenanalytisch hat die Überparameterisierung eines Varianzanalysemodells den Nachteil,
dass aus $p$ geschätzten Erwartungswertparametern $p + 1$ Betaparameterschätzer
bestimmt werden müssten, was wie oben gesehen nicht eindeutig erfolgen kann. Um
diese Probleme in der Effektparameterdarstellung des EVA Modells zu umgehen und diese
konsistent auf mehrfaktorielle Varianzanalysemodelle zu übertragen, bietet sich die
Einführung der Nebenbedingung
\begin{equation}
\alpha_1 := 0
\end{equation}
an. Es wird also ein Effektparameter von vornherein als "gleich Null" angenommen.
Für die gruppenspezifischen Erwartungswertparameter
ergibt sich damit
\begin{align}
\begin{split}
\mu_1 & := \mu_0                                        \\
\mu_i & := \mu_0 + \alpha_i \mbox{ für } i= 2,...,p  .
\end{split}
\end{align}
Hierbei wird die erste Gruppe nun als *Referenzgruppe* bezeichnet und die $\alpha_i$
modellieren die Differenz zwischen dem Erwartungswertparameter der $i$ten Gruppe
und dem Erwartungswertparameter der ersten Gruppe:
\begin{equation}
\alpha_i = \mu_i - \mu_0 = \mu_i - \mu_1 \mbox{ für } i = 1,...,p.
\end{equation}
$\mu_0$ ist also kein gruppenübergreifender Erwartungswertparameter mehr, sondern
identisch mit dem Erwartungswertparameter der ersten Gruppe. Welche tatsächliche
experimentelle Gruppe dabei als "erste Gruppe" definiert wird, ist unerheblich.
Entscheidend ist, dass die entsprechenden Erwartungswertparameterschätzer
$\hat{\mu}_0$,$\hat{\alpha}_2, ..., \hat{\alpha}_p$ korrekt als (1) Erwartungswertparameterschätzer
der Referenzgruppe ($\hat{\mu}_0$) und (2) geschätzte Erwartungswertparameterdifferenz zwischen
dem Erwartungswertparameter der Referenzgruppe und der dem Erwartungswertparameter
der $i$ten Gruppe ($\hat{\alpha}_2, ..., \hat{\alpha}_p$) verstanden werden. Wir
formalisieren das oben Gesagte in folgendem Theorem.



# Modellformulierung
\footnotesize
\setstretch{1.3}
\begin{theorem}[EVA Modell in Effektdarstellung mit Referenzgruppe I]
\justifying
\normalfont
Gegeben sei das EVA Modell in Erwartungswertparameterdarstellung. Dann können die
Zufallsvariablen, die die Datenpunkte des EVA Szenarios modellieren, äquivalent in
der strukturellen Form
\begin{align}\label{eq:aov_1_effekt_1}
\begin{split}
y_{1j} & = \mu_0 + \varepsilon_{1j} \quad\quad\,\,  \mbox{ mit }  \varepsilon_{1j} \sim N(0,\sigma^2) \mbox{ u.i.v. für } j = 1,...,n_1              \\
y_{ij} & = \mu_0 + \alpha_i + \varepsilon_{ij}      \mbox{ mit } \varepsilon_{ij} \sim N(0,\sigma^2) \mbox{ u.i.v. für } i = 2,...,p, j = 1,...,n_i
\end{split}
\end{align}
mit
\begin{equation}
\alpha_i := \mu_i - \mu_1 \mbox{ für } i = 2,...,p
\end{equation}
und in der entsprechenden Datenverteilungsform
\begin{align}\label{eq:aov_1_effekt_2}
\begin{split}
y_{1j} & \sim N(\mu_0,\sigma^2)  \quad\quad\,\, \mbox{ u.i.v. für } j = 1,...,n_i \mbox{ mit } \mu_1 \in \mathbb{R}, \sigma^2 > 0 \\
y_{ij} & \sim N(\mu_0 + \alpha_i,\sigma^2)      \mbox{ u.i.v. für } i = 2,..., p, j = 1,...,n_i \mbox{ mit } \alpha_i \in \mathbb{R}, \sigma^2 > 0 \\
\end{split}
\end{align}
geschrieben werden. Wir nennen \eqref{eq:aov_1_effekt_1} und \eqref{eq:aov_1_effekt_2}
strukturelle und Datenverteilungsform des \textit{EVA Modells in Effektdarstellung
mit Referenzgruppe}.
\end{theorem}
\vspace{-2mm}
\footnotesize
\underline{Beweis}

Es gilt
\begin{equation}
\mu_i = \mu_0 + \mu_i - \mu_0.
\end{equation}
Die Parameterisierungen mit $\mu_i$ und mit $\mu_0 + \mu_i - \mu_0$ sind also gleich
und damit äquivalent. Dann folgt aber auch
\begin{equation}
\mu_i = \mu_0 + (\mu_i - \mu_0) =: \mu_0 + \alpha_i \mbox{ für } i = 1,...,p
\end{equation}
Mit $\alpha_1 := 0$ gilt dann $\mu_1 = \mu_0$ und  $\mu_i = \mu_0 + \alpha_i$ für
$i = 2,...,p$, wie im Theorem behauptet.

# Modellformulierung
\footnotesize
\vspace{2mm}
\setstretch{1.2}
\begin{theorem}[EVA Modell in Effektdarstellung mit Referenzgruppe II]
\justifying
\normalfont
Gegeben sei die strukturelle Form des EVA Modells in Effektdarstellung mit Referenzgruppe.
Dann hat dieses Modell die Designmatrixform
\begin{equation}
y = X\beta + \varepsilon \mbox{ mit } \varepsilon \sim N(0_n,\sigma^2 I_n), n := \sum_{i=1}^p n_i
\end{equation}
\begin{equation*}
\renewcommand{\arraystretch}{.8}
y
:=
\begin{pmatrix*}[c]
y_{11} 	\\ 	\vdots 	\\ y_{1n_1}
\\
y_{21} 	\\ 	\vdots 	\\ y_{2n_2}
\\		\\ 	\vdots 	\\
\\
y_{p1} 	\\ 	\vdots 	\\ y_{pn_p}
\end{pmatrix*}
\in \mathbb{R}^n, \,
X :=
\begin{pmatrix}
1 		    & 	0		   &          & 	0 	  	    \\
\vdots 	  &  	\vdots &	\cdots	& 	\vdots 	    \\
1 		    & 	0		   &	        & 	0 		      \\
1 		    & 	1		   &	        & 	0 		      \\
\vdots 	  & 	\vdots &	\cdots	& 	\vdots 	    \\
1 		    & 	1 		 &			    & 	0 	      	\\
 		      & 			   &			    & 	 		        \\
\vdots 	  & 	\vdots &	\cdots	& 	\vdots 	    \\
 		      &  			   &			    & 	 		        \\
1 		    & 	0		   &			    & 	1 		      \\
\vdots 	  & 	\vdots &	\cdots	& 	\vdots 	    \\
1 		    & 	0 	 	 &			    & 	1 		      \\
\end{pmatrix}
\in \mathbb{R}^{n \times p},\,
\beta :=
\begin{pmatrix}
\mu_0 		\\
\alpha_2	\\
\vdots		\\
\alpha_p
\end{pmatrix}
\in \mathbb{R}^{p}
\mbox{ und }
\sigma^2 > 0.
\end{equation*}
\end{theorem}
\vspace{-2mm}
\underline{Beweis}

Das Theorem ergibt sich direkt mit den Regeln der Matrixmultiplikation.

# Modellformulierung
\small
\textcolor{darkblue}{Beispiel}

Es seien
\begin{equation}
p = 4 \mbox{ und } n_i := 3 \mbox{ für } i = 1,...,p \mbox{, also } n = 12.
\end{equation}
Dann gilt
\begin{equation}
y = X\beta + \varepsilon \mbox{ mit } \varepsilon \sim N(0_{12},\sigma^2 I_{12})
\end{equation}
mit
\footnotesize
\begin{equation}
y :=
\begin{pmatrix}
y_{11} 	\\
y_{12} 	\\
y_{13}  \\
y_{21} 	\\
y_{22} 	\\
y_{23}  \\
y_{31} 	\\
y_{32} 	\\
y_{33}  \\
y_{41} 	\\
y_{42} 	\\
y_{43}
\end{pmatrix},
\,
X :=
\begin{pmatrix}
1  & 	0	 &  0	 &  0  \\
1  &  0  &  0  &  0  \\
1  & 	0	 &	0  &  0  \\
1  & 	1	 &	0  & 	0  \\
1  & 	1  &	0  & 	0  \\
1  & 	1  &	0	 & 	0  \\
1	 & 	0	 &	1  & 	0  \\
1  &	0  &  1	 & 	0  \\
1  &	0	 &  1	 & 	0  \\
1  & 	0	 &  0  & 	1  \\
1  & 	0  &	0	 & 	1  \\
1  &	0	 &	0  & 	1  \\
\end{pmatrix}
\in \mathbb{R}^{12 \times 4},
\,
\beta :=
\begin{pmatrix}
\mu_0 		\\
\alpha_2	\\
\alpha_3	\\
\alpha_4	\\
\end{pmatrix}
\in \mathbb{R}^{4}
\mbox{ und }
\sigma^2 > 0.
\end{equation}

# Modellformulierung
\vspace{2mm}
\textcolor{darkblue}{Beispiel}
\vspace{1mm}
\tiny
\setstretch{1}

```{r}
# Modellformulierung
library(MASS)                                             # Multivariate Normalverteilung
m      = 3                                                # Anzahl von Datenpunkten der iten Gruppe
p      = 4                                                # Anzahl Gruppen
n      = p*m                                              # Gesamtanzahl Datenpunkte
Xt     = cbind(                                           # Designmatrix
         matrix(1,nrow = n, ncol = 1),
         kronecker(diag(p), matrix(1,nrow = m,ncol = 1)))
X      = Xt[,-2]
I_n    = diag(n)                                          # n x n Einheitsmatrix
beta   = matrix(c(1,2), nrow = p)                         # \beta = (\mu_0,\alpha_2,\alpha_3,\alpha_4)
sigsqr = 14                                               # \sigma^2

# Datenrealisierung
y      = mvrnorm(1, X %*% beta, sigsqr*I_n)               # eine Realisierung eines n-dimensionalen ZVs
```

```{r, echo = F}
print(X)
```


#
\large
\setstretch{2.7}
\vfill
Anwendungsszenario

Modellformulierung

**Modellschätzung**

Modellevaluation

Selbstkontrollfragen
\vfill

# Modellschätzung
\footnotesize
\begin{theorem}[Betaparameterschätzung im EVA Modell]
\justifying
\normalfont
Gegeben sei die Designmatrixform des EVA in Effektdarstellung mit Referenzgruppe
Dann ergibt sich für den Betaparameterschätzer
\begin{equation}
\hat{\beta}
:= \begin{pmatrix} \hat{\mu}_0 \\ \hat{\alpha}_2        \\ \vdots \\ \hat{\alpha}_p \end{pmatrix}
= \begin{pmatrix} \bar{y}_1   \\ \bar{y}_2 - \bar{y}_1 \\ \vdots \\ \bar{y}_p - \bar{y}_1  \end{pmatrix}
\end{equation}
wobei
\begin{equation}
\bar{y}_i := \frac{1}{n_i}\sum_{j=1}^{n_i}y_{ij}
\end{equation}
das Stichprobenmittel der $i$ten Gruppe bezeichent.
\end{theorem}
Bemerkungen

* \justifying Der Erwartungswertparameter der ersten Gruppe  wird durch das
   Stichprobenmittel der ersten Gruppe geschätzt; der Effektparameter der $i$ten
   Gruppe wird durch die Differenz des Stichprobenmittels der $i$ten und der
   ersten Gruppe geschätzt. Die Beziehung zwischen dem Varianzparameterschätzer
   $\hat{\sigma}^2$ und dem Konzept der gepoolten Stichprobenvarianz betrachten
   wir an dieser Stelle nicht genauer.


# Modellschätzung
\footnotesize
\vspace{2mm}
\underline{Beweis}

Wir halten zunächst fest, dass

\tiny
\begin{align*}
\begin{split}
X^T X
& =
\setcounter{MaxMatrixCols}{20}
\begin{pmatrix}
1 & \cdots & 1 & 1 & \cdots & 1 & & \cdots & & 1 & \cdots & 1  	\\
0 & \cdots & 0 & 1 & \cdots & 1 & & \cdots & & 0 & \cdots & 0  	\\
  & \vdots &   &   & \vdots &   & & \vdots & &   & \vdots &   	\\
0 & \cdots & 0 & 0 & \cdots & 0 & & \cdots & & 1 & \cdots & 1  	\\
\end{pmatrix}
\begin{pmatrix}
1 		  & 	0	    	& 			  & 	0 		\\
\vdots 	&  	\vdots	&	\cdots	& 	\vdots 	\\
1 	   	& 	0		    &			    & 	0 		\\
1 		  & 	1		    &			    & 	0 		\\
\vdots 	& 	\vdots	&	\cdots	& 	\vdots 	\\
1 		  & 	1 		  &			    & 	0 		\\
 		    & 			    &			    & 	 		\\
\vdots 	& 	\vdots	&	\cdots	& 	\vdots 	\\
 		    &  			    &			    & 	 		\\
1 	  	& 	0		    &			    & 	1 		\\
\vdots 	& 	\vdots	&	\cdots	& 	\vdots 	\\
1 		  & 	0 		  &			    & 	1 		\\
\end{pmatrix} \\
& =
\begin{pmatrix}
n 		& n_2 		& n_3 		& 	\cdots 	& n_p 		\\
n_2 	& n_2 		& 0 		&	\cdots 	& 0 		\\
n_3 	& 0 		& n_3 		& 	\cdots  & 0			\\
\vdots 	& \vdots	& \vdots	&	\ddots 	& \vdots	\\
n_p		& 0 		& 0 		&	\cdots  & n_p  		\\
\end{pmatrix}.
\end{split}
\end{align*}

# Modellschätzung
\footnotesize
\underline{Beweis (fortgeführt)}

Die Inverse von $X^TX$ ist
\begin{equation}
\renewcommand{\arraystretch}{1.5}
(X^TX)^{-1} =
\begin{pmatrix*}[c]
   \frac{1}{n_1}
& -\frac{1}{n_1}
& \cdots
& -\frac{1}{n_1}
\\
  -\frac{1}{n_1}
& \frac{n_1+n_2}{n_1 n_2}
& \cdots
& \frac{1}{n_1}
\\
  \vdots
& \vdots
& \ddots
& \vdots
\\
 -\frac{1}{n_1}
& \frac{1}{n_1}
& \cdots
& \frac{n_1+n_p}{n_1 n_p}
\end{pmatrix*}.
\end{equation}
So gilt zum Beispiel für $p = 3$, dass
\begin{equation}
X^T X
=
\begin{pmatrix}
n 		& n_2 	& n_3    		\\
n_2 	& n_2 	& 0 	 	   	\\
n_3 	& 0 		& n_3 			\\
\end{pmatrix}
\mbox{ und }
\renewcommand{\arraystretch}{1.5}
(X^TX)^{-1} =
\begin{pmatrix*}[r]
   \frac{1}{n_1}
& -\frac{1}{n_1}
& -\frac{1}{n_1}
\\
  -\frac{1}{n_1}
& \frac{n_1+n_2}{n_1 n_2}
& \frac{1}{n_1}
\\
  -\frac{1}{n_1}
& \frac{1}{n_1}
& \frac{n_1+n_3}{n_1 n_3}
\end{pmatrix*}.
\end{equation}

# Modellschätzung
\footnotesize
\underline{Beweis (fortgeführt)}


Wir halten weiterhin fest, dass
\tiny
\begin{align}
\begin{split}
\renewcommand{\arraystretch}{1}
X^Ty
& =
\setcounter{MaxMatrixCols}{20}
\begin{pmatrix}
1 & \cdots & 1 & 1 & \cdots & 1 & & \cdots & & 1 & \cdots & 1  	\\
0 & \cdots & 0 & 1 & \cdots & 1 & & \cdots & & 0 & \cdots & 0  	\\
  & \vdots &   &   & \vdots &   & & \vdots & &   & \vdots &   	\\
0 & \cdots & 0 & 0 & \cdots & 0 & & \cdots & & 1 & \cdots & 1  	\\
\end{pmatrix}
\begin{pmatrix*}[c]
y_{11} 	\\ 	\vdots 	\\ y_{1n_1}
\\
y_{21} 	\\ 	\vdots 	\\ y_{2n_2}
\\		\\ 	\vdots 	\\
\\
y_{p1} 	\\ 	\vdots 	\\ y_{pn_p}
\end{pmatrix*}
\\
& =
\begin{pmatrix}
\sum_{i=1}^p \sum_{j=1}^{n_i} y_{ij} 	\\
\sum_{j=1}^{n_2} y_{2j}					\\
\vdots									\\
\sum_{j=1}^{n_p} y_{pj}					\\
\end{pmatrix}.
\end{split}
\end{align}

# Modellschätzung
\vspace{2mm}
\footnotesize
\underline{Beweis (fortgeführt)}

Es ergibt sich also
\tiny
\begin{equation}
\renewcommand{\arraystretch}{2}
\hat{\beta}
= (X^T X)^{-1}X^Ty
=
\begin{pmatrix*}[c]
   \frac{1}{n_1}
& -\frac{1}{n_1}
& \cdots
& -\frac{1}{n_1}
\\
  -\frac{1}{n_1}
& \frac{n_1+n_2}{n_1 n_2}
& \cdots
& \frac{1}{n_1}
\\
  \vdots
& \vdots
& \ddots
& \vdots
\\
 -\frac{1}{n_1}
& \frac{1}{n_1}
& \cdots
& \frac{n_1+n_p}{n_1 n_p}
\end{pmatrix*}
\begin{pmatrix}
\sum_{i=1}^p \sum_{j=1}^{n_i} y_{ij} 	\\
\sum_{j=1}^{n_2} y_{2j}					\\
\vdots									\\
\sum_{j=1}^{n_p} y_{pj}					\\
\end{pmatrix}.
\end{equation}
\footnotesize
Für die erste Komponente von $\hat{\beta}$ ergibt sich damit
\tiny
\begin{align}
\begin{split}
\hat{\beta}_1
& =
\frac{1}{n_1}\sum_{i=1}^p \sum_{j=1}^{n_i} y_{ij}
- \frac{1}{n_1}\sum_{j=1}^{n_2} y_{2j}
- \cdots
- \frac{1}{n_1}\sum_{j=1}^{n_p} y_{pj}
\\
& =
\frac{1}{n_1}
\left(
\left(
  \sum_{j=1}^{n_1} y_{1j}
+ \sum_{j=1}^{n_2} y_{2j}
+ \cdots
+ \sum_{j=1}^{n_p} y_{pj}
\right)
- \sum_{j=1}^{n_2} y_{2j}
- \cdots
- \sum_{j=1}^{n_p} y_{pj}
\right)
\\
& = \frac{1}{n_1}\sum_{j=1}^{n_1} y_{1j}
\\
&
= \bar{y}_1.
\end{split}
\end{align}

# Modellschätzung
\footnotesize
\vspace{2mm}
\underline{Beweis (fortgeführt)}

Für die zweite Komponente von $\hat{\beta}$ und analog für alle weiteren ergibt sich
\tiny
\begin{align}
\begin{split}
\hat{\beta}_2
& =
- \frac{1}{n_1} 		   \sum_{i=1}^p \sum_{j=1}^{n_i} y_{ij}
+ \frac{n_1 + n_2}{n_1n_2} \sum_{j=1}^{n_2} y_{2j}
+ \frac{1}{n_1} 		   \sum_{j=1}^{n_3} y_{3j}
+ \cdots
+  \frac{1}{n_1} 		   \sum_{j=1}^{n_p} y_{pj}
\\
& =
\frac{n_1 + n_2}{n_1n_2} \sum_{j=1}^{n_2} y_{2j}
-\frac{1}{n_1}
\left(
\left(
 \sum_{j=1}^{n_1} y_{1j}
+ \sum_{j=1}^{n_2} y_{2j}
+ \cdots
+ \sum_{j=1}^{n_p} y_{pj}
\right)
- \sum_{j=1}^{n_3} y_{3j}
- \cdots
- \sum_{j=1}^{n_p} y_{pj}
\right)
\\
& =
 \frac{n_1 + n_2}{n_1n_2} \sum_{j=1}^{n_2} y_{2j}
-\frac{1}{n_1}            \sum_{j=1}^{n_1} y_{1j}
-\frac{1}{n_1}            \sum_{j=1}^{n_2} y_{2j}
\\
& =
 \frac{n_1+n_2}{n_1n_2} \sum_{j=1}^{n_2} y_{2j}
-\frac{n_2}{n_1n_2}     \sum_{j=1}^{n_2} y_{2j}
-\frac{1}{n_1}          \sum_{j=1}^{n_1} y_{1j}
\\
& =
 \frac{n_1}{n_1n_2} \sum_{j=1}^{n_2} y_{2j}
-\frac{1}{n_1}          \sum_{j=1}^{n_1} y_{1j}
\\
& =
 \frac{1}{n_2} \sum_{j=1}^{n_2} y_{2j}
-\frac{1}{n_1} \sum_{j=1}^{n_1} y_{1j}
= \bar{y}_2 - \bar{y}_1.
\end{split}
\end{align}



# Modellschätzung
\tiny
\vspace{2mm}
\setstretch{.8}
```{r}
# Dateneinlesen
fname      = file.path(getwd(), "10_Daten", "10_Einfaktorielle_Varianzanalyse_Daten.csv")
D          = read.table(fname, sep = ",", header = TRUE)

# Datengruppen
y_1        = D$BDI[D$Condition == "F2F"]                        # BDI Differenzwerte in der F2F Gruppe
y_2        = D$BDI[D$Condition == "ONL"]                        # BDI Differenzwerte in der ONL Gruppe
y_3        = D$BDI[D$Condition == "WLC"]                        # BDI Differenzwerte in der ONL Gruppe

# Modellformulierung
p          = 3                                                  # drei Gruppen
m          = length(y_1)                                        # balancierters Design mit n_i = 40
n          = p*m                                                # Datenvektordimension
y          = matrix(c(y_1, y_2, y_3), nrow = n)                 # Datenvektor
Xt         = cbind(                                             # Designmatrix
             matrix(1, nrow = n, ncol = 1),
             kronecker(diag(p), matrix(1, nrow = m, ncol = 1)))
X          = Xt[,-2]

# Modellschätzung
beta_hat   = solve(t(X) %*% X) %*% t(X) %*% y                   # Betaparameterschätzer
eps_hat    = y - X %*% beta_hat                                 # Residuenvektor
sigsqr_hat = (t(eps_hat) %*% eps_hat) /(n-p)                    # Varianzparameterschätzer
s_sqr_123 = ((m-1)*var(y_1) +                                   # gepoolte Stichprobenvarianz
             (m-1)*var(y_2) +
             (m-1)*var(y_3))/(m+m+m-p)

# Ausgabe
cat("hat{beta}                                    : "  , beta_hat,
    "\nbar{y}_1,bar{y}_2,bar{y}_3                   : ", c(mean(y_1),mean(y_2),mean(y_3)),
    "\nbar{y}_1,bar{y}_2-bar{y}_1,bar{y}_3-bar{y}_1 : ", c(mean(y_1),mean(y_2)-mean(y_1),mean(y_3)-mean(y_1)),
    "\nhat{sigsqr}                                  : ", sigsqr_hat,
    "\ns_123^2                                      : ", s_sqr_123,
    "\ns_y^2                                        : ", var(y))
```

#
\large
\setstretch{2.7}
\vfill
Anwendungsszenario

Modellformulierung

Modellschätzung

**Modellevaluation**

Selbstkontrollfragen
\vfill

# Modellevaluation
\small
\textcolor{darkblue}{Vorbemerkungen und Überblick}

\footnotesize
Prinzipiell sind alle Parameterschätzwerte in einem EVA Modell von Interesse;
mit der T-Teststatistik können einzelne oder lineare Kombinationen der 
Betaparameterschätzwerte im Sinne von Hypothesentests evaluiert werden.

Nichtsdestotrotz steht im EVA Szenario häufig die Evaluation der Nullhypothese, dass
alle Effektparameter gleich Null sind im Vordergrund. Intuitiv besagt diese Nullhypothese,
dass die wahren, aber unbekannten, Erwartungswertparameter aller Gruppen identisch sind,
formal haben wir
\begin{equation}
H_0 : \alpha_i = 0 \mbox{ für alle } i = 1,...,p \Leftrightarrow \Theta_0 := \mathbb{R} \times \{0_{p-1}\}
\end{equation}
und
\begin{equation}
H_1 : \alpha_i \neq 0 \mbox{ für mindestens ein } i = 1,...,p \Leftrightarrow \Theta_1 := \mathbb{R}^p \setminus \mathbb{R} \times \{0_{p-1}\}
\end{equation}
Zur Überprüfung von $H_0$ wird im Allgemeinen eine $F$-Teststatistik eingesetzt. 

Im Folgenden entwickeln wir zunächst diese $F$-Teststatistik anhand einer 
*Quadratsummenzerlegung* der Datenvariabilität in einem EVA Szenario und betrachten 
in diesem Zusammenhang auch das dem $R^2$ analoge  Maß  $\eta^2$ der Effektstärke 
im EVA Szenario. Ausgestattet mit der speziellen Form der $F$-Teststatistik in 
dem hier betrachteten Szenario diskutieren wir dann den traditionellen EVA 
Hypothesentest. Wir verzichten auf eine Analyse der Testgütefunktion und eine
Diskussion der Powerfunktion.

# Modellevaluation
\footnotesize
\setstretch{1.2}
\begin{theorem}[Quadratsummenzerlegung bei einfaktorieller Varianzanalyse]
\justifying
\normalfont
Für $i = 1,...,p$ und $j = 1,...,n_i$ sei $y_{ij}$ die $j$te Datenvariable in der
$i$ten Gruppe eines EVA Szenarios. Weiterhin seien
\center
\vspace{1mm}
\begin{tabular}{ll}
$\bar{y} := \frac{1}{n}\sum_{i=1}^p \sum_{j=1}^{n_i} y_{ij}$         & das \textit{Gesamtstichprobenmittel}  \\\\
$\bar{y}_i =\frac{1}{n_i}\sum_{j=1}^{n_i} y_{ij}$                    & das \textit{$i$te Stichprobenmittel}  \\\\
\end{tabular}
\vspace{1mm}
\flushleft
sowie

\center
\vspace{1mm}
\begin{tabular}{ll}
$\mbox{SQT} := \sum_{i=1}^p \sum_{j=1}^{n_i} (y_{ij}-\bar{y})^{2}$   & die \textit{Total Sum of Squares}   \\\\
$\mbox{SQB} := \sum_{i=1}^p n_i(\bar{y}_i-\bar{y})^{2}$              & die \textit{Between Sum of Squares} \\\\
$\mbox{SQW} := \sum_{i=1}^p \sum_{j=1}^{n_i} (y_{ij}-\bar{y}_i)^{2}$ & die \textit{Within Sum of Squares}  \\\\
\end{tabular}
\vspace{1mm}
\flushleft
Dann gilt
\begin{equation}
\mbox{SQT} = \mbox{SQB} + \mbox{SQW}.
\end{equation}
\end{theorem}
\vspace{-2mm}
Bemerkung

* \justifying In Analogie zur Quadratsummenzerlegung bei einer Ausgleichsgerade
(vgl. Einheit (3) Korrelation) wird die *Within Sum of Squares* auch als
*Residual Sum of Squares* bezeichnet.

# Modellevaluation
\footnotesize
\underline{Beweis}

Es gilt
\tiny
\begin{align}
\begin{split}
\mbox{SQT}
& = \sum_{i=1}^p \sum_{j=1}^{n_i}(y_{ij}-\bar{y})^{2}
\\
& = \sum_{i=1}^p \sum_{j=1}^{n_i} (y_{ij}-\bar{y}_i+\bar{y}_i-\bar{y})^2
\\
& = \sum_{i=1}^p \sum_{j=1}^{n_i} \left((y_{ij}-\bar{y}_i)+(\bar{y}_i-\bar{y}) \right)^2
\\
& = \sum_{i=1}^p \sum_{j=1}^{n_i} \left(
									(y_{ij}-\bar{y}_i)^2
								  +2(y_{ij}-\bar{y}_i)(\bar{y}_i-\bar{y})
				    		      +(\bar{y}_i-\bar{y})^2 \right)
\\
& = \sum_{i=1}^p \left(\sum_{j=1}^{n_i} (y_{ij}-\bar{y}_i)^2
   			          +\sum_{j=1}^{n_i}  2(y_{ij}-\bar{y}_i)(\bar{y}_i-\bar{y})
					  +\sum_{j=1}^{n_i} (\bar{y}_i-\bar{y})^2 \right)
\end{split}
\end{align}

# Modellevaluation
\footnotesize
\underline{Beweis (fortgeführt)}

und weiter
\tiny
\begin{align*}
\begin{split}
\mbox{SQT}
& = \sum_{i=1}^p \left(\sum_{j=1}^{n_i} (y_{ij}-\bar{y}_i)^2
					 +2(\bar{y}_i-\bar{y})\sum_{j=1}^{n_i}(y_{ij}-\bar{y}_i)
					   +n_i(\bar{y}_i-\bar{y})^2 \right)
\\
& =\sum_{i=1}^p \left(\sum_{j=1}^{n_i} (y_{ij}-\bar{y}_i)^2
  				 +2(\bar{y}_i-\bar{y})\sum_{j=1}^{n_i} \left(y_{ij}-\frac{1}{n_i}\sum_{j=1}^{n_i}{y_{ij}}\right)
				 +n_i(\bar{y}_i-\bar{y})^2 \right)
\\
& =\sum_{i=1}^p \left(\sum_{j=1}^{n_i} (y_{ij}-\bar{y}_i)^2
									   +2(\bar{y}_i-\bar{y})\left(\sum_{j=1}^{n_i} y_{ij}-\sum_{j=1}^{n_i}\left(\frac{1}{n_i}\sum_{j=1}^{n_i}{y_{ij}}\right)\right)
									    +n_i(\bar{y}_i-\bar{y})^2 \right)
\\
& =\sum_{i=1}^p \left(\sum_{j=1}^{n_i} (y_{ij}-\bar{y}_i)^2
									   +2(\bar{y}_i-\bar{y})\left(\sum_{j=1}^{n_i} y_{ij}-\frac{n_i}{n_i}\sum_{j=1}^{n_i}{y_{ij}}\right)
									    +n_i(\bar{y}_i-\bar{y})^2 \right)
\end{split}
\end{align*}

# Modellevaluation
\footnotesize
\underline{Beweis (fortgeführt)}

und weiter
\tiny
\begin{align}
\begin{split}
\mbox{SQT}
& =\sum_{i=1}^p \left(\sum_{j=1}^{n_i} (y_{ij}-\bar{y}_i)^2
									   +2(\bar{y}_i-\bar{y})\left(\sum_{j=1}^{n_i} y_{ij}-\sum_{j=1}^{n_i}{y_{ij}}\right)
									    +n_i(\bar{y}_i-\bar{y})^2 \right) \\
& =\sum_{i=1}^p \left(\sum_{j=1}^{n_i} (y_{ij}-\bar{y}_i)^2 +n_i(\bar{y}_i-\bar{y})^2 \right)
\\
& =\sum_{i=1}^p \sum_{j=1}^{n_i} (y_{ij}-\bar{y}_i)^2  + \sum_{i=1}^p n_i(\bar{y}_i-\bar{y})^2
\\
& = \mbox{SQW} + \mbox{SQB}
\end{split}
\end{align}
\footnotesize

und damit direkt
\begin{equation}
\mbox{SQT}  = \mbox{SQB} + \mbox{SQW}.
\end{equation}

# Modellevaluation
\footnotesize

\begin{definition}[Effektstärkenmaß $\eta^2$]
\justifying
Für ein EVA Szenario seien die Between Sum of Squares $\mbox{SQB}$ und die
Total Sum of Squares $\mbox{SQT}$ definiert wie oben. Dann ist das \textit{Effektstärkenmaß}
$\eta^2$ definiert als
\begin{equation}
\eta^2 := \frac{\mbox{SQB}}{\mbox{SQT}}
\end{equation}
\end{definition}
\vspace{-1mm}
Bemerkungen

* $\eta^2$ ist analog zum Bestimmtheitsmaß $R^2$ der Regression definiert.
* $\eta^2$ gibt den Anteil der Varianz zwischen den Gruppen an der Gesamtvarianz der Daten an.
* Mit dem Theorem zur Quadratsummenzerlegung bei EVA folgt sofort $0 \le \eta^2 \le 1$, da
\begin{align}
\begin{split}
\mbox{SQB} & = 0 \Rightarrow \mbox{SQT} = \mbox{SQW und } \eta^2 = 0 \\
\mbox{SQW} & = 0 \Rightarrow \mbox{SQT} = \mbox{SQB und } \eta^2 = 1
\end{split}
\end{align}



# Modellevaluation
\footnotesize
\begin{theorem}[F-Teststatistik]
\justifying
\normalfont
Es sei
\begin{equation}
y = X\beta + \varepsilon \mbox{ mit } \varepsilon \sim N(0_n,\sigma^2I_n)
\end{equation}
die Designmatrixform der Effektdarstellung mit Referenzgruppe des EVA Modells und
im Sinne der Definition der F-Statistik (vgl. Einheit (7) Modellevaluation) sei
dieses Modell partioniert mit $p_1 := 1$ und $p_2 := p - 1$. Weiterhin seien

\center
\vspace{1mm}
\begin{tabular}{ll}
$\mbox{MSB} := \frac{\mbox{SQB}}{p-1}$        & die \textit{Mean Between Sum of Squares} \\\\
$\mbox{MSW} := \frac{\mbox{SQW}}{n-p}$        & die \textit{Mean Within  Sum of Squares} \\\\
\end{tabular}

\flushleft
respektive. Dann gilt
\begin{equation}
F = \frac{\mbox{MSB}}{\mbox{MSW}}.
\end{equation}
\end{theorem}

Bemerkungen

* $p_1 := 1$ impliziert, dass das reduzierte Modell die Designmatrix $X_1 := 1_n$ hat.
* $p_1 := 1$ impliziert zudem, dass das reduzierte Modell den Betaparameter $\beta := \mu_0$ hat.
* $p_1 := 1$ impliziert damit auch, dass das reduzierte Modell keine Effektparameter hat.
* Die Zahl $p-1$ wird auch als "Between Freiheitsgrade" bezeichnet.
* Die Zahl $n-p$ wird auch als "Within  Freiheitsgrade" bezeichnet.



# Modellevaluation
\footnotesize
\underline{Beweis}

Wir halten zunächst fest, dass für den Betaparameterschätzer des reduzierten Modells
gilt, dass
\begin{align}
\begin{split}
\hat{\beta}_1
= (X_1^TX_1)^{-1}X_1^Ty
= (1_n^T 1_n)^{-1}1_n^Ty
= \frac{1}{n} \sum_{i=1}^p \sum_{j = 1}^{n_i} y_{ij}
= \bar{y}.
\end{split}
\end{align}
Weiterhin ergibt sich
\begin{align}
\begin{split}
\hat{\varepsilon}_1^T \hat{\varepsilon}_1
= (y - X_1\hat{\beta}_1)^T(y - X_1\hat{\beta}_1)
= (y - 1_n\bar{y})^T(y - 1_n\bar{y})
= \sum_{i=1}^p \sum_{j=1}^{n_i} (y_{ij} - \bar{y})^2
= \mbox{SQT}.
\end{split}
\end{align}



Der Betaparameterschätzer des vollständigen Modells ergibt sich wie oben gesehen zu
\tiny
\begin{equation}
\renewcommand{\arraystretch}{1.4}
\hat{\beta} =
\begin{pmatrix}
\hat{\mu}_0		\\
\hat{\alpha}_2	\\
\vdots			\\
\hat{\alpha}_m
\end{pmatrix}
=
\begin{pmatrix}
 \frac{1}{n_1}\sum_{j=1}^{n_1} y_{1j} 	\\
 \frac{1}{n_2}\sum_{j=1}^{n_2} y_{2j}
-\frac{1}{n_1}\sum_{j=1}^{n_1} y_{1j} 	\\
\vdots \\
 \frac{1}{n_m}\sum_{j=1}^{n_m} y_{mj}
-\frac{1}{n_1}\sum_{j=1}^{n_1} y_{1j} 	\\
\end{pmatrix}
=
\begin{pmatrix}
\bar{y}_1								\\
\bar{y}_2 - \bar{y}_1					\\
\vdots 									\\
\bar{y}_p - \bar{y}_1					\\
\end{pmatrix},
\end{equation}
\footnotesize
so dass

# Modellevaluation
\footnotesize
\underline{Beweis (fortgeführt)}

\tiny
\begin{align*}
\renewcommand{\arraystretch}{.8}
\begin{split}
\hat{\varepsilon}^T\hat{\varepsilon}
= & (y - X\hat{\beta})^T(y - X\hat{\beta}) \\
= &
\left(
\begin{pmatrix}
y_{11}			\\
\vdots			\\
y_{1n_1}		\\
y_{21}			\\
\vdots			\\
y_{2n_2}		\\
				\\
\vdots			\\
				\\
y_{p1}			\\
\vdots			\\
y_{pn_p}		\\
\end{pmatrix}
-
\begin{pmatrix}
1 		& 	0		& 			& 	0 		\\
\vdots 	&  	\vdots	&	\cdots	& 	\vdots 	\\
1 		& 	0		&			& 	0 		\\
1 		& 	1		&			& 	0 		\\
\vdots 	& 	\vdots	&	\cdots	& 	\vdots 	\\
1 		& 	1 		&			& 	0 		\\
 		& 			&			& 	 		\\
\vdots 	& 	\vdots	&	\cdots	& 	\vdots 	\\
 		&  			&			& 	 		\\
1 		& 	0		&			& 	1 		\\
\vdots 	& 	\vdots	&	\cdots	& 	\vdots 	\\
1 		& 	0 		&			& 	1 		\\
\end{pmatrix}
\begin{pmatrix}
\bar{y}_1								\\
\bar{y}_2 - \bar{y}_1					\\
\vdots 									\\
\bar{y}_p - \bar{y}_1					\\
\end{pmatrix}
\right)^T
(y - X\hat{\beta})
\end{split}
\end{align*}

# Modellevaluation
\footnotesize
\underline{Beweis (fortgeführt)}

und weiter
\tiny
\begin{align*}
\begin{split}
\hat{\varepsilon}^T\hat{\varepsilon}
& =
\begin{pmatrix}
y_{11}	 - \bar{y}_1							\\
\vdots											\\
y_{1n_1} - \bar{y}_1							\\
y_{21}	 - \bar{y}_1 - \bar{y}_2 + \bar{y}_1	\\
\vdots			\\
y_{2n_2} - \bar{y}_1 - \bar{y}_2 + \bar{y}_1	\\
				\\
\vdots			\\
				\\
y_{p1}	 - \bar{y}_1 - \bar{y}_p + \bar{y}_1	\\
\vdots			\\
y_{pn_p}  - \bar{y}_1 - \bar{y}_p + \bar{y}_1	\\
\end{pmatrix}^T
\begin{pmatrix}
y_{11}	 - \bar{y}_1							\\
\vdots											\\
y_{1n_1} - \bar{y}_1							\\
y_{21}	 - \bar{y}_1 - \bar{y}_2 + \bar{y}_1	\\
\vdots			\\
y_{2n_2} - \bar{y}_1 - \bar{y}_2 + \bar{y}_1	\\
				\\
\vdots			\\
				\\
y_{p1}	 - \bar{y}_1 - \bar{y}_p + \bar{y}_1	\\
\vdots			\\
y_{pn_p}  - \bar{y}_1 - \bar{y}_p + \bar{y}_1	\\
\end{pmatrix}
=
\begin{pmatrix}
y_{11}	 - \bar{y}_1	\\
\vdots					\\
y_{1n_1} - \bar{y}_1	\\
y_{21}	 - \bar{y}_2 	\\
\vdots					\\
y_{2n_2} - \bar{y}_2 	\\
						\\
\vdots					\\
						\\
y_{p1}	 - \bar{y}_p 	\\
\vdots			\\
y_{pn_p} - \bar{y}_p	\\
\end{pmatrix}^T
\begin{pmatrix}
y_{11}	 - \bar{y}_1	\\
\vdots					\\
y_{1n_1} - \bar{y}_1	\\
y_{21}	 - \bar{y}_2 	\\
\vdots					\\
y_{2n_2} - \bar{y}_2 	\\
						\\
\vdots					\\
						\\
y_{p1}	 - \bar{y}_p 	\\
\vdots			\\
y_{pn_p} - \bar{y}_p	\\
\end{pmatrix}
\\
& = \sum_{i=1}^p \sum_{j = 1}^{n_i} (y_{ij} - \bar{y}_i)^2 \\
& = \mbox{SQW}.
\end{split}
\end{align*}

# Modellevaluation
\footnotesize
\underline{Beweis (fortgeführt)}

Mit dem Theorem zur Quadratsummenzerlegung bei einfaktorieller Varianzanalyse
\begin{equation}
\mbox{SQT}  =  \mbox{SQB} +  \mbox{SQW} \Leftrightarrow \mbox{SQB} = \mbox{SQT} - \mbox{SQW}
\end{equation}
folgt sofort, dass
\begin{align}
\begin{split}
\mbox{SQB}
& = \mbox{SQT} - \mbox{SQW} \\
& = \hat{\varepsilon}_1^T\hat{\varepsilon}_1 - \hat{\varepsilon}^T\hat{\varepsilon}.
\end{split}
\end{align}
Dann aber folgt auch direkt, dass
\begin{align}
\begin{split}
\frac{\mbox{MSB}}{\mbox{MSW}}
& = \frac{\frac{\mbox{SQB}}{p-1}}
       {\frac{\mbox{SQW}}{n-p}}
\\
& = \frac{\frac{\hat{\varepsilon}_1^T\hat{\varepsilon}_1 - \hat{\varepsilon}^T\hat{\varepsilon}}{p-1}}
       {\frac{\hat{\varepsilon}^T\hat{\varepsilon}}{n-p}}
\\
& =  F
\end{split}
\end{align}

# Modellevaluation
\footnotesize

\begin{theorem}[Effektstärkenmaß $\eta^2$ und F-Teststatistik]
\justifying
\normalfont
Für ein EVA Szenario mit $p$ Gruppen und Gesamtdatenpunktanzahl $n$ seien das 
Effektstärkenmaß $\eta^2$ und die $F$-Teststatistik wie oben definiert. Dann gilt
\begin{equation}
\eta^2 = \frac{F(p-1)}{F(p-1) + (n-p)}
\end{equation}
\end{theorem}



Bemerkungen

* Das Verhältnis von $F$ und $\eta^2$ ist Analog zum Verhältnis von $T$ und Cohen's $d$.
* Die gleichzeitige Angabe von $F$ und $\eta^2$ ist redundant.

# Modellevaluation
\footnotesize
\setstretch{1}
\underline{Beweis}

Wir halten zunächst fest, dass
\begin{equation}
F = \frac{\mbox{SQB}}{\mbox{SQW}}\cdot \frac{n-p}{p-1} 
\Leftrightarrow 
\mbox{SQB} = \frac{p-1}{n-p}\cdot \mbox{SQW} \cdot F
\end{equation}
Damit folgt dann
\begin{align}
\begin{split}
\eta^2
  = \frac{\mbox{SQB}}{\mbox{SQT}}  
  = \frac{\mbox{SQB}}{\mbox{SQB}+\mbox{SQW}}  
  = \frac{\frac{p-1}{n-p}\cdot \mbox{SQW} \cdot F}{\frac{p-1}{n-p}\cdot \mbox{SQW} \cdot F +\mbox{SQW}}  
& = \frac{\frac{F(p-1)}{n-p}\cdot \mbox{SQW} }{\frac{F(p-1)}{n-p}\cdot \mbox{SQW}  +\mbox{SQW}} \\
& = \frac{\frac{F(p-1)}{n-p}\cdot \mbox{SQW} }{\left(\frac{F(p-1)}{n-p} + 1 \right)\cdot \mbox{SQW}} \\
& = \frac{\frac{F(p-1)}{n-p}}{\frac{F(p-1)}{n-p} + \frac{n-p}{n-p}} \\
& = \frac{\frac{F(p-1)}{n-p}}{\frac{F(p-1) + (n-p)}{n-p}} \\
& = \frac{F(p-1)}{F(p-1)+(n-p)}
\end{split}
\end{align}



# Modellevaluation
\setstretch{1.8}
\textcolor{darkblue}{Gliederung (vgl. WTFI Einheiten (12) - (14))}

(1) Statistisches Modell \checkmark

(2) Testhypothesen \checkmark

(3) Teststatistik  \checkmark

(4) Test

(5) Testumfangkontrolle

(6) p-Werte


# Modellevaluation
\noindent (4) Test

\footnotesize
\begin{definition}[Einfaktorielle Varianzanalyse F-Test]
\justifying
Gegeben sie das Modell der einfaktoriellen Varianzanalyse sowie die zusammengesetzten
Null- und Alternativhypothesen
\begin{equation}
H_0 : \alpha_i = 0 \mbox{ für alle } i = 1,...,p \Leftrightarrow \Theta_0 := \mathbb{R} \times \{0_{p-1}\}
\end{equation}
und
\begin{equation}
H_1 : \alpha_i \neq 0 \mbox{ für mindestens ein } i = 1,...,p \Leftrightarrow \Theta_1 := \mathbb{R}^p \setminus \mathbb{R} \times \{0_{p-1}\}
\end{equation}
respektive. Weiterhin sei die F-Teststatistik definiert durch
\begin{equation}
F = \frac{\mbox{MSB}}{\mbox{MSW}}
\end{equation}
mit der Mean Sum of Squares Between $\mbox{MSB}$ und der Mean Sum of Square Within
$\mbox{MSW}$ definiert wie oben. Dann ist der \textit{einfaktoriellen Varianzanalyse F-Test (EVA F-Test)} 
definiert als der kritische Wert-basierte Test
\begin{equation}
\phi(y) := 1_{\{F \ge k\}} :=
\begin{cases}
1 & F \ge k \\
0 & F < k
\end{cases}.
\end{equation}
\end{definition}


# Modellevaluation
\vspace{2mm}
\noindent (5) Testumfangkontrolle

\footnotesize
\begin{theorem}[Testumfangkontrolle]
\justifying
\normalfont
$\phi$ sei der F-Test zur einfaktoriellen Varianzanalyse. Dann ist $\phi$ ein
Level-$\alpha_0$-Test mit Testumfang $\alpha_0$, wenn der kritische Wert definiert
ist durch
\begin{equation}
k_{\alpha_0} := \varphi^{-1}(1-\alpha_0;p-1, n-p),
\end{equation}
wobei $\varphi^{-1}(\cdot; p-1, n-p)$ die inverse KVF der $f$-Verteilung mit
Freiheitsgradparametern $p-1$ und $n-p$ ist.
\end{theorem}

\center
Wahl von $k_{\alpha_0} := \varphi^{-1}(1 - \alpha_0; p-1, n-p)$ mit $p = 3, n =12$ $\alpha_0 := 0.05$ und Ablehnungsbereich

```{r,echo = F, eval= F}
par(
family      = "sans",
mfcol       = c(1,2),
pty         = "m",
bty         = "l",
lwd         = 1,
las         = 1,
mgp         = c(2,1,0),
xaxs        = "i",
yaxs        = "i",
font.main   = 1,
cex         = 1,
cex.main    = 1.2)

# Parameter
p           = 3                                                                  # Anzahl Gruppen
m           = 12                                                                 # Anzahl experimenteller Einheiten pro Gruppe
n           = p*m                                                                # Gesamtstichprobengröße
alpha_0     = 0.05                                                               # Signifikanzlevel
k_alpha_0   = qf(1 - alpha_0, p-1,n-p)                                           # kritischer Wert
eff         = seq(0,6,length=1e4 )                                               # F-Statistikwerte
Peff        = pf(eff,p-1,n-p)                                                    # F-Statistik KVF für H_0
peff        = df(eff,p-1,n-p)                                                    # F-Statistik WDF für H_0

# KVF Perspektive
plot(                                                                            # original density function
eff,
Peff,
type        = "l",
xlab        = " ",
ylab        = " ",
ylim        = c(0,1),
main        = TeX("$\\varphi(F;2,33)$"))

lines(
k_alpha_0,
0,
type        = "p",
pch         = 16,
xpd         = TRUE)

lines(
min(eff),
1 - alpha_0,
type        = "p",
pch         = 16,
xpd         = TRUE)

arrows(
x0          = min(eff),
y0          = 1 - alpha_0,
x1          = k_alpha_0,
y1          = 1 - alpha_0,
col         = "darkorange",
angle       = 45,
length      = .1)

arrows(
x0          = k_alpha_0,
y0          = 1-alpha_0,
x1          = k_alpha_0,
y1          = 0,
col         = "darkorange",
angle       = 45,
length      = .1)

text(k_alpha_0-.5, .1 , TeX("$\\k_{\\alpha_0}$"), xpd = TRUE)
text(1      , 1 , TeX("$1 - \\alpha_0$"), xpd = TRUE)

# WDF Perspektive
plot(
eff,
peff,
type        = "l",
ylab        = " ",
xlab        = " ",
ylim        = c(0,.4),
main        = TeX("$f(F;2,33)$"))

polygon(
c(eff[eff  >= k_alpha_0] , max(eff), k_alpha_0),
c(peff[eff >= k_alpha_0],       0, 0),
col = "gray90",
border = NA)


lines(
seq(k_alpha_0, max(eff), len = 1e2),
rep(0,1e2),
type        = "l",
lwd         = 5,
col         = "darkorange")

lines(
k_alpha_0,
0,
type        = "p",
pch         = 16,
xpd         = TRUE)

text( k_alpha_0-.5,.03, TeX("$\\k_{\\alpha_0}$") , xpd = TRUE)
text( 5, .05, TeX("$P(F >= k_{\\alpha_0}) = \\alpha_0$"), xpd = TRUE, cex = 1, col = "gray50")

# PDF Speicherung
dev.copy2pdf(
file        = file.path(getwd(), "10_Abbildungen", "alm_10_eva_testumfang.pdf"),
width       = 8,
height      = 4)

```
```{r, echo = FALSE, out.width = "70%"}
knitr::include_graphics("10_Abbildungen/alm_10_eva_testumfang.pdf")
```

# Modellevaluation
\footnotesize
\underline{Beweis}

Die Testgütefunktion des betrachteten Tests im vorliegenden Testszenario ist definiert als
\begin{equation}
q : \mathbb{R} \to [0,1], \beta \mapsto q_\phi(\beta) := \mathbb{P}_\beta(\phi = 1).
\end{equation}
Wir haben in Einheit (7) Modellevaluation gesehen, dass die F-Teststatistik für
$p_2 = p - 1$ nach einer nichtzentralen $f$-Verteilung verteilt ist, 
\begin{equation}
F \sim f(\delta,p-1, n-p).
\end{equation}
Weiterhin ist der Ablehnungsbereich des hier betrachteten Tests gegeben als $[k,\infty[$
Für die funktionale Form der Testgütefunktion ergibt sich also
\begin{align}
\begin{split}
\mathbb{P}_\beta(\phi = 1)
& = \mathbb{P}_\beta(F \in [k,\infty[) \\
& = \mathbb{P}_\beta(F \ge k) \\
& = 1 - \mathbb{P}_\beta(F \le k) \\
& = 1 - \varphi(k;\delta,p-1,n-p),  \\
\end{split}
\end{align}
wobei $\varphi(k;\delta,p-1,n-p)$ den Wert der KVF der nichtzentralen $f$-Verteilung
an der Stelle $k$ und mit Nichtzentralitätsparameter $\delta$ sowie Freiheitsgradparametern
$p-1$ und $n-p$ bezeichnet (vgl. Einheit (7) Modellevaluation).

Damit der betrachtete Test ein Level-$\alpha_0$-Test ist, muss bekanntlich gelten, dass
\begin{equation}
q_\phi(\beta) \le \alpha_0 \mbox{ für alle } \beta \in \Theta_0 \mbox{ mit } \Theta_0 = \mathbb{R} \times \{0_{p-1}\}.
\end{equation}

# Modellevaluation
\footnotesize
\underline{Beweis}

Mit der Form des Nichtzentralitätsparameters (vgl. Einheit (7) Modellevaluation) 
gegeben durch
\begin{equation}
\delta = \frac{1}{\sigma^2}K^T\beta\left(K^T(X^TX)^{-1}K\right)^{-1}K^T\beta
\end{equation}
folgt mit $\beta \in \Theta_0$ aus
\begin{equation}
K = \begin{pmatrix} 0 \\ 1_{p-1} \end{pmatrix} \in \mathbb{R}^p \mbox{ und } \beta = \begin{pmatrix} \mu_0 \\ 0_{p-1} \end{pmatrix} \in \mathbb{R}^p 
\end{equation}
dann aber $\delta = 0$ und somit 
\begin{equation}
q_\phi(\beta) = 1 - \varphi(k;p-1,n-p) \mbox{ für alle } \beta \in \Theta_0.
\end{equation}
wobei $\varphi(k;p-1,n-p)$ den Wert der KVF der $f$-Verteilung an der Stelle $k$ mit 
Freiheitsgradparametern $p-1$ und $n-p$ bezeichnet (vgl. Einheit (7) Modellevaluation).
Der Testumfang des betrachteten Tests ergibt sich nach Definition (vgl. WTFI Einheit 
(12) Hypothesentests) als
\begin{equation}
\alpha = \max_{{\beta \in \Theta_0}} q_{\phi}(\beta) = 1 - \varphi(k;p-1,n-p),
\end{equation}
da  $q_{\phi}(\beta)$ für $\beta \in \Theta_0$ nicht von $\mu_0$ abhängt. Wir müssen
also lediglich zeigen, dass die Wahl von $k_{\alpha_0}$ wie im Theorem garantiert,
dass $\phi$ den Testumfang $\alpha_0$ hat. Sei also $k := k_{\alpha_0}$. Dann gilt 
für alle $\beta \in \Theta_0$ 
\begin{equation}
q_\phi(\beta) 
= 1 - \varphi( \varphi^{-1}(1-\alpha_0;p-1, n-p);p-1,n-p)
= 1 - 1-\alpha_0
= \alpha_0
\end{equation}
und damit ist alles gezeigt.

# Modellevaluation
(7) p-Wert

\setstretch{1.2}
\footnotesize
Nach Definition ist der p-Wert das kleinste Signifikanzlevel $\alpha_0$, bei
welchem man die Nullhypothese basierend auf einem vorliegenden Wert der Teststatistik
ablehnen würde. Wir wollen einen vorliegenden Wert der $F$-Teststatistik hier mit $f$
bezeichnen.

Bei $F = f$ würde $H_0$ für jedes $\alpha_0$ mit $f \ge \psi^{-1}(1-\alpha_0;p-1,n-p)$
abgelehnt werden. Für ein solches $\alpha_0$ gilt aber 
\begin{equation}
\alpha_0 \ge \mathbb{P}(F \ge f),
\end{equation}
denn
\begin{align}
\begin{split}
f & \ge \psi^{-1}(1-\alpha_0;p-1,n-p) 
\\\Leftrightarrow
\psi(f;p-1,n-p) & \ge \psi(\psi^{-1}(1-\alpha_0;p-1,n-p), p-1,n-p) 
\\\Leftrightarrow
\psi(f;p-1,n-p) & \ge 1-\alpha_0 
\\\Leftrightarrow
\mathbb{P}(F \le f) & \ge 1-\alpha_0 
\\\Leftrightarrow
\alpha_0  & \ge 1 - \mathbb{P}(F \le f)
\\\Leftrightarrow
\alpha_0  & \ge \mathbb{P}(F \ge f)
\end{split}
\end{align}
Das kleinste $\alpha_0 \in [0,1]$ mit $\alpha_0 \ge \mathbb{P}(F \ge f)$ ist 
dann $\alpha_0 = \mathbb{P}(F \ge f)$, also folgt
\begin{equation}
\mbox{p-Wert} = \mathbb{P}(F \ge f) = 1 - \varphi(f; p-1, n-p).
\end{equation}


# Modellevaluation

Praktisches Vorgehen
\footnotesize

* \justifying Man nimmt an, dass ein vorliegender Datensatz von $p$ Gruppendatensätzen
$\upsilon_{11}, ...,\upsilon_{1n_1}$, $\upsilon_{21}, ...,\upsilon_{2n_2}$, ...,
$\upsilon_{p1}, ...,\upsilon_{pn_p}$ Realisationen von $y_{1j} \sim N(\mu_0,\sigma^2)$
und $y_{ij} \sim N(\mu_0 + \alpha_i,\sigma^2)$ für $i = 2,...,p$ mit unbekannten
Parametern $\mu_0, \alpha_i, i = 2,...,p$ und $\sigma^2>0$ sind.

* Man möchte entscheiden ob $H_0 : \alpha_i = 0$ für alle $i = 2,...,p$ eher zutrifft oder eher nicht.

* Man wählt ein Signifikanzniveau $\alpha_0$ und bestimmt den zugehörigen
Freiheitsgradparameter-abhängigen kritischen Wert $k_{\alpha_0}$. Zum Beispiel gilt
bei Wahl von $\alpha_0 := 0.05, p = 3, m = 12, i = 1,2,3$ und somit $n = 36$, dass
$k_{\alpha_0} = \varphi^{-1}(1 - 0.05; 2, 33) \approx 3.28$ ist.

* Anhand der MSB und MSW berechnet man den realisierten Wert der F-Teststatistik,
den wir hier mit $f$ bezeichnen.

* Wenn $f$ größer gleich $k_{\alpha_0}$ ist, lehnt man die Nullhypothese ab,
andernfalls nicht.

* Die oben entwickelte Theorie garantiert dann, dass man im Mittel in höchstens
$\alpha_0 \cdot 100$ von 100 Fällen die Nullhypothese fälschlicherweise ablehnt.

* Schließlich ergibt sich der assoziierte p-Wert der realisiertern F-Teststatistik
$\tilde{F}$ zu
\begin{equation}
\mbox{p-Wert} = \mathbb{P}(F \ge f) = 1 - \varphi(f; p-1, n-p)
\end{equation}


# Modellevaluation
Anwendungsbeispiel

\tiny
\vspace{1mm}
\setstretch{.9}
```{r}
# Dateneinlesen
fname      = file.path(getwd(), "10_Daten", "10_Einfaktorielle_Varianzanalyse_Daten.csv")
D          = read.table(fname, sep = ",", header = TRUE)

# Datengruppen
y_1        = D$BDI[D$Condition == "F2F"]               # BDI Differenzwerte in der F2F Gruppe
y_2        = D$BDI[D$Condition == "ONL"]               # BDI Differenzwerte in der ONL Gruppe
y_3        = D$BDI[D$Condition == "WLC"]               # BDI Differenzwerte in der ONL Gruppe

# Modellformulierung
p          = 3                                         # drei Gruppen
m          = length(y_1)                               # balancierters Design mit n_i = 40
n          = p*m                                       # Datenvektordimension
y          = matrix(c(y_1, y_2, y_3), nrow = n)        # Datenvektor
Xt         = cbind(                                    # Designmatrix vollständiges Modell
             matrix(1, nrow = n, ncol = 1),
             kronecker(diag(p),
                       matrix(1, nrow = m, ncol = 1)))
X          = Xt[,-2]
X_1        = X[,1]                                     # Designmatrix reduziertes Modell

# F-Teststatistikevaluation
beta_hat   = solve(t(X) %*% X) %*% t(X) %*% y          # Betaparameterschätzer vollständiges Modell
beta_hat_1 = solve(t(X_1) %*% X_1) %*% t(X_1) %*% y    # Betaparameterschätzer reduziertes Modell
eps_hat    = y - X %*% beta_hat                        # Residuenvektor vollständiges Modell
eps_hat_1  = y - X_1 %*% beta_hat_1                    # Residuenvektor reduziertes Modell
SQT        = t(eps_hat_1) %*% eps_hat_1                # Sum of Squares Total
SQW        = t(eps_hat)   %*% eps_hat                  # Sum of Squares Within
SQB        = SQT - SQW                                 # Sum of Squares Between
DFB        = p - 1                                     # Between Degrees of Freedom
DFW        = n - p                                     # Within  Degrees of Freedom
DFB        = p - 1                                     # Between Degrees of Freeom
MSB        = SQB/DFB                                   # Mean Sum of Squares Between
MSW        = SQW/DFW                                   # Mean Sum of Squares Within
Eff        = MSB/MSW                                   # F-Teststatistik
p          = 1 - pf(Eff, p-1, n-p)                     # p-Wert
```

# Modellevaluation
Anwendungsbeispiel

\tiny
\vspace{1mm}
```{r}

# Ausgabe
cat( "DFB :" , DFB,
    "\nDFW :", DFW,
    "\nSQB :", SQB,
    "\nSQW :", SQW,
    "\nMSB :", MSB,
    "\nMSW :", MSW,
    "\nF   :", Eff,
    "\np   :", paste(p))
```

# Modellevaluation
Anwendungsbeispiel

\tiny
\vspace{1mm}
```{r, echo = T}
# Dateneinlesen
fname      = file.path(getwd(), "10_Daten", "10_Einfaktorielle_Varianzanalyse_Daten.csv")
D          = read.table(fname, sep = ",", header = TRUE)

# Benutzung von R's aov Funktion und Ausgabe
res.aov = aov(D$BDI ~ D$Condition, data = D)
summary(res.aov)
```
\vfill

#
\large
\setstretch{2.7}
\vfill
Anwendungsszenario

Modellformulierung

Modellschätzung

Modellevaluation

**Selbstkontrollfragen**
\vfill

# Selbstkontrollfragen
\footnotesize
\begin{enumerate}
\itemsep1mm
\item Erläutern Sie das Anwendungsszenario einer einfaktoriellen Varianzanalyse (EVA).
\item Geben Sie die Definition des EVA Modells in Erwartungswertparameterdarstellung wieder.
\item Geben Sie die strukturelle Form des EVA Modells in Effektdarstellung wieder.
\item Erläutern Sie die Motivation für die Reparameterisierung des EVA Modells
\item Welche Bedeutung haben die Parameter $\mu_0,\alpha_2,...,\alpha_p$ in der Effektparameterdarstellung des EVA Modells?
\item Warum gibt es bei $p$ Gruppen eines EVA Szenarios nur die $p-1$ Effektparameter $\alpha_2,...,\alpha_p$?
\item Geben Sie die Designmatrixform des EVA Modells in Effektdarstellung wieder.
\item Formulieren Sie die Designmatrix eines EVA Modells mit $n_i = 3$ und $p = 2$.
\item Formulieren Sie die Designmatrix eines EVA Modells mit $n_i = 2$ und $p = 5$.
\item Geben Sie das Theorem zur Betaparameterschätzung im EVA Modell wieder.
\item Mit welchen deskriptiven Statistiken werden die Parameter $\mu_0,\alpha_2,...,\alpha_p$ eines EVA Modells geschätzt? 
\item Geben Sie das Theorem zur Quadratsummenzerlegung bei einfaktorieller Varianzanalyse wieder.
\item Erläutern Sie die Begriffe Total Sum of Squares, Between Sum of Squares, Within Sum of Squares der EVA.
\item Geben Sie die Definition des Effektstärkenmaßes $\eta^2$ an.
\end{enumerate}

# Selbstkontrollfragen
\footnotesize
\begin{enumerate}
\itemsep1mm
\setcounter{enumi}{14}
\justifying
\item Wann nimmt das Effektstärkenmaß $\eta^2$ der EVA seinen Minimalwert an und wie lautet dieser?
\item Wann nimmt das Effektstärkenmaß $\eta^2$ der EVA seinen Maximalwert an und wie lautet dieser?
\item Geben Sie das Theorem zur F-Teststatistik der EVA wieder.
\item Erläutern Sie die Begriffe Mean Between Sum of Squares und Mean Within Sum of Squares der EVA.
\item Geben Sie das Theorem zum Zusammenhang von Effektstärkenmaß $\eta^2$  und F-Teststatistik der EVA wieder.
\item Geben Sie die Definition des EVA F-Test wieder.
\item Erläutern sie die Null- und Alternativhypothesen des EVA F-Tests.
\item Geben Sie das Theorem zur Testumfangkontrolle der EVA wieder.
\item Skizzieren Sie den Beweis zur Testumfangkontrolle der EVA.
\item Geben Sie den p-Wert zum F-Test der EVA wieder.
\item Betrachten Sie die Daten zur Therapiedauer der Patient:innen in der Face-to-Face,
Online, und Waitlist Control Gruppe im Beispieldatensatz. Erstellen Sie ein Balkendiagramme 
der Gruppenmittelwerte und Gruppenstandardabweichungen und erläutern Sie dieses. 
Führen Sie zu diesen Daten einen EVA F-Test mit $\alpha := 0.05$ durch. 
Dokumentieren Sie ihre Ergebnisse. Was folgern Sie aus den sich ergebenen Resultaten?
\end{enumerate}


# References
\footnotesize
