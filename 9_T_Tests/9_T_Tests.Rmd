---
fontsize: 8pt
bibliography: 9_Referenzen.bib
citation_package: natbib
output:
  beamer_presentation:
    keep_tex: true
    includes:
      in_header: 9_header.tex
---


```{r, include = F}
source("9_R_common.R")
fdir        = file.path(getwd(), "9_Abbildungen")                                # Abbildungsverzeichnis
```


#  {.plain}
\center
```{r, echo = FALSE, out.width = "20%"}
knitr::include_graphics("9_Abbildungen/alm_9_otto.png")
```

\vspace{2mm}

\huge
Allgemeines Lineares Modell
\vspace{6mm}

\large
BSc Psychologie SoSe 2022

\vspace{6mm}
\normalsize
Prof. Dr. Dirk Ostwald

# {.plain}
\center
\huge
\vfill
\noindent (9) T-Tests
\vfill

# {.plain}
\large
\setstretch{3}
\vfill
Überblick

Einstichproben-T-Tests

Zweistichproben-T-Tests

Selbstkontrollfragen
\vfill

# {.plain}
\large
\setstretch{3}
\vfill
**Überblick**

Einstichproben-T-Tests

Zweistichproben-T-Tests

Selbstkontrollfragen
\vfill


# Überblick
\textcolor{darkblue}{Kontinuum von ALM Designs}

\small
Extremszenario (1) Die Erwartungswerte aller Datenvariablen sind identisch.
\begin{multline}
y_i \sim N(\mu,\sigma^2) \mbox{ u.i.v. für } i = 1,...,n  \Leftrightarrow \\
y = X\beta + \varepsilon,  X := 1_n \in \mathbb{R}^{n\times 1}, \beta := \mu \in \mathbb{R}, \varepsilon \sim N(0_n,\sigma^2 I_n)
\end{multline}
$\Rightarrow$ Jegliche Datenvariabilität wird dem Fehlerterm zugeschrieben.
\vspace{2mm}

Extremszenario (2) Die Erwartungswerte aller Datenvariablen sind paarweise verschieden
\begin{multline}
y_i \sim N(\mu_i,\sigma^2) \mbox{ u.v. für } i = 1,...,n \Leftrightarrow \\
y = X\beta + \varepsilon \mbox{ mit } X := I_n \in \mathbb{R}^{n \times n}, \beta := (\mu_1,..., \mu_n)^T \in \mathbb{R}^n, \varepsilon \sim N(0_n,\sigma^2 I_n)
\end{multline}
$\Rightarrow$ Jegliche Datenvariabilität wird dem Erwartungswertparameter zugeschrieben.

$\Rightarrow$ Es gilt $\hat{\beta} = (I_n^TI_n)^{-1}I_n^Ty = y$ und $\hat{\sigma}^2 = \frac{(y - I_ny)^T(y - I_ny)}{n-p} = 0$.
\vspace{2mm}

Beide Extremszenarien sind wissenschaftlich nicht ergiebig, da sie keine
theoriegeleitete systematische Abhängigkeit zwischen der UV und der AV repräsentieren.
Die im weiteren Verlauf der Vorlesung betrachteten ALM Designs liegen zwischen den beiden
Extremszenarien und repräsentieren verschiedene Formen der systematischen Abhängigkeit
zwischen UV und AV.

# Überblick
\vspace{2mm}
\setstretch{1.3}
\textcolor{darkblue}{Faktorielle und Parametrische ALM Designs}

\small
Faktorielle ALM Designs
\vspace{-2mm}

* Designmatrizen mit $1$en und $0$en, manchmal $-1$en.
* Betaparameter repräsentieren Gruppenerwartungswerte.
* Betaparameterschätzer repräsentieren Gruppenstichprobenmittel.
* $\Rightarrow$ T-Tests, Einfaktorielle Varianzanalyse, Mehrfaktorielle Varianzanalyse


Parametrische ALM Designs
\vspace{-2mm}

* Designmatrizen besitzen Spalten mit kontinuierlichen reellen Werten.
* Die Designmatrixsspalten werden *Regressoren*, *Prädiktoren*, oder *Kovariaten* genannt.
* Betaparameter repräsentieren Steigungsparameter.
* Betaparameterschätzer ergeben sich als normalisierte Regressor-Daten Kovarianzen.
* Es besteht ein enger Bezug zur Theorie der Korrelation.
* $\Rightarrow$ Einfache lineare Regression, Multiple lineare Regression

Faktoriell-parametrische ALM Designs
\vspace{-2mm}

* Designmatrizen mit mehreren faktoriellen und parametrischen Werten.
* Die parametrischen Regressoren werden oft als kontrollierte Kovariaten betrachtet.
* $\Rightarrow$ Kovarianzanalyse

# Überblick
\setstretch{1.6}
\textcolor{darkblue}{ALM Designs als Hypothesentestverfahren$^\ast$}

Testen von Unterschiedshypothesen

* T-Tests
* Einfaktorielle Varianzanalyse
* Mehrfaktorielle Varianzanalyse
* Kovarianzanalyse

Testen von Zusammenhangshypothesen

* Einfache lineare Regression/Korrelation
* Multiple lineare Regression/Multiple Korrelation


$^\ast$Diese Sichtweise durch den Lehrenden nicht favorisiert.

# Überblick
\textcolor{darkblue}{T-Tests}
\setstretch{1.6}

\small
Es gibt viele T-Test Varianten, jeweils mit eigenen Testgütefunktionen.

Wir fokussieren hier auf die Erkenntnis von T-Tests als Spezialfälle des ALMs.

Wir behandeln im Detail
\vspace{-2mm}

* \justifying Einstichproben-T-Tests mit einfacher Nullhypothese und ungerichteter Alternativhypothese.
* Zweistichproben-T-Tests bei unabhängigen Stichproben unter Annahme identischer Varianzen mit
  einfacher Nullhypothese und ungerichteter Alternativhypothese.


Wir behandeln nicht
\vspace{-2mm}

* T-Tests mit gerichteten Hypothesen oder einfachen Null- und Alternativhypothesen.
* Zweistichproben-T-Tests bei Annahme nicht identischer Varianzen (Behrends-Fischer Problem).
* Zweistichproben T-Tests bei abhängigen Stichproben.

Für dieses Themengebiete wird auf WTFI Einheiten (13) und (14) verwiesen.


# {.plain}
\large
\setstretch{3}
\vfill
Überblick

**Einstichproben-T-Tests**

Zweistichproben-T-Tests

Selbstkontrollfragen
\vfill

# {.plain}
\center
\huge
\vfill
\noindent Einstichproben-T-Tests
\vfill


# Einstichproben-T-Tests
\large
\setstretch{3}
\vfill
Anwendungsszenario

Modellformulierung

Modellschätzung

Modellevaluation
\vfill

# Einstichproben-T-Tests
\large
\setstretch{3}
\vfill
**Anwendungsszenario**

Modellformulierung

Modellschätzung

Modellevaluation
\vfill


# Anwendungsszenario
\textbf{\textcolor{darkblue}{Eine Gruppe}} (Stichprobe) randomisierter experimenteller Einheiten.

Annahme der unabhängigen und identischen Normalverteilung $N(\mu,\sigma^2)$ der Datenpunkte.

$\mu$ und $\sigma^2$ unbekannt.

Quantifizieren der Unsicherheit beim inferentiellen Vergleich von $\mu$ mit $\mu_0$ beabsichtigt.
\vspace{2mm}

\textcolor{darkblue}{Anwendungsbeispiele}

\small
Pre-Post-Psychotherapie BDI Differenzanalyse einer Gruppe von Patient:innen

\vspace{-2mm}
* $\mu \neq \mu_0 := 0 \quad \Rightarrow$  Evidenz für Depressionsymptomatikveränderung

Gruppenanalysen mit Wechsler Adult Intelligence Scale

\vspace{-2mm}
* $\mu \neq \mu_0 := 100\, \Rightarrow$ Evidenz für über- oder unterdurchschnittliche WAIS Performanz

Gruppenanalysen in der funktionellen Kernspintomographie

\vspace{-2mm}
* $\mu > \mu_0 := 0   \quad \Rightarrow$ Evidenz für regionale Gehirnaktivierung


# Anwendungsszenario
\small
Wir betrachten das Anwendungsbeispiel aus Einheit (8) Studiendesign und
fokussieren auf die Gruppe (= Stichprobe, Experimentalbedingung) der Face-to-Face
Therapie. Wir betrachten also den Datensatz der negativen PostBDI-PreBDI
Differenzwerte mit Variablennamen "BDI".
\vspace{4mm}

Wir nehmen an, dass diese Datenpunkte u.i.v. Realisierungen von ZVen
$y_i \sim N(\mu,\sigma^2)$ sind und nehmen weiter an, dass wir sind an der
Quantifizierung der Unsicherheit beim inferentiellen Vergleich  des wahren,
aber unbekannten, Erwartungswertparameters $\mu$ im Sinne eines Hypothesentests
interessiert sind.
\vspace{4mm}

Im Folgenden evaluieren diesen Datensatz zunächst im Sinne deskriptiver Statistiken,
siehe dazu Einheit (11) Anwendungsbeispiel in Programmierung und Deskriptive Statistik.

```{r, eval = F, echo = F}
# Initialisierung
library(writexl)                                                                 # Excel Output
set.seed(1)                                                                      # Random number generator seed

# Simulationsparameter
n_c    = 3                                                                       # Anzahl Gruppen
n_i    = 40                                                                      # Anzahl Proband:innen pro Gruppe
n      = n_c*n_i                                                                 # Gesamtanzahl Datenpunte


# Simulationsparameter
mu_pre = c(31, 32, 29)                                                           # \mu pre F2F, ONL, WLC
mu_pos = c(27, 26, 301)                                                          # \mu post F2F, ONL, WLC
sigsqr = 10                                                                      # \sigma^2

# Datensimulation
D            = data.frame("ID" = 1:n)                                            # Dataframe Initialisierung und ID Variable
D$Condition  = c(rep("F2F",n_i), rep("ONL", n_i), rep("WLC", n_i))               # Bedingung
D$PreBDI     = c(round(rnorm(n_i, mu_pre[1], sqrt(sigsqr))),                     # PreBDI
                 round(rnorm(n_i, mu_pre[2], sqrt(sigsqr))),
                 round(rnorm(n_i, mu_pre[3], sqrt(sigsqr))))
D$PostBDI    = c(round(rnorm(n_i, mu_pos[1], sqrt(sigsqr))),                     # PostBDI
                 round(rnorm(n_i, mu_pos[2], sqrt(sigsqr))),
                 round(rnorm(n_i, mu_pos[3], sqrt(sigsqr))))
D$BDI        = -(D$PostBDI - D$PreBDI)                                           # -(PostBDI - PreBDI) = PreBDI - PostBDI
D$Age        = round(runif(n,20,80))                                             # Uniform verteilte Alterswerte
D$Duration   = round(runif(n,12,24))                                             # Uniform Therapiedauerwerte


# Datenspeicherung
write_xlsx(D, file.path(getwd()       , "9_Daten", "data_9_t_tests.xlsx"))
write.csv( D, file = file.path(getwd(), "9_Daten", "data_9_t_tests.csv"))
```

# Anwendungsszenario
\vspace{3mm}
\small
\textcolor{darkblue}{Dateneinlesen}
\setstretch{.6}
\tiny
\vspace{1mm}
```{r}
fname       = file.path(getwd(), "9_Daten", "data_9_t_tests.csv")
D           = read.table(fname, sep = ",", header = TRUE)
```
\vspace{-1mm}
```{r, echo = F}
# table visualization
knitr::kable(D[c(1:40),],
             align      = "ccc",
             "pipe")
```

# Anwendungsszenario
\small
\textcolor{darkblue}{Histogramm}
\vspace{1mm}
\tiny
\setstretch{.8}
```{r, eval = F}
# Datensatz von Interesse
BDI_F2F     = D$BDI[D$Condition == "F2F"]   # BDI Differenzwerte in der F2F Gruppe

# Histogrammparameter
h           = 1                             # gewünschte Klassenbreite
b_0         = min(BDI_F2F)                  # b_0
b_k         = max(BDI_F2F)                  # b_0
k           = ceiling((b_k - b_0)/h)        # Anzahl der Klassen
b           = seq(b_0, b_k, by = h)         # Klassen [b_{j-1}, b_j[
ylimits     = c(0,0.25)                     # y-Achsenlimits
xlimits     = c(-5,15)                      # x-Achsenlimits

# Abbildungsparameter
par(                                        # für Details siehe ?par
mfcol       = c(1,1),                       # 1 x 1 Panelstruktur
family      = "sans",                       # Serif-freier Fonttyp
pty         = "s",                          # Quadratische Abbildungsregion
bty         = "l",                          # L förmige Box
las         = 1,                            # Horizontale Achsenbeschriftung
xaxs        = "i",                          # x-Achse bei y = 0
yaxs        = "i",                          # y-Achse bei x = 0
font.main   = 1,                            # Non-Bold Titel
cex         = 1,                            # Textvergrößerungsfaktor
cex.main    = 1)                            # Titeltextvergrößerungsfaktor

# Histogramm
hist(
BDI_F2F,                                    # Delta.BDI Werte von Therapiebedingung i
breaks    = b,                              # Histogrammklassen
freq      = F,                              # normierte relative Häufigkeit
xlim      = xlimits,                        # x-Achsenlimits
ylim      = ylimits,                        # y-Achsenlimits
xlab      = "BDI",                          # x-Achsenbeschriftung
ylab      = "Geschätzte Wahrscheinlichkeit",# y-Achsenbeschriftung
main      = "")                             # Titelbeschriftung

# PDF Speicherung
dev.copy2pdf(
file        = file.path(getwd(), "9_Abbildungen", "alm_9_F2F_histogramm.pdf"),
width       = 4,
height      = 4)
```

# Anwendungsszenario
\small
\textcolor{darkblue}{Deskriptive Statistiken}
\vspace{3mm}
\tiny
\setstretch{1}
```{r, echo = T}
# Initialisierung eines Dataframes
tp            = c("F2F")                            # Therapiebedingungen
ntp           = length(tp)                          # Anzahl Therapiebedingungen
S             = data.frame(                         # Dataframeerzeugung
                n         = rep(NaN,ntp),           # Stichprobengrößen
                Max       = rep(NaN,ntp),           # Maxima
                Min       = rep(NaN,ntp),           # Minima
                Median    = rep(NaN,ntp),           # Mediane
                Mean      = rep(NaN,ntp),           # Mittelwerte
                Var       = rep(NaN,ntp),           # Varianzen
                Std       = rep(NaN,ntp),           # Standardabweichungen
                row.names = tp)                     # Therapiebedingungen

# Iterationen über Therapiebedingungen
for(i in 1:ntp){
  data        = D$BDI[D$Condition == tp[i]]         # Daten
  print(data)
  S$n[i]      = length(data)                        # Stichprobengröße
  S$Max[i]    = max(data)                           # Maxima
  S$Min[i]    = min(data)                           # Minima
  S$Median[i] = median(data)                        # Mediane
  S$Mean[i]   = mean(data)                          # Mittelwerte
  S$Var[i]    = var(data)                           # Varianzen
  S$Std[i]    = sd(data)                            # Standardabweichungen
}
```

# Anwendungsszenario
\small
\vspace{2mm}
\textcolor{darkblue}{Deskriptive Statistiken der negativen PostBDI-PreBDI Differenzen bei Face-to-Face Therapie}
\vspace{1mm}

```{r, echo = FALSE, out.width = "45%"}
knitr::include_graphics("9_Abbildungen/alm_9_F2F_histogramm.pdf")
```

\setstretch{1}
\footnotesize
```{r}
# Ausgabe
print.AsIs(S)
```


# Einstichproben-T-Tests
\large
\setstretch{3}
\vfill
Anwendungsszenario

**Modellformulierung**

Modellschätzung

Modellevaluation
\vfill


# Modellformulierung
\footnotesize
\begin{definition}[Einstichproben-T-Test Modell]
\justifying
$y_i, i = 1,...,n$ seien Zufallsvariablen, die die $n$ Datenpunkte eines Einstichproben-T-Test
Anwendungsszenarios modellieren. Dann hat das \textit{Einstichproben-T-Test Modell}
die strukturelle Form
\begin{equation}
y_i = \mu + \varepsilon_i
\mbox{ mit }
\varepsilon_i \sim N(0,\sigma^2) \mbox{ u.i.v. für } i = 1,...,n \mbox{ mit } \mu \in \mathbb{R} \mbox{ und } \sigma^2 > 0,
\end{equation}
die Datenverteilungsform
\begin{equation}
y_i \sim  N(\mu,\sigma^2) \mbox{ u.i.v. für } i = 1,...,n \mbox{ mit } \mu \in \mathbb{R} \mbox{ und } \sigma^2 > 0,
\end{equation}
und für den Datenvektor $y = (y_1,...,y_n)^T$ die Designmatrixform
\begin{equation}
y = X\beta + \varepsilon \mbox{ mit }
X := 1_n \in \mathbb{R}^{n \times 1},
\beta := \mu \in \mathbb{R},
\varepsilon \sim N(0_n,\sigma^2I_n),
\mbox{ und }
\sigma^2 > 0.
\end{equation}
\end{definition}
Bemerkungen

* Das Modell ist identisch mit dem Modell unabhängiger und identisch normalverteilter Zufallsvariablen.
* Es ist $p = 1$.
* Die Äquivalenz der drei Modellformen wurde in Einheit (5) Modellformulierung ausführlich diskutiert.


# Modellformulierung
\small
Datensimulation (vgl. Einheit (5) Modellformulierung)
\vspace{4mm}

\footnotesize
\setstretch{1.2}
```{r}
# Libraries
library(MASS)                                # Multivariate Normalverteilung

# Modellformulierung
n      = 40                                  # Anzahl von Datenpunkten
p      = 1                                   # Anzahl von Betaparameter
X      = matrix(rep(1,n), nrow = n)          # Designmatrix
I_n    = diag(n)                             # n x n Einheitsmatrix
beta   = 5                                   # wahrer, aber unbekannter, Betaparameter
sigsqr = 14                                  # wahrer, aber unbekannter, Varianzparameter

# Datenrealisierung
y      = mvrnorm(1, X %*% beta, sigsqr*I_n)  # eine Realisierung eines n-dimensionalen ZVs
```

# Einstichproben-T-Tests
\large
\setstretch{3}
\vfill
Anwendungsszenario

Modellformulierung

**Modellschätzung**

Modellevaluation
\vfill

# Modellschätzung
\footnotesize
\begin{theorem}[Parameterschätzung im Einstichproben-T-Test Modell]
\normalfont
\justifying
Gegeben sei die Designmatrixform des Einstichproben-T-Test Modells. Dann ergeben
sich für den Betaparameterschätzer
\begin{equation}
\hat{\beta} = \frac{1}{n}\sum_{i=1}^n y_i =: \bar{y},
\end{equation}
und für den Varianzparameterschätzer
\begin{equation}
\hat{\sigma}^2 = \frac{1}{n-1}\sum_{i=1}^n (y_i - \bar{y})^2 =: s_y^2
\end{equation}
\end{theorem}
Bemerkungen

* Die Formen von $\hat{\beta}$ und $\hat{\sigma}^2$ wurden in Einheit (6) Modellschätzung hergeleitet.
* $\bar{y}$ und $s_y^2$ bezeichnen das Stichprobenmittel und die Stichprobenvarianz der $y_1,...,y_n$.


# Modellschätzung
\tiny
\setstretch{1.2}
```{r}
# Dateneinlesen
fname       = file.path(getwd(), "9_Daten", "data_9_t_tests.csv")   # Dateiname
D           = read.table(fname, sep = ",", header = TRUE)           # Dataframe
y           = D$BDI[D$Condition == "F2F"]                           # BDI Differenzwerte in der F2F Gruppe

# Modellformulierung
n          = length(y)                                              # Anzahl Datenpunkte
p          = 1                                                      # Anzahl Betaparameter
X          = matrix(rep(1,n), nrow = n)                             # Designmatrix

# Modellschätzung
beta_hat   = solve(t(X) %*% X) %*% t(X) %*% y                       # Betaparameterschätzer
eps_hat    = y - X %*% beta_hat                                     # Residuenvektor
sigsqr_hat = (t(eps_hat) %*% eps_hat) /(n-p)                        # Varianzparameterschätzer

# Ausgabe
cat("hat{beta}   : "  , beta_hat,                                   # Betaparameterschätzer
    "\nbar{y}      : ", mean(y),                                    # Stichprobenmittel
    "\nhat{sigsqr} : ", sigsqr_hat,                                 # Varianzparameterschätzer
    "\ns_y^2       : ", var(y))                                     # Stichprobenvarianz
```


# Einstichproben-T-Tests
\large
\setstretch{3}
\vfill
Anwendungsszenario

Modellformulierung

Modellschätzung

**Modellevaluation**
\vfill

# Modellevaluation

\setstretch{3}
Überblick

\footnotesize

* Wir gruppieren frequentistische Konfidenzintervalle und Hypothesentests unter Modellevaluation.
* Zu Konfidenzintervallen im Szenario u.i.n.v. ZVen siehe WTFI Einheit (11) Konfidenzintervalle.
* In der Praxis zielt die Evaluation von Einstichproben-T-Tests ALM Designs meist auf einen Hypothesentest.
* Die Theorie des Einstichproben-T-Tests ist umfangreich, siehe dazu WTFI (13) Einstichproben T-Tests.
* Wir fokussieren hier auf zweiseitige Einstichproben-T-Tests mit ungerichteter Hypothese.
* Ein gutes Verständnis von WTFI Einheit (12) Hypothesentests wird im Folgenden vorausgesetzt.


# Modellevaluation
\small
Hypothesenszenarien

\setstretch{1.1}
Einfache Nullhypothese, einfache Alternativhypothese $H_0:\mu = \mu_0, H_1:\mu = \mu_1$
\begin{itemize}
\item Theoretisch wichtiges Szenario (Neymann-Pearson Lemma)
\item Praktische Relevanz eher gering
\end{itemize}

Einfache Nullhypothese, zusammengesetzte Alternativhypothese $H_0:\mu = \mu_0, H_1:\mu \neq \mu_0$
\begin{itemize}
\item Zweiseitiger Einstichproben-T-Test mit ungerichteter Hypothese
\item Ungerichtete Fragestellung nach einem Unterschied
\end{itemize}

Zusammengesetzte Nullhypothese/Alternativhypothese $H_0:\mu \le \mu_0, H_1:\mu > \mu_0$
\begin{itemize}
\item Einseitiger Einstichproben-T-Test mit gerichteter Hypothese
\item Gerichtete Fragestellung nach einem positiven Unterschied
\end{itemize}

Zusammengesetzte Nullhypothese/Alternativhypothese $H_0:\mu\ge\mu_0,H_1:\mu<\mu_0$
\begin{itemize}
\item Gerichtete Fragestellung nach einem negativen Unterschied
\item Qualitativ äquivalente Theorie zum umgekehrten Fall
\end{itemize}

# Modellevaluation
\small
Hypothesenszenarien

\small
Im Folgenden näher betrachtetes Hypothesenszenario

\setstretch{1.1}
\textcolor{lightgray}{Einfache Nullhypothese, einfache Alternativhypothese $H_0:\mu = \mu_0, H_1:\mu = \mu_1$}
\begin{itemize}
\item[\textcolor{lightgray}{$\bullet$}] \textcolor{lightgray}{Theoretisch wichtiges Szenario (Neymann-Pearson Lemma)}
\item[\textcolor{lightgray}{$\bullet$}] \textcolor{lightgray}{Praktische Relevanz eher gering}
\end{itemize}
Einfache Nullhypothese, zusammengesetzte Alternativhypothese $H_0:\mu = \mu_0, H_1:\mu \neq \mu_0$
\begin{itemize}
\item Zweiseitiger Einstichproben-T-Test mit ungerichteter Hypothese
\item Ungerichtete Fragestellung nach einem Unterschied
\end{itemize}
\textcolor{lightgray}{Zusammengesetzte Nullhypothese/Alternativhypothese $H_0:\mu \le \mu_0, H_1:\mu > \mu_0$}
\begin{itemize}
\item[\textcolor{lightgray}{$\bullet$}] \textcolor{lightgray}{Einseitiger Einstichproben-T-Test mit gerichteter Hypothese}
\item[\textcolor{lightgray}{$\bullet$}] \textcolor{lightgray}{Gerichtete Fragestellung nach einem positiven Unterschied}
\end{itemize}
\textcolor{lightgray}{Zusammengesetzte Nullhypothese/Alternativhypothese $H_0:\mu\ge\mu_0,H_1:\mu<\mu_0$}
\begin{itemize}
\item[\textcolor{lightgray}{$\bullet$}] \textcolor{lightgray}{Gerichtete Fragestellung nach einem negativen Unterschied}
\item[\textcolor{lightgray}{$\bullet$}] \textcolor{lightgray}{Qualitativ äquivalente Theorie zum umgekehrten Fall}
\end{itemize}

# Modellevaluation
\setstretch{1.8}
\textcolor{darkblue}{Gliederung (vgl. WTFI Einheiten (12) - (14))}

(1) Statistisches Modell \checkmark

(2) Testhypothesen  \checkmark

(3) Teststatistik

(4) Test

(5) Analyse der Testgütefunktion

(6) Testumfangkontrolle

(7) p-Werte

(8) Analyse der Powerfunktion


# Modellevaluation
\noindent (3) Teststatistik

\footnotesize
\begin{theorem}[T-Teststatistik des Einstichproben-T-Tests]
\normalfont
\justifying
Gegeben sei die Designmatrixform des Einstichproben-T-Test Modells. Dann ergibt
sich für die T-Teststatistik mit
\begin{equation}
c := 1 \mbox{ und } c^T\beta_0 =: \mu_0,
\end{equation}
dass
\begin{equation}
T = \sqrt{n}\left(\frac{\bar{y} - \mu_0}{s_y}\right)
\end{equation}
und es gilt
\begin{equation}
T \sim t(\delta, n-1) \mbox{ mit } \delta = \sqrt{n}\left(\frac{\mu - \mu_0}{\sigma}\right)
\end{equation}
\end{theorem}

Bemerkungen

* Das Theorem basiert auf dem T-Teststatistik Theorem in Einheit (7) Modellevaluation.
* Die eng verwandte T-Statistik wurde bereits in Einheit (7) Modellevaluation hergeleitet.

# Modellevaluation
\noindent (3) Teststatistik

\footnotesize
\underline{Beweis}

Mit dem  T-Teststatistik Theorem in Einheit (7) Modellevaluation gilt
\begin{equation}
T
= \frac{c^T \hat{\beta} - c^T \beta_0}{\sqrt{\hat{\sigma}^2 c^T (X^TX)^{-1}c}}
= \frac{1^T \bar{y} - 1^T \mu_0}{\sqrt{s_y^2 1^T (1_n^T1_n)^{-1}1}}
= \sqrt{n}\left(\frac{\bar{y} - \mu_0}{s_y}\right).
\end{equation}
\vspace{2mm}

Weiterhin gilt mit demselben Theorem
\begin{equation}
\delta
= \frac{c^T \beta - c^T \beta_0}{\sqrt{\sigma^2 c^T (X^TX)^{-1}c}}
= \frac{1^T \mu   - 1^T \mu_0  }{\sqrt{\sigma^2 1^T (1_n^T 1_n)^{-1}1}}
= \sqrt{n}\left(\frac{\mu - \mu_0}{\sigma}\right)
\end{equation}


# Modellevaluation
\noindent (4) Test

\footnotesize
\begin{definition}[Zweiseitiger Einstichproben-T-Tests]
\justifying
Gegeben sei das Einstichproben-T-Test Modell. Für ein $\mu_0 \in \mathbb{R}$ seien
die einfache Nullhypothese und die zusammengesetzte Alternativhypothese als
\begin{equation}
H_0 : \mu = \mu_0 \Leftrightarrow \Theta_0 := \{\mu_0\}
\mbox{ und }
H_1 : \mu \neq \mu_0 \Leftrightarrow \Theta_1 := \mathbb{R} \setminus \{\mu_0\},
\end{equation}
definiert. Weiterhin sei die T-Teststatistik definiert als
\begin{equation}
T := \sqrt{n}\left(\frac{\bar{y} - \mu_0}{s_y}\right)
\end{equation}
Dann ist der \textit{zweiseitige Einstichproben-T-Tests} definiert als der
kritische Wert-basierten Test
\begin{equation}
\phi(y) := 1_{\{|T| \ge k\}} =
{\begin{cases}
1 & |T| \ge k \\
0 & |T|  <  k
\end{cases}}.
\end{equation}
\end{definition}

Bemerkungen

* Ausführlicher handelt es sich um den *zweiseitigen Einstichproben-T-Tests mit ungerichteter Hypothese*.

# Modellevaluation
\noindent (5) Analyse der Testgütefunktion
\vspace{1cm}

\small
\begin{theorem}[Testgütefunktion]
\justifying
\normalfont
$\phi$ sei der im obigen Testszenario definierte Test. Dann ist die
Testgütefunktion von $\phi$ gegeben durch
\begin{equation}
q_{\phi} : \mathbb{R} \to [0,1],
\mu \mapsto q_{\phi}(\mu)
:= 1 - \psi(k;\delta,n-1) + \psi(-k;\delta,n-1)
\end{equation}
wobei $\psi(\cdot; \delta, n-1)$  die KVF der nichtzentralen $t$-Verteilung mit
Nichtzentralitätsparameter
\begin{equation}
\delta := \sqrt{n}\left(\frac{\mu - \mu_0}{\sigma}\right)
\end{equation}
und Freiheitsgradparameter $n-1$ bezeichnet.
\end{theorem}

# Modellevaluation
\setstretch{1.1}
\noindent (5) Analyse der Testgütefunktion
\vspace{5mm}

\small
\center Testgütefunktion $q_\phi$ für $\sigma^2 = 9, \mu_0 = 4, n = 12$ und $k = 1,2,3$.
\vspace{2mm}
\begin{equation*}
\quad q_{\phi}(\mu) = \mathbb{P}_\mu(\phi = 1)
\end{equation*}

```{r, echo = F, eval = F}
dev.new()
graphics.off()
par(
family      = "sans",
bty         = "l",
lwd         = 1,
las         = 1,
mgp         = c(2,1,0),
xaxs        = "i",
yaxs        = "i",
font.main   = 1,
cex         = 1.1,
cex.main    = 1.1)

# Parameter
mu_0        = 4
n           = 12
sigsqr      = 9
sigma       = sqrt(9)
k           = c(1,2,3)
mu          = matrix(seq(0, 8,len = 1e3), nrow = 1e3)
d           = sqrt(n)*(mu - mu_0)/sigma
q_mu        = cbind(matrix(1-pt(k[1],n-1,d)+ pt(-k[1],n-1,d),nrow=length(mu)),
                    matrix(1-pt(k[2],n-1,d)+ pt(-k[2],n-1,d),nrow=length(mu)),
                    matrix(1-pt(k[3],n-1,d)+ pt(-k[3],n-1,d),nrow=length(mu)))

# Visualisierung
matplot(
mu,
q_mu,
type        = "l",
lty         = c(1,2,3),
col         = "black",
lwd         = 2,
xlab        = "",
ylab        = "",
ylim        = c(0,1.05),
)
lines(
4,
0,
pty         = "p",
pch         = 16,
xpd         = TRUE
)
legend(
6,
.4,
c("k = 1", "k = 2", "k = 3"),
lty         = c(1,2,3),
col         = "black",
bty         = "n"
)
text(8.3,-.01, TeX("$\\mu$")                        , cex = 1.1, xpd = TRUE)
text(4  ,-.25, TeX("$H_0\\,:\\, \\mu = \\mu_0$")    , cex = 1.1, xpd = TRUE)
text(2  ,-.35, TeX("$H_1\\,:\\, \\mu \\neq \\mu_0$"), cex = 1.1, xpd = TRUE)
text(6  ,-.35, TeX("$H_1\\,:\\, \\mu \\neq \\mu_0$"), cex = 1.1, xpd = TRUE)
dev.copy2pdf(
file        = file.path(fdir, "alm_9_t_test_ungerichtet_guetefunktion.pdf"),
width       = 7,
height      = 4)
```

```{r, echo = FALSE, out.width = "80%"}
knitr::include_graphics("9_Abbildungen/alm_9_t_test_ungerichtet_guetefunktion.pdf")
```

# Modellevaluation
\setstretch{1.2}
\noindent (5) Analyse der Testgütefunktion

\footnotesize
\underline{Beweis}

Die Testgütefunktion des betrachteten Test im vorliegenden Testszenario ist
definiert als
\begin{equation}
q_{\phi} : \mathbb{R} \to [0,1],
\mu \mapsto q_{\phi}(\mu) := \mathbb{P}_{\mu}(\phi = 1).
\end{equation}
Da die Wahrscheinlichkeiten für $\phi = 1$ und dafür, dass  die zugehörige
Teststatistik im Ablehnungsbereich des Tests liegt gleich sind, benötigen wird
die also zunächst die Verteilung der Teststatistik. Wir haben oben bereits
gesehen, dass die T-Teststatistik
\begin{equation}
T := \sqrt{n}\left(\frac{\bar{y} - \mu_0}{s_y} \right)
\end{equation}
unter der Annahme $y_i \sim N(\mu,\sigma^2) \mbox{ u.i.v. für } i = 1,...,n$ nach
einer nichtzentralen $t$-Verteilung $t(\delta,n-1)$ mit Nichtzentralitätsparameter
\begin{equation}
\delta = \sqrt{n}\left(\frac{\mu - \mu_0}{\sigma}\right)
\end{equation}
verteilt ist. Der Ablehnungsbereich des zweiseitigen T-Tests ergibt sich,
wie in ähnlicher Form bei der Betrachtung des zweiseitigen Z-Tests gesehen, zu
\begin{equation}
A  = \,]-\infty, -k]\, \cup \,]k,\infty[.
\end{equation}
\vfill


# Modellevaluation
\setstretch{1.2}
\noindent (5) Analyse der Testgütefunktion

\footnotesize
\underline{Beweis (fortgeführt)}

Mit diesem Ablehungsbereich ergibt sich dann
\begin{align}
\begin{split}
q_\phi(\mu)
& = \mathbb{P}_{\mu}(\phi = 1)                                                   \\
& = \mathbb{P}_{\mu}\left(T \in ]-\infty, -k]\,
                         \cup \,]k,\infty[ \right)                               \\
& = \mathbb{P}_{\mu}\left(T \in ]-\infty, -k]\right)
  + \mathbb{P}_{\mu}\left(T \in [k,\infty[ \right)                               \\
& = \mathbb{P}_{\mu}(T \le -k)  + \mathbb{P}_{\mu}(T \ge k)                      \\
& = \mathbb{P}_{\mu}(T \le -k)  + (1-\mathbb{P}_{\mu}(T \le k))                  \\
& = 1 - \mathbb{P}_{\mu}(T \le k)  + \mathbb{P}_{\mu}(T \le - k)                 \\
& = 1 - \psi(k; \delta, n-1)  + \psi(-k;\delta,n-1),
\end{split}
\end{align}
wobei $\psi(\cdot; \delta,n-1)$ die KVF der nichtzentralen T-Verteilung mit
Nichtzentralitätsparameter $\delta$ und Freiheitsgradparameter $n-1$ bezeichnet.

$\hfill\Box$
\vfill

# Modellevaluation
\setstretch{1.2}
\noindent (6) Testumfangkontrolle
\vfill
\small

\begin{theorem}[Testumfangkontrolle]
\justifying
\normalfont
$\phi$ sei der im obigen Testszenario definierte Test. Dann ist $\phi$ ein
Level-$\alpha_0$-Test mit Testumfang $\alpha_0$, wenn der kritische Wert
definiert ist durch
\begin{equation}
k_{\alpha_0} := \psi^{-1}\left(1 - \frac{\alpha_0}{2}; n-1 \right),
\end{equation}
wobei $\psi^{-1}(\cdot; n-1)$ die inverse KVF der $t$-Verteilung mit $n-1$
Freiheitsgraden ist.
\end{theorem}
\vfill

# Modellevaluation
\setstretch{1.1}
\noindent (6) Testumfangkontrolle
\setstretch{1}

\footnotesize
\underline{Beweis}

Damit der betrachtete Test ein Level-$\alpha_0$-Test ist, muss bekanntlich
$q_\phi(\mu) \le \alpha_0$ für alle $\mu \in \{\mu_0\}$, also hier $q_\phi(\mu_0)
\le \alpha_0$, gelten. Weiterhin ist der Testumfang des betrachteten Tests durch
$\alpha = \max_{\mu \in \{\mu_0\}} q_\phi(\mu)$, also hier durch $\alpha =
q_\phi(\mu_0)$ gegeben. Wir  müssen also zeigen, dass die Wahl von $k_{\alpha_0}$
garantiert, dass $\phi$ ein Level-$\alpha_0$-Test mit Testumfang $\alpha_0$ ist.
Dazu merken wir zunächst an, dass für $\mu = \mu_0$ gilt, dass
\begin{align}
\begin{split}
q_\phi(\mu_0)
& =  1 - \psi(k;\delta,n-1) + \psi(-k;\delta,n-1)                          \\
& =  1 - \psi(k;0,n-1) + \psi(-k;0,n-1)                                          \\
& =  1 - \psi(k;n-1) + \psi(-k;n-1),                                             \\
\end{split}
\end{align}
wobei $\psi(\cdot;\delta,n-1)$ und $\psi(\cdot;n-1)$ die KVF der nichtzentralen
$t$-Verteilung mit Nichtzentralitätsparameter $\delta$ und Freiheitsgradparameter $n-1$
sowie der $t$-Verteilung mit Freiheitsgradparameter $n-1$, respektive, bezeichnen.
Sei nun also $k := k_{\alpha_0}$. Dann gilt
\begin{align}
\begin{split}
q_\phi(\mu_0)
& = 1 - \psi(k_{\alpha_0}, n-1) + \psi(-k_{\alpha_0}, n-1)                                 \\
& = 1 - \psi(k_{\alpha_0}, n-1) + (1 - \psi(k_{\alpha_0}), n-1)                            \\
& = 2(1-\psi(k_{\alpha_0}, n-1))                                                      \\
& = 2\left(1-\psi\left(\psi^{-1}\left(1 - \alpha_0/2 , n-1\right), n-1\right)\right) \\
& = 2\left(1 - 1 + \alpha_0/2\right)                          \\
& = \alpha_0,
\end{split}
\end{align}
wobei die zweite Gleichung mit der Symmetrie der $t$-Verteilung folgt. Es folgt
also direkt, dass bei der Wahl von $k = k_{\alpha_0}$, $q_\phi(\mu_0)\le \alpha_0$
ist und der betrachtete Test somit ein Level-$\alpha_0$-Test ist. Weiterhin
folgt direkt, dass der Testumfang des betrachteten Tests bei der Wahl von
$k = k_{\alpha_0}$ gleich $\alpha_0$ ist.

# Modellevaluation
\setstretch{1.2}
\noindent (6) Testumfangkontrolle
\small
\vfill
\center Wahl von $k_{\alpha_0} := \psi^{-1}(1 - \alpha_0/2; n-1)$ mit $n =12$,
$\alpha_0 := 0.05$ und Ablehnungsbereich
\vspace{3mm}

```{r, echo = F, eval = F}
dev.new()
graphics.off()
par(
family      = "sans",
mfcol       = c(1,2),
pty         = "m",
bty         = "l",
lwd         = 1,
las         = 1,
mgp         = c(2,1,0),
xaxs        = "i",
yaxs        = "i",
font.main   = 1,
cex         = 1,
cex.main    = 1.2)

# Parameter
n           = 12
alpha_0     = 0.05                                                               # Konfidenzniveau
k_alpha_0   = qt(1 - alpha_0/2, n-1)                                             # kritischer Wert
t           = seq(-4,4,length=1e4)                                               # T-Statistikwerte
Pt          = pt(t,n-1)                                                          # T-Statistik KVF für H_0
pt          = dt(t,n-1)                                                          # T-Statistik WDF für H_0

# KVF Perspektive
plot(                                                                            # original density function
t,
Pt,
type        = "l",
ylab        = " ",
ylim        = c(0,1),
main        = TeX("$\\psi$"))

lines(
k_alpha_0,
0,
type        = "p",
pch         = 16,
xpd         = TRUE)

lines(
min(t),
1 - alpha_0/2,
type        = "p",
pch         = 16,
xpd         = TRUE)

arrows(
x0          = min(t),
y0          = 1 - alpha_0/2,
x1          = k_alpha_0,
y1          = 1 - alpha_0/2,
col         = "darkorange",
angle       = 45,
length      = .1)

arrows(
x0          = k_alpha_0,
y0          = 1-alpha_0/2,
x1          = k_alpha_0,
y1          = 0,
col         = "darkorange",
angle       = 45,
length      = .1)

text(k_alpha_0, -.25 , TeX("$\\k_{\\alpha_0}$"), xpd = TRUE)
text(-3       , 1.05 , TeX("$1 - \\alpha_0/2$"), xpd = TRUE)


# WDF Perspektive
plot(
t,
pt,
type        = "l",
ylab        = " ",
ylim        = c(0,.4),
main        = TeX("$t$"))

polygon(
c(t[t  <= -k_alpha_0] , 0, 0),
c(pt[t <= -k_alpha_0],  min(t), -k_alpha_0),
col = "gray90",
border = NA)

polygon(
c(t[t  >= k_alpha_0] , max(t), k_alpha_0),
c(pt[t >= k_alpha_0],       0, 0),
col = "gray90",
border = NA)

lines(
seq(min(t), -k_alpha_0, len = 1e2),
rep(0,1e2),
type        = "l",
lwd         = 5,
col         = "darkorange")

lines(
seq(k_alpha_0, max(t), len = 1e2),
rep(0,1e2),
type        = "l",
lwd         = 5,
col         = "darkorange")

lines(
- k_alpha_0,
0,
type        = "p",
pch         = 16,
xpd         = TRUE,)

lines(
k_alpha_0,
0,
type        = "p",
pch         = 16,
xpd         = TRUE)

text(-k_alpha_0,-.11, TeX("$-\\k_{\\alpha_0}$"), xpd = TRUE)
text( k_alpha_0,-.11, TeX("$\\k_{\\alpha_0}$") , xpd = TRUE)
text( 3, .05 , TeX("$P(T > = k_{\\alpha_0}) = \\alpha_0/2$"), xpd = TRUE, cex = .8, col = "gray50")
text(-3, .05 , TeX("$P(T < = k_{\\alpha_0}) = \\alpha_0/2$"), xpd = TRUE, cex = .8, col = "gray50")

fdir        =  file.path(getwd(), "9_Abbildungen")
dev.copy2pdf(
file        = file.path(fdir, "alm_9_t_test_ungerichtet_testumfangkontrolle.pdf"),
width       = 8,
height      = 4)
```

```{r, echo = FALSE, out.width = "80%"}
knitr::include_graphics("9_Abbildungen/alm_9_t_test_ungerichtet_testumfangkontrolle.pdf")
```


# Modellevaluation
\justifying
\setstretch{1.2}
\noindent (6) Testumfangkontrolle
\vspace{1mm}

Praktisches Vorgehen
\small

* \justifying Man nimmt an, dass ein Datensatz $\upsilon_1,...,\upsilon_n$ eine
Realisation von $y_i \sim N(\mu,\sigma^2) \mbox{ u.i.v. für } i = 1,...,n$ mit
unbekannten Parametern $\mu$ und $\sigma^2 > 0$ ist.

* Man möchte entscheiden ob für ein $\mu_0 \in \mathbb{R}$ eher
$H_0 : \mu = \mu_0$ oder $H_1: \mu \neq \mu_0$ zutrifft.
\item Man wählt ein Signifikanzniveau $\alpha_0$ und bestimmt den
zugehörigen Freiheitsgradparameter-abhängigen kritischen Wert $k_{\alpha_0}$.
Zum Beispiel gilt bei Wahl von $\alpha_0  := 0.05$ und $n=12$, also
Freiheitsgradparameter 11, dass $k_{0.05}=\psi^{-1}(1 - 0.05/2; 11) \approx 2.20$
ist.

* Anhand von $n, \mu_0, \bar{\upsilon}$ und $s_\upsilon$ berechnet man die
Realisierung der T-Teststatistik
\begin{equation}
t:= \sqrt{n}\left(\frac{\bar{\upsilon} - \mu_0}{s_\upsilon}\right)
\end{equation}

* Wenn $t$ größer-gleich $k_{\alpha_0}$ ist oder wenn $\tau$ kleiner-
gleich $-k_{\alpha_0}$ ist, lehnt man die Nullhypothese ab, andernfalls lehnt
man sie nicht ab.

* Die oben entwickelte Theorie  garantiert dann, dass man in höchstens
$\alpha_0 \cdot 100$ von $100$ Fällen die Nullhypothese fälschlicherweise ablehnt.


# Modellevaluation
\noindent (7) p-Werte

\small
Bestimmung des p-Wertes
\vspace{2mm}

* \itemsep2mm \justifying Per Definition ist der p-Wert das kleinste Signifikanzlevel $\alpha_0$, bei
welchem man die Nullhypothese basierend auf einem vorliegendem Wert der
Teststatistik ablehnen würde.

* Bei $T = t$ würde $H_0$ für jedes $\alpha_0$ mit
$|t| \ge \psi^{-1}(1-\alpha_0/2; n-1)$ abgelehnt werden. Für diese $\alpha_0$
gilt, wie unten gezeigt,
\begin{equation}
\alpha_0 \ge 2 \mathbb{P}(T \ge |t|).
\end{equation}

* Das kleinste $\alpha_0 \in [0,1]$ mit $\alpha_0 \ge 2 \mathbb{P}(T \ge |t|)$ ist
dann $\alpha_0 = 2 \mathbb{P}(T \ge |t|)$, also folgt
\begin{equation}
\mbox{p-Wert} =  2 \mathbb{P}(T \ge |t|) = 2(1 - \psi(|t|;n-1)).
\end{equation}

* Im Gegensatz zum Z-Test hängt bei T-Tests der p-Wert auch von der
Stichprobengröße ab.

* Zum Beispiel ist für $T = 2.00$ und $n = 10$ der p-Wert $0.076$, für $T = 2.00$
und $n = 100$ ist der p-Wert dagegen $0.048$.

# Modellevaluation
\noindent (7) p-Werte

\small
Bestimmung des p-Wertes
\vspace{2mm}

* \itemsep2mm \justifying Es bleibt zu zeigen, dass gilt
\begin{equation}
|t| \ge \psi^{-1}(1 - \alpha_0/2; n-1)
\Leftrightarrow
\alpha_0 \ge 2 \mathbb{P}(T \ge |t|)
\end{equation}

* Dies aber folgt aus \footnotesize \vspace{-2mm}
\begin{align}
\begin{split}
|t|
& \ge \psi^{-1}\left(1 - \frac{\alpha_0}{2}; n-1\right)
\\\Leftrightarrow
\psi(|t|; n-1)
& \ge \psi\left(\psi^{-1}\left(1 - \frac{\alpha_0}{2}; n-1\right); n-1\right)
\\\Leftrightarrow
\psi(|t|; n-1)
& \ge 1 - \frac{\alpha_0}{2}
\\\Leftrightarrow
\mathbb{P}(T \le |t|)
& \ge 1 - \frac{\alpha_0}{2}
\\\Leftrightarrow
\frac{\alpha_0}{2}
& \ge 1 - \mathbb{P}(T \le |t|)
\\\Leftrightarrow
\frac{\alpha_0}{2}
& \ge \mathbb{P}(T \ge |t|)
\\\Leftrightarrow
\alpha_0
& \ge 2 \mathbb{P}(T \ge |t|).
\end{split}
\end{align}

# Modellevaluation
\vspace{1mm}
\small
\textcolor{darkblue}{Anwendungszenario}
\vspace{1mm}
\setstretch{.9}
\tiny
```{r}
# Dateneinlesen
fname       = file.path(getwd(), "9_Daten", "data_9_t_tests.csv")  # Dateiname
D           = read.table(fname, sep = ",", header = TRUE)          # Dataframe
y           = D$BDI[D$Condition == "F2F"]                          # BDI Differenzwerte in der F2F Gruppe

# Modellformulierung
n          = length(y)                                             # Anzahl Datenpunkte
p          = 1                                                     # Anzahl Betaparameter
X          = matrix(rep(1,n), nrow = n)                            # Designmatrix

# Modellschätzung
beta_hat   = solve(t(X) %*% X) %*% t(X) %*% y                      # Betaparameterschätzer
eps_hat    = y - X %*% beta_hat                                    # Residuenvektor
sigsqr_hat = (t(eps_hat) %*% eps_hat) /(n-p)                       # Varianzparameterschätzer

# Modellevaluation
c          = matrix(c(1),nrow = p)                                 # Kontrastgewichtsvektor
mu_0       = 0                                                     # Nullhypothese H_0
alpha_0    = 0.05                                                  # Signifikanzniveau
k_alpha_0  = qt(1 - (alpha_0/2), n-1)                              # kritischer Wert
t_num      = t(c) %*% beta_hat - mu_0                              # T-Teststatistik Zähler
t_den      = sqrt(sigsqr_hat %*% t(c)*solve(t(X) %*% X)%*%c)       # T-Teststatistik Nenner
t          = t_num/t_den                                           # T-Teststatistik
if(abs(t) >= k_alpha_0){                                           # Test 1_{|T(X) >= k_alpha_0|}
    phi = 1                                                        # Ablehnen von H_0
} else {
    phi = 0                                                        # Nicht Ablehnen von H_0
}
pval      = 2*(1 - pt(abs(t), n-1))                                # p-Wert
```
\vspace{-2mm}
```{r, echo = F}
cat("fg        = "  , n-1,                                         # Ausgabe
    "\nt         = ", t,
    "\nalpha_0   = ", alpha_0,
    "\nk_alpha_0 = ", k_alpha_0,
    "\nphi       = ", phi,
    "\np-Wert    = ", pval)
```

# Modellevaluation
\small
\textcolor{darkblue}{Anwendungszenario}
\vspace{2mm}

\setstretch{1.1}
\tiny
```{r}
# Automatischer Einstichproben-T-Test
varphi    = t.test(                           # ?t.test für Details
            y,                                # Datensatz
            alternative = c("two.sided"),     # H_1: \mu \neq \mu_0
            mu          = 0,                  # \mu_0 (sic!)
            conf.level  = 1-alpha_0)          # \delta = 1 - \alpha_0 (sic!)

# Ausgabe
print(varphi)

# Genauere Ausgabe t
paste(varphi[1])

# Genauere Ausgabe p
paste(varphi[3])
```


# Modellevaluation
\noindent (8) Analyse der Powerfunktion
\vfill
\justifying

\small
Wir betrachten die Testgütefunktion
\begin{equation}
q_\phi : \mathbb{R} \to [0,1],
\mu \mapsto q_\phi(\mu)
:= 1 - \psi(k_{\alpha_0}; \delta, n-1) + \psi(-k_{\alpha_0}; \delta, n-1)
\end{equation}
bei kontrolliertem Testumfang, also für $k_{\alpha_0} := \psi^{-1}(1-\alpha_0/2;n-1)$
mit festem $\alpha_0$ als Funktion des Nichtzentralitätsparameters und des
Stichprobenumfangs. Namentlich hängt hier $k_{\alpha_0}$ auch von $n$ ab.


Es ergibt sich die bivariate reellwertige Funktion
\begin{equation}
\pi : \mathbb{R} \times \mathbb{N} \to [0,1],
(\delta,n) \mapsto
\pi(\delta,n) := 1 - \psi(k_{\alpha_0}; \delta, n-1) + \psi(-k_{\alpha_0}; \delta, n-1)
\end{equation}
Bei festgelegten $\alpha_0$ hängt die Powerfunktion des zweiseitigen T-Tests
mit einfacher Nullhypothese also vom unbekannten Wert $\delta$ und von der
Stichprobengröße $n$ ab. Wir visualisieren diese Abhängigkeiten untenstehend.
\vfill

# Modellevaluation

(8) Analyse der Powerfunktion

\small
Powerfunktion für $\alpha_0 = 0.05$


```{r, eval = F, echo = F}

# circumvent RMarkdown Beamer Interaction
graphics.off()
fdir        =  file.path(getwd(), "9_Abbildungen")
dev.new()
par(
family      = "sans",
mfcol       = c(1,1),
pty         = "m",
bty         = "l",
lwd         = 1,
las         = 1,
xaxs        = "i",
yaxs        = "i",
font.main   = 1,
cex         = 1.2,
cex.main    = 1.2)

# Szenariospezifikation
d_min       = -5                                # delta Minimum
d_max       =  5                                # delta Maximum
d_res       = 50                                # delta Auflösung
delta       = seq(d_min, d_max, len = d_res)    # delta Raum
n_min       = 1                                 # n Minimum
n_max       = 30                                # n Maximum
n_res       = 50                                # n Auflösung
n           = seq(n_min,n_max, len = n_res)     # n Raum


# Visualisierung
alpha_0   = 0.05
pi        = matrix(rep(NaN, d_res*n_res), nrow = d_res)
for(i in 1:d_res){
  for(j in 1:n_res){
    k_alpha_0 = qt(1 - alpha_0/2, n[j]-1)
    pi[i,j]   = 1-pt(k_alpha_0, n[j]-1, delta[i])+pt(-k_alpha_0, n[j]-1, delta[i])
  }
}
persp(
delta,
n,
pi,
d           = 1,
col         = "gray90",
theta       = 21,
phi         = 30,
lwd         = .5,
scale       = T,
ticktype    = "detailed",
r           = 1.5)
dev.copy2pdf(
file        = file.path(fdir, "alm_9_t_test_ungerichtet_power_005.pdf"),
width       = 7,
height      = 7)
```

```{r, echo = FALSE, out.width = "60%"}
knitr::include_graphics("9_Abbildungen/alm_9_t_test_ungerichtet_power_005.pdf")
```

# Zweiseitige Einstichproben-T-Tests

(8) Analyse der Powerfunktion

\small
Powerfunktion für $\alpha_0 = 0.001$


```{r, eval = F, echo = F}

# circumvent RMarkdown Beamer Interaction
graphics.off()
fdir        =  file.path(getwd(), "9_Abbildungen")
dev.new()
par(
family      = "sans",
mfcol       = c(1,1),
pty         = "m",
bty         = "l",
lwd         = 1,
las         = 1,
xaxs        = "i",
yaxs        = "i",
font.main   = 1,
cex         = 1.2,
cex.main    = 1.2)

# Szenariospezifikation
d_min       = -5                                # delta Minimum
d_max       =  5                                # delta Maximum
d_res       = 50                                # delta Auflösung
delta       = seq(d_min, d_max, len = d_res)    # delta Raum
n_min       = 1                                 # n Minimum
n_max       = 30                                # n Maximum
n_res       = 50                                # n Auflösung
n           = seq(n_min,n_max, len = n_res)     # n Raum

# Visualisierung
alpha_0   = 0.001
pi        = matrix(rep(NaN, d_res*n_res), nrow = d_res)
for(i in 1:d_res){
  for(j in 1:n_res){
    k_alpha_0 = qt(1 - alpha_0/2, n[j]-1)
    pi[i,j]   = 1-pt(k_alpha_0, n[j]-1, delta[i])+pt(-k_alpha_0, n[j]-1, delta[i])
  }
}
persp(
delta,
n,
pi,
d           = 1,
col         = "gray90",
theta       = 21,
phi         = 30,
lwd         = .5,
scale       = T,
ticktype    = "detailed",
r           = 1.5)
dev.copy2pdf(
file        = file.path(fdir, "alm_9_t_test_ungerichtet_power_0001.pdf"),
width       = 7,
height      = 7)
```

```{r, echo = FALSE, out.width = "60%"}
knitr::include_graphics("9_Abbildungen/alm_9_t_test_ungerichtet_power_0001.pdf")
```

# Modellevaluation
(8) Analyse der Powerfunktion

\small
\justifying

Powerfunktionen für $\mu_0 = 0$
\vspace{2mm}

```{r, echo = F, eval = F}
dev.new()
graphics.off()
par(
family      = "sans",
mfcol       = c(2,2),
pty         = "m",
bty         = "l",
lwd         = 1,
las         = 1,
xaxs        = "i",
yaxs        = "i",
font.main   = 1,
cex         = 1,
cex.main    = 1)

# Szenariospezifikation
mu_0      = 0                                 # einfache Nullhypothese
d_min     = -5                                # d  Minimum
d_max     =  5                                # d Maximum
d_res     = 50                                # d Auflösung
d         = seq(d_min, d_max, len = d_res)    # d Raum
n_min     = 2                                 # n Minimum
n_max     = 50                                # n Maximum
n_res     = 1e2                               # n Auflösung
n         = seq(n_min,n_max, len = n_res)     # n Raum


# Funktion von d, n = 12, \alpha_0 = 0.05
alpha_0   = 0.05
n_fix     = 12
k_alpha_0 = qt(1 - alpha_0/2, n_fix-1)
pi_d      = 1-pt(k_alpha_0, n_fix-1, d)+pt(-k_alpha_0, n_fix-1, d)
plot(
d,
pi_d,
type      = "l",
lwd       = 2,
ylim      = c(0,1),
ylab      = " ",
xlab      = TeX("$\\delta$"),
main      = TeX("$\\pi(d,n = 12),\\, \\alpha_0 = 0.05$"))

# Funktion von d, n = 12, \alpha_0 = 0.001
alpha_0   = 0.001
n_fix     = 12
k_alpha_0 = qt(1-alpha_0/2, n_fix-1)
pi_d      = 1-pt(k_alpha_0, n_fix-1, d)+pt(-k_alpha_0, n_fix-1, d)
plot(
d,
pi_d,
type      = "l",
lwd       = 2,
ylim      = c(0,1),
ylab      = " ",
xlab      = TeX("$\\delta$"),
main      = TeX("$\\pi(d,n = 12),\\, \\alpha_0 = 0.001$"))

# Funktion von n, \delta = 3, \alpha_0 = 0.05
alpha_0   = 0.05
d_fix     = 3
k_alpha_0 = qt(1-alpha_0/2, n-1)
pi_n      = 1-pt(k_alpha_0, n-1, d_fix)+pt(-k_alpha_0, n-1, d_fix)
plot(
n,
pi_n,
type      = "l",
lwd       = 2,
ylab      = " ",
ylim      = c(0,1),
xlab      = TeX("$n$"),
main      = TeX("$\\pi(\\delta = 3,n),\\, \\alpha_0 = 0.05$"))

# Funktion von n, \delta = 3, \alpha_0 = 0.001
alpha_0   = 0.001
d_fix     = 3
k_alpha_0 = qt(1-alpha_0/2, n-1)
pi_n      = 1-pt(k_alpha_0, n-1, d_fix)+pt(-k_alpha_0, n-1, d_fix)
plot(
n,
pi_n,
type      = "l",
lwd       = 2,
ylab      = " ",
ylim      = c(0,1),
xlab      = TeX("$n$"),
main      = TeX("$\\pi(\\delta = 3,n),\\, \\alpha_0 = 0.001$"))

dev.copy2pdf(
file        = file.path(fdir, "alm_9_t_test_ungerichtet_powerfunktionen.pdf"),
width       = 8,
height      = 7)

```

```{r, echo = FALSE, out.width = "65%"}
knitr::include_graphics("9_Abbildungen/alm_9_t_test_ungerichtet_powerfunktionen.pdf")
```


# Modellevaluation

\noindent (8) Analyse der Powerfunktion

Praktisches Vorgehen
\small

Mit größerem $n$ steigt die Powerfunktion des Tests an

* Ein großer Stichprobenumfang ist besser als ein kleiner Stichprobenumfang.

* Kosten für die Erhöhung des Stichprobenumfangs werden aber nicht berücksichtigt.

$\Rightarrow$ Die Theorie statistischer Hypothesentests ist nicht besonders lebensnah.

\vspace{1mm}

Die Powerfunktion hängt vom wahren, aber unbekannten, Wert $\delta = \sqrt{n}\frac{\mu - \mu_0}{\sigma}$ ab.

$\Rightarrow$ Wenn man $\delta$ schon kennen würde, würde man den Test nicht durchführen.

\vspace{1mm}

Generell wird folgendes Vorgehen favorisiert

* Man legt das Signifikanzniveau $\alpha_0$ fest und evaluiert die Powerfunktion.

* Man wählt einen Mindestparameterwert $\delta^*$, den man mit $\pi(\delta,n) = b$ detektieren möchte.

* Ein konventioneller Wert ist $b = 0.8$.

* Man liest die für $\pi(\delta = \delta^*,n) = b$ nötige Stichprobengröße $n$ ab.


# Modellevaluation

\noindent (8) Analyse der Powerfunktion

Praktisches Vorgehen
\vspace{5mm}

```{r, echo = F, eval = F}

# Szenariospezifikation
sigma     = 1                                                       # bekanntes \sigma
mu_0      = 0                                                       # einfache Nullhypothese
n_min     = 2                                                       # n Minimum
n_max     = 20                                                      # n Maximum
n_res     = 1e2                                                     # n Auflösung
n         = seq(n_min,n_max, len = n_res)                           # n Raum
alpha_0   = 0.05                                                    # Signifikanzniveau

# Poweranalyse
d_fix     = 3                                                       # fester Nichtzentralitätsparameter
k_alpha_0 = qt(1-alpha_0/2, n-1)                                    # kritische Werte
pi_n      = 1-pt(k_alpha_0, n-1, d_fix)+pt(-k_alpha_0, n-1, d_fix)  # Powerfunktion
beta      = 0.8                                                     # gewünschter Powerfunktionswert
i         = 1                                                       # Indexinitialisierung
n_min     = NaN                                                     # minimales n Initialisierung
while(pi_n[i] < beta){                                              # Solange \pi(d*,n) < \beta
    n_min = n[i]                                                    # Aufnahme des minimal nötigen ns
    i     = i + 1                                                   # und Erhöhung des Indexes
}
cat("Minimal nötiges n =", ceiling(n_min))                          # Ausgabe
```

```{r, echo = F, eval = F}
dev.new()
graphics.off()
par(
family      = "sans",
mfcol       = c(1,1),
pty         = "m",
bty         = "l",
lwd         = 1,
las         = 1,
xaxs        = "i",
yaxs        = "i",
font.main   = 1,
cex         = 1.2,
cex.main    = 1.2)

plot(
n,
pi_n,
type        = "l",
lwd         = 2,
ylab        = " ",
ylim        = c(0,1),
xlab        = TeX("$n$"),
main        = TeX("$\\pi(\delta = 3,n)\\, für \\,\\alpha_0 = 0.05,\\, \\mu_0 = 0"))

lines(
2,
beta,
type        = "p",
pch         = 16,
xpd         = TRUE)

lines(
n_min,
0,
type        = "p",
pch         = 16,
xpd         = TRUE)

arrows(
x0          = min(n),
y0          = beta,
x1          = n_min,
y1          = beta,
col         = "darkorange",
angle       = 20,
length      = .1)

arrows(
x0          = n_min,
y0          = beta,
x1          = n_min,
y1          = 0,
col         = "darkorange",
angle       = 20,
length      = .1)
text(3 , 0.85 , TeX("$b$") ,xpd = TRUE, cex = 1.2)
text(20 ,.05  , TeX("$n_{opt}") ,xpd = TRUE, cex = 1.2)

dev.copy2pdf(
file        = file.path(fdir, "alm_9_t_test_ungerichtet_stichprobengroesse.pdf"),
width       = 6,
height      = 5)

```

```{r, echo = FALSE, out.width = "60%"}
knitr::include_graphics("9_Abbildungen/alm_9_t_test_ungerichtet_stichprobengroesse.pdf")
```


# {.plain}
\large
\setstretch{3}
\vfill
Überblick

Einstichproben-T-Tests

**Zweistichproben-T-Tests**

Selbstkontrollfragen
\vfill

# {.plain}
\center
\huge
\vfill
\noindent Zweistichproben-T-Tests
\vfill

# Zweistichproben-T-Tests
\large
\setstretch{3}
\vfill
Anwendungsszenario

Modellformulierung

Modellschätzung

Modellevaluation
\vfill


# Zweistichproben-T-Tests
\large
\setstretch{3}
\vfill
**Anwendungsszenario**

Modellformulierung

Modellschätzung

Modellevaluation
\vfill

# Anwendungsszenario
**\textcolor{darkblue}{Zwei Gruppen}** (Stichproben) randomisierter experimenteller Einheiten.

Annahme unabhängiger identischer Normalverteilungen $N(\mu_1,\sigma^2)$ und $N(\mu_2,\sigma^2)$.

$\mu_1,\mu_2$ und $\sigma^2$ unbekannt.

Annahme eines identischen Varianzparameters für beide Gruppen.

Quantifizieren der Unsicherheit beim inferentiellen Vergleich von $\mu_1$ mit $\mu_2$ beabsichtigt.

\vspace{2mm}
\textcolor{darkblue}{Anwendungsbeispiele}

\small
BDI Differenzwert Datenanalyse bei zwei Gruppen von Patient:innen
\vspace{-2mm}

* Gruppe 1 Face-to-Face Therapie, Gruppe 2 Online Therapie
* $\mu_1 \neq \mu_2 \Leftrightarrow$ Unterscheiden sich die Therapiewirksamkeiten?

Forcierte Schwimmtestdatenanalyse bei zwei Gruppen genmanipulierter Mäuse
\vspace{-2mm}

* Gruppe 1 Wildtyp, Gruppe 2 Serotoninrezeptormutation
* $\mu_1 \neq \mu_2 \Leftrightarrow$ Trägt Serotoninrezeptor zum Schwimmtestverhalten bei?

# Anwendungsszenario
\small

Wir betrachten das Anwendungsbeispiel aus Einheit (8) Studiendesign und fokussieren
auf die Gruppen (= Stichproben, Experimentalbedingungen) der Face-to-Face und
der Online Therapie. Wir betrachten dabei wieder den Datensatz der negativen
PostBDI-PreBDI Differenzwerte mit Variablennamen "BDI".
\vspace{3mm}

Wir nehmen an, dass die Datenpunkte der Face-to-Face Therapiegruppe u.i.v.
Realisierungen von ZVen $y_{1j} \sim N(\mu_1,\sigma^2)$ für $j = 1,...,40$ und
dass die Datenpunkte der Online Therapiegruppe u.i.v. Realisierungen von ZVen
$y_{2j} \sim N(\mu_2,\sigma^2)$ für $j = 1,...,40$ sind. Wir nehmen weiter an,
dass wir an der Quantifizierung der Unsicherheit beim inferentiellen Vergleich
der wahren, aber unbekannt, Erwartungswertparameter $\mu_1$ und $\mu_2$ im Sinne
eines Hypothesentests interessiert sind.
\vspace{3mm}


Im Folgenden evaluieren den hier betrachteten Datensatz zunächst im Sinne deskriptiver
Statistiken, siehe dazu auch Einheit (11) Anwendungsbeispiel in Programmierung
und Deskriptive Statistik.


# Anwendungsszenario
\vspace{3mm}
\small
\textcolor{darkblue}{Dateneinlesen $\vert$ $j = 1,...,20$ für jede Gruppe}
\setstretch{.6}
\tiny
\vspace{1mm}
```{r}
fname       = file.path(getwd(), "9_Daten", "data_9_t_tests.csv")
D           = read.table(fname, sep = ",", header = TRUE)
```
\vspace{-1mm}
```{r, echo = F}
# table visualization
knitr::kable(D[c(1:20, 41:60),],
             align      = "ccc",
             "pipe")
```

# Anwendungsszenario
\vspace{3mm}
\small
\textcolor{darkblue}{Histogramme}
\setstretch{.5}
\tiny
\vspace{1mm}

```{r, eval = F}
# Histogrammparameter
h           = 1                               # gewünschte Klassenbreite
b_0         = min(D$BDI)                      # b_0
b_k         = max(D$BDI)                      # b_0
k           = ceiling((b_k - b_0)/h)          # Anzahl der Klassen
b           = seq(b_0, b_k, by = h)           # Klassen [b_{j-1}, b_j[
ylimits     = c(0,.25)                        # y-Achsenlimits
xlimits     = c(-2,14)                        # x-Achsenlimits
therapie    = c("F2F" , "ONL")                # Therapiebedingungen
labs        = c("Face-to-Face",               # Abbildungslabel
                "Online")

# Abbildungsparameter
par(                                          # für Details siehe ?par
mfcol       = c(1,2),                         # 1 x 2 Panelstruktur
family      = "sans",                         # Serif-freier Fonttyp
pty         = "m",                            # Maximale Abbildungsregion
bty         = "l",                            # L förmige Box
las         = 1,                              # Horizontale Achsenbeschriftung
xaxs        = "i",                            # x-Achse bei y = 0
yaxs        = "i",                            # y-Achse bei x = 0
font.main   = 1,                              # Non-Bold Titel
cex         = 1,                              # Textvergrößerungsfaktor
cex.main    = 1)                              # Titeltextvergrößerungsfaktor

# Iteration über Therapiebedingungen
for(i in 1:2){
  hist(
  D$BDI[D$Condition == therapie[i]],          # Werte von Therapiebedingung i
  breaks    = b,                              # Histogrammklassen
  freq      = F,                              # normierte relative Häufigkeit
  xlim      = xlimits,                        # x-Achsenlimits
  ylim      = ylimits,                        # y-Achsenlimits
  xlab      = TeX("BDI"),                     # x-Achsenbeschriftung
  ylab      = "",                             # y-Achsenbeschriftung
  main      = labs[i])                        # Titelbeschriftung
}

# PDF Speicherung
dev.copy2pdf(
file        = file.path(getwd(), "9_Abbildungen", "alm_9_F2F_ONL_histogramme.pdf"),
width       = 8,
height      = 4)
```

# Anwendungsszenario
\vspace{3mm}
\small
\textcolor{darkblue}{Deskriptive Statistiken}
\setstretch{1}
\tiny
\vspace{1mm}

```{r, echo = T}
# Initialisierung eines Dataframes
tp            = c("F2F", "ONL")                     # Therapiebedingungen
ntp           = length(tp)                          # Anzahl Therapiebedingungen
S             = data.frame(                         # Dataframeerzeugung
                n         = rep(NaN,ntp),           # Stichprobengrößen
                Max       = rep(NaN,ntp),           # Maxima
                Min       = rep(NaN,ntp),           # Minima
                Median    = rep(NaN,ntp),           # Mediane
                Mean      = rep(NaN,ntp),           # Mittelwerte
                Var       = rep(NaN,ntp),           # Varianzen
                Std       = rep(NaN,ntp),           # Standardabweichungen
                row.names = tp)                     # Therapiebedingungen

# Iterationen über Therapiebedingungen
for(i in 1:ntp){
  data        = D$BDI[D$Condition == tp[i]]         # Daten
  S$n[i]      = length(data)                        # Stichprobengröße
  S$Max[i]    = max(data)                           # Maxima
  S$Min[i]    = min(data)                           # Minima
  S$Median[i] = median(data)                        # Mediane
  S$Mean[i]   = mean(data)                          # Mittelwerte
  S$Var[i]    = var(data)                           # Varianzen
  S$Std[i]    = sd(data)                            # Standardabweichungen
}
```

# Anwendungsszenario
\small
\vspace{2mm}
\textcolor{darkblue}{Deskriptive Statistiken der PostBDI-PreBDI Differenzen bei Face-to-Face und Online Therapie}
\vspace{1mm}

```{r, echo = FALSE, out.width = "95%"}
knitr::include_graphics("9_Abbildungen/alm_9_F2F_ONL_histogramme.pdf")
```

\setstretch{1}
\footnotesize
```{r}
# Ausgabe
print.AsIs(S)
```

# Zweistichproben-T-Tests
\large
\setstretch{3}
\vfill
Anwendungsszenario

**Modellformulierung**

Modellschätzung

Modellevaluation
\vfill

# Modellformulierung
\footnotesize
\begin{definition}[Zweistichproben-T-Test Modell]
\justifying
$y_{ij}$ mit $i = 1,2$ und $j = 1,...,n_i$ seien Zufallsvariablen, die die Datenpunkte
eines Zweistichproben-T-Test Anwendungsszenarios modellieren. Dann hat das
\textit{Zweistichproben-T-Test Modell} die strukturelle Form
\begin{equation}
y_{ij} = \mu_i + \varepsilon_{ij}
\mbox{ mit } \varepsilon_{ij} \sim N(0,\sigma^2)
\mbox{ u.i.v. für } i = 1,2, j = 1,...,n_i \mbox{ mit } \mu_i \in \mathbb{R} \mbox{ und } \sigma^2 > 0,
\end{equation}
die Datenverteilungsform
\begin{equation}
y_{ij} \sim N(\mu_i,\sigma^2)
\mbox{ u.i.v. für } i = 1,2, j = 1,...,n_i \mbox{ mit } \mu_i \in \mathbb{R} \mbox{ und } \sigma^2 > 0,
\end{equation}
und für den Datenvektor $y = (y_{11}, ...,y_{1n_1}, y_{21}, ...,y_{2n_2})^T$ und $n := n_1 + n_2$ die Designmatrixform
\begin{equation}
y = X\beta + \varepsilon \mbox{ mit }
X     := \begin{pmatrix} 1_{n_1} & 0_{n_1} \\ 0_{n_2} & 1_{n_2} \end{pmatrix} \in \mathbb{R}^{n \times 2},
\beta := \begin{pmatrix} \mu_1 \\ \mu_2 \end{pmatrix} \in \mathbb{R}^2,
\varepsilon \sim N(0_n,\sigma^2I_n),
\sigma^2 > 0.
\end{equation}
\end{definition}

Bemerkungen

* $i$ indiziert die Gruppen, $j$ indiziert die Daten in jeder Gruppe.
* $n_1$ und $n_2$ repräsentieren die Gruppengrößen, $n$ repräsentiert die Gesamtanzahl an Datenpunkten.
* Es ist $p = 2$.
* Die Äquivalenz der drei Modellformen ergibt sich mit den Ergebnissen Einheit (5) Modellformulierung.

# Modellformulierung
\small
Datensimulation (vgl. Einheit (5) Modellformulierung)
\vspace{4mm}

\footnotesize
\setstretch{1.2}
```{r}
# Libraries
library(MASS)                                # Multivariate Normalverteilung

# Modellformulierung
n_1    = 40                                  # Anzahl von Datenpunkten Gruppe 1
n_2    = 40                                  # Anzahl von Datenpunkten Gruppe 2
n      = n_1 + n_2                           # Gesamtanzahl Datenpunkte
p      = 2                                   # Anzahl von Betaparameter
X      = matrix(c(rep(1,n_1), rep(0,n_1),    # Designmatrix
                  rep(0,n_2), rep(1,n_2)),
                  nrow  = n)
I_n    = diag(n)                             # n x n Einheitsmatrix
beta   = matrix(c(1,2), nrow = p)            # wahrer, aber unbekannter, Betaparameter
sigsqr = 14                                  # wahrer, aber unbekannter, Varianzparameter

# Datenrealisierung
y      = mvrnorm(1, X %*% beta, sigsqr*I_n)  # eine Realisierung eines n-dimensionalen ZVs
```

# Zweistichproben-T-Tests
\large
\setstretch{3}
\vfill
Anwendungsszenario

Modellformulierung

**Modellschätzung**

Modellevaluation
\vfill


# Modellschätzung
\footnotesize
\begin{theorem}[Parameterschätzung im Zweistichproben-T-Test Modell]
\normalfont
\justifying
Gegeben sei die Designmatrixform des Zweistichproben-T-Test Modells. Dann ergeben
sich für den Betaparameterschätzer
\begin{equation}
\hat{\beta}
=  \begin{pmatrix} \frac{1}{n_1}\sum_{j=1}^{n_1} y_{1j} \\  \frac{1}{n_2}\sum_{j=1}^{n_2} y_{2j} \end{pmatrix}
=: \begin{pmatrix} \bar{y}_1 \\  \bar{y}_2 \end{pmatrix}
\end{equation}
und für den Varianzparameterschätzer
\begin{equation}
\hat{\sigma}^2_{12}
= \frac{\sum_{j=1}^{n_1} (y_{1j} - \bar{y}_1)^2 + \sum_{j=1}^{n_2} (y_{2j} - \bar{y}_2)^2}{n_1+n_2-2}
=: s_{12}^2
\end{equation}
\end{theorem}
Bemerkungen

* \justifying $\bar{y}_1$ und $\bar{y}_2$ bezeichnen die gruppenspezifischen Stichprobenmittel.
* $s_{12}^2$ wird als \textit{gepoolte Stichprobenvarianz} bezeichnet.
* Für einen Datensatz $y = (y_1,y_2)^T \in \mathbb{R}^{n_1 + n_2}$ gilt allgemeinen,
  dass $s_y^2 \neq s_{12}^2$; die gepoolte Stichprobenvarianz und die Stichprobenvarianz eines
  konkatenierten  Datensatzes sind im Allgemeinen also nicht identisch. Wir wollen das Konzept
  der gepoolten Stichprobenvarianz hier aber nicht weiter vertiefen.

# Modellschätzung
\footnotesize
\underline{Beweis}

Für $i = 1,2$ sei $y_i := (y_{i1},...,y_{in_i})^T$. Dann ergibt sich für den Betaparameterschätzer
\begin{align}
\begin{split}
\hat{\beta}
& = (X^{T}X)^{-1}X^{T}y
\\
& = \left(
\begin{pmatrix} 1_{n_1} & 0_{n_2} \\ 0_{n_1} & 1_{n_2} \end{pmatrix}
\begin{pmatrix} 1_{n_1} & 0_{n_1} \\ 0_{n_2} & 1_{n_2} \end{pmatrix}
\right)^{-1}
\begin{pmatrix} 1_{n_1} & 0_{n_2} \\ 0_{n_1} & 1_{n_2} \end{pmatrix}
\begin{pmatrix} y_1 \\ y_2 \end{pmatrix}
\\
& =
\begin{pmatrix}
n_1 	& 0		\\
0 		& n_2	\\
\end{pmatrix}^{-1}
\begin{pmatrix}
\sum_{j=1}^{n_1} y_{1j} \\
\sum_{j=1}^{n_2} y_{2j} \\
\end{pmatrix}
\\
& = \begin{pmatrix}
n_1^{-1} 	& 0			\\
0 			& n_2^{-1}	\\
\end{pmatrix}
\begin{pmatrix}
\sum_{j=1}^{n_1} y_{1j} \\
\sum_{j=1}^{n_2} y_{2j} \\
\end{pmatrix} \\
& =\begin{pmatrix}
\frac{1}{n_1}\sum_{j=1}^{n_1} y_{1j} \\
\frac{1}{n_2}\sum_{j=1}^{n_2} y_{2j} \\
\end{pmatrix}
\\
& =: \begin{pmatrix} \bar{y}_1 \\  \bar{y}_2 \end{pmatrix}.
\end{split}
\end{align}



# Modellschätzung
\footnotesize
\underline{Beweis (fortgeführt)}

Gleichsam ergibt sich für Varianzparameterschätzer mit $n = n_1 + n_2$ und $p = 2$
\begin{align}
\begin{split}
\hat{\sigma}^{2}
& =
\frac{(y-X\hat{\beta})^T(y - X\hat{\beta})}{n - p} \\
& =
\frac{1}{n_1+n_2-2}
\left(
\begin{pmatrix} y_1 \\ y_2 \end{pmatrix}
-
\begin{pmatrix} 1_{n_1} & 0_{n_1} \\ 0_{n_2} & 1_{n_2} \end{pmatrix}
\begin{pmatrix}
\bar{y}_{1}\\
\bar{y}_{2}\\
\end{pmatrix}
\right)^{T}
\left(
\begin{pmatrix} y_1 \\ y_2 \end{pmatrix}
-
\begin{pmatrix} 1_{n_1} & 0_{n_1} \\ 0_{n_2} & 1_{n_2} \end{pmatrix}
\begin{pmatrix}
\bar{y}_{1}\\
\bar{y}_{2}\\
\end{pmatrix} \right) \\
& =\frac{1}{n_1+n_2-2}
\begin{pmatrix}
y_{11}-\bar{y}_{1}\\
\vdots \\
y_{1n_1}-\bar{y}_{1}\\
y_{21}-\bar{y}_{2}\\
\vdots \\
y_{2n_2}-\bar{y}_{2}\\
\end{pmatrix}^{T}
\begin{pmatrix}
y_{11}-\bar{y}_{1}\\
\vdots \\
y_{1n_1}-\bar{y}_{1}\\
y_{21}-\bar{y}_{2}\\
\vdots \\
y_{2n_2}-\bar{y}_{2}\\
\end{pmatrix} \\
& = \frac{
    \sum_{j=1}^{n_1} (y_{1j}-\bar{y}_{1})^{2}
   +\sum_{j=1}^{n_2} (y_{2j}-\bar{y}_{2})^{2}
   }{n_1+n_2-2}
\\
& =: s_{12}^2.
\end{split}
\end{align}

# Modellschätzung
\tiny
\vspace{2mm}
\setstretch{1}
```{r}
# Dateneinlesen
fname      = file.path(getwd(), "9_Daten", "data_9_t_tests.csv")  # Dateiname
D          = read.table(fname, sep = ",", header = TRUE)          # Dataframe
y_1        = D$BDI[D$Condition == "F2F"]                          # BDI Differenzwerte in der F2F Gruppe
y_2        = D$BDI[D$Condition == "ONL"]                          # BDI Differenzwerte in der ONL Gruppe

# Modellformulierung
n_1        = length(y_1)                                          # Anzahl Datenpunkte Gruppe 1 (F2F)
n_2        = length(y_1)                                          # Anzahl Datenpunkte Gruppe 2 (ONL)
n          = n_1 + n_2                                            # Gesamtanzahl Datenpunkte
y          = matrix(c(y_1, y_2), nrow = n)                        # Datenvektor
p          = 2                                                    # Anzahl Betaparameter
X          = matrix(c(rep(1,n_1), rep(0,n_1),                     # Designmatrix
                      rep(0,n_2), rep(1,n_2)),
                      nrow  = n)

# Modellschätzung
beta_hat   = solve(t(X) %*% X) %*% t(X) %*% y                     # Betaparameterschätzer
eps_hat    = y - X %*% beta_hat                                   # Residuenvektor
sigsqr_hat = (t(eps_hat) %*% eps_hat) /(n-p)                      # Varianzparameterschätzer
s_sqr_12   = ((n_1-1)*var(y_1) + (n_2-1)*var(y_2))/(n_1+n_2-2)    # gepoolte Stichprobenvarianz

# Ausgabe
cat("hat{beta}          : "  , paste(beta_hat),                   # Betaparameterschätzer
    "\nbar{y}_1, bar{y_2} : ", paste( c(mean(y_1), mean(y_2))),   # Stichprobenmittel
    "\nhat{sigsqr}        : ", paste(sigsqr_hat),                 # Varianzparameterschätzer
    "\ns_12^2             : ", paste(s_sqr_12),                   # gepoolte Stichprobenvarianz
    "\ns_y^2              : ", paste(var(y)))                     # Stichprobenvarianz des konkatenierten Datensatzes
```


# Zweistichproben-T-Tests
\large
\setstretch{3}
\vfill
Anwendungsszenario

Modellformulierung

Modellschätzung

**Modellevaluation**
\vfill


# Modellevaluation
\small
\setstretch{1.6}
Überblick

\footnotesize

* Wir gruppieren frequentistische Konfidenzintervalle und Hypothesentests unter Modellevaluation.
* Wir verzichten an dieser Stelle auf eine Diskussion von Konfidenzintervallen
* In der Praxis zielt die Evaluation von Zweistichproben-T-Tests ALM Designs meist auf einen Hypothesentest.
* Die Theorie der Zweistichproben-T-Tests ist umfangreich, siehe dazu WTFI (14) Zweistichproben-T-Tests.
* Ein gutes Verständnis von WTFI Einheit (12) Hypothesentests wird im Folgenden vorausgesetzt.

Im Zweistichproben-T-Test ALM Design ergeben sich folgende Hypothesenszenarien

* $H_0:\mu_1 - \mu_2  =  \mu_0$ und $H_1: \mu_1 - \mu_2 \neq \mu_0$
* $H_0:\mu_1 - \mu_2 \le \mu_0$ und $H_1: \mu_1 - \mu_2 >    \mu_0$
* $H_0:\mu_1 - \mu_2 \ge \mu_0$ und $H_1: \mu_1 - \mu_2 <    \mu_0$

Wir betrachten hier nur exemplarisch $H_0:\mu_1 - \mu_2 = \mu_0$ und $H_1: \mu_1 - \mu_2 \neq \mu_0$

Für $\mu_0 := 0$ gelten dabei insbesondere

* $H_0:\mu_1 - \mu_2 =    0 \Leftrightarrow H_0: \mu_1 =    \mu_2$
* $H_0:\mu_1 - \mu_2 \neq 0 \Leftrightarrow H_0: \mu_1 \neq \mu_2$


# Modellevaluation
\setstretch{1.8}
\textcolor{darkblue}{Gliederung (vgl. WTFI Einheiten (12) - (14))}

(1) Statistisches Modell \checkmark

(2) Testhypothesen \checkmark

(3) Teststatistik

(4) Test

(5) Analyse der Testgütefunktion

(6) Testumfangkontrolle

(7) p-Werte

(8) Analyse der Powerfunktion



# Modellevaluation
\noindent (3) Teststatistik

\footnotesize
\begin{theorem}[T-Teststatistik des Zweistichproben-T-Tests]
\justifying
\normalfont
Gegeben sei die Designmatrixform des Zweistichproben-T-Tests. Dann ergibt sich
für die T-Teststatistik mit
\begin{equation}
c := (1,-1)^T \mbox{ und } c^T\beta_0 =: \mu_0,
\end{equation}
dass
\begin{equation}
T = \sqrt{\frac{n_1n_2}{n_1+n_2}}\left(\frac{\bar{y}_1-\bar{y}_2 - \mu_0}{s_{12}}\right)
\end{equation}
und es gilt
\begin{equation}
T \sim t(\delta, n_1 + n_2 - 2) \mbox{ mit } \delta = \sqrt{\frac{n_1n_2}{n_1+n_2}}\left(\frac{\mu_1-\mu_2-\mu_0}{\sigma}\right).
\end{equation}
\end{theorem}

Bemerkungen

* Das Theorem basiert auf dem T-Teststatistik Theorem in Einheit (7) Modellevaluation.

# Modellevaluation
\noindent (3) Teststatistik

\footnotesize
\underline{Beweis}

Mit dem  T-Teststatistik Theorem in Einheit (7) Modellevaluation gilt zunächst
für die Zähler von $T$ und $\delta$, dass
\begin{equation}
c^T\hat{\beta} - c^T\beta_0
= \begin{pmatrix} 1         &  - 1       \end{pmatrix}
  \begin{pmatrix} \bar{y}_1 \\ \bar{y}_2 \end{pmatrix}
  - \mu_0
= \bar{y}_1 - \bar{y}_2 - \mu_0
\end{equation}
und
\begin{equation}
c^T\beta - c^T\beta_0
= \begin{pmatrix} 1     &  - 1    \end{pmatrix}
  \begin{pmatrix} \mu_1 \\ \mu_2  \end{pmatrix}
  - \mu_0
= \mu_1 - \mu_2 - \mu_0,
\end{equation}
respektive. Weiterhin gilt für die Nenner von  $T$ und $\delta$, dass
\begin{equation}
c^T(X^TX)^{-1}c =
\begin{pmatrix*}[r] 1        & - 1 \end{pmatrix*}
\begin{pmatrix} n_1^{-1} & 0        \\
                0        & n_2^{-1}
\end{pmatrix}
\begin{pmatrix*}[r] 1       \\ - 1 \end{pmatrix*}
=
\begin{pmatrix*}[r] n_1^{-1} &  - n_2^{-1} \end{pmatrix*}
\begin{pmatrix*}[r] 1        \\ - 1 \end{pmatrix*}
= \frac{1}{n_1} + \frac{1}{n_2}
\end{equation}
Außerdem gilt
\begin{equation}
  \left(\frac{1}{n_1} + \frac{1}{n_2}\right)^{-\frac{1}{2}}
= \left(\frac{n_2}{n_1n_2} + \frac{n_1}{n_1n_2}\right)^{-\frac{1}{2}}
= \left(\frac{n_1 + n_2}{n_1n_2}\right)^{-\frac{1}{2}}
= \left(\frac{n_1n_2}{n_1+n_2}\right)^{\frac{1}{2}}
\end{equation}
Zusammengenommen folgt direkt, dass
\begin{equation}
T = \sqrt{\frac{n_1n_2}{n_1+n_2}}\left(\frac{\bar{y}_1-\bar{y}_2 - \mu_0}{s_{12}}\right)
\mbox{ und }
\delta = \sqrt{\frac{n_1n_2}{n_1+n_2}}\left(\frac{\mu_1-\mu_2-\mu_0}{\sigma}\right).
\end{equation}

# Modellevaluation
\noindent (4) Test

\footnotesize
\begin{definition}[Zweiseitiger Zweistichproben-T-Test]
\justifying
Gegeben sei das Zweistichproben-T-Test Modell. Für ein $\mu_0 \in \mathbb{R}$ seien
die einfache Nullhypothese und die zusammgensetzte Alternativhypothese gegeben durch
\begin{equation}
H_0 : \mu_1 - \mu_2 = \mu_0
\Leftrightarrow
\Theta_0 := \{(\mu_1,\mu_2) \in \mathbb{R}^2|\mu_1 - \mu_2 = \mu_0\}
\end{equation}
und
\begin{equation}
H_1 : \mu_1 - \mu_2 \neq \mu_0
\Leftrightarrow
\Theta_1 := \{(\mu_1,\mu_2) \in \mathbb{R}^2|\mu_1 - \mu_2 \neq \mu_0\},
\end{equation}
respektive. Weiterhin sei die T-Teststatistik definiert durch
\begin{equation}
T := \sqrt{\frac{n_1n_2}{n_1+n_2}}\left(\frac{\bar{y}_1-\bar{y}_2}{s_{12}}\right)
\end{equation}
Dann ist der zweiseitige \textit{Zweistichproben-T-Teststatistik} definiert als
der kritischen Wert-basierte Test
\begin{equation}
\phi(y) := 1_{\{|T| \ge k\}}.
\end{equation}
\end{definition}

Bemerkungen

* Ausführlicher handelt es sich um den *zweiseitigen Zweistichproben-T-Test mit ungerichteter Hypothese*.

# Modellevaluation
\setstretch{1.1}
\noindent (5) Analyse der Testgütefunktion

\footnotesize
\begin{theorem}[Testgütefunktion]
\justifying
\normalfont
Es sei $\phi$ der im obigen Modell formulierte Zweistichproben-T-Test. Dann ist
die Testgütefunktion von $\phi$ gegeben durch
\begin{multline}
q_{\phi} : \mathbb{R}^2 \to [0,1],
(\mu_1, \mu_2) \mapsto q_{\phi}(\mu_1, \mu_2)
\\ := 1 - \psi(k;\delta,n_1+n_2-2) + \psi(-k;\delta,n_1+n_2-2)
\end{multline}
wobei $\psi(\cdot; \delta, n_1+n_2-2)$  die KVF der nichtzentralen
$t$-Verteilung mit Nichtzentralitätsparameter
\begin{equation}
\delta := \sqrt{\frac{n_1n_2}{n_1+n_2}}\frac{\mu_1-\mu_2}{\sigma}
\end{equation}
und Freiheitsgradparameter $n_1+n_2-2$ bezeichnet.
\end{theorem}

Bemerkungen

* $q_{\phi}$ ist eine bivariate reellwertige Funktion.
* $q_{\phi}$ kann alternativ als univariate reellwertige Funktion von $\Delta := \mu_1 - \mu_2$ konzipiert werden.
* Im Vergleich zum Einstichprobenszenario gelten
\begin{equation}
n \hookrightarrow n_1+n_2-2,\quad\quad
\sqrt{n} \hookrightarrow \sqrt{\frac{n_1n_2}{n_1 + n_2}},\quad\quad
\mu - \mu_0  \hookrightarrow \mu_1 - \mu_2
\end{equation}
* Für einen Beweisansatz, siehe @degroot_2012 Seite 591.

# Modellevaluation
\setstretch{1.1}
\noindent (5) Analyse der Testgütefunktion
\vfill

\center Testgütefunktion $q_\phi$ für $\sigma^2 = 9, n_1 = 12, n_2 = 12$.
\vspace{2mm}
\begin{equation*}
q_{\phi}(\mu) = \mathbb{P}_\mu(\phi = 1)
\end{equation*}
\vspace{1mm}

```{r, eval = F, echo = F}

# Abbildungsparameter
graphics.off()
dev.new()
par(
family      = "sans",
mfcol       = c(1,3),
pty         = "m",
bty         = "l",
lwd         = 1,
las         = 1,
xaxs        = "i",
yaxs        = "i",
font.main   = 1,
cex         = .4,
cex.main    = 2)

# Visualisierung
k_all        = c(1,2,3)                                                          # kritische Werte
n_1         = 12                                                                 # Stichprobengröße n_1
n_2         = 12                                                                 # Stichprobengröße n_2
sigsqr      = 9                                                                  # Varianzparameter
mu_min      = -5                                                                 # Minimum   \mu_1,\mu_2
mu_max      = 5                                                                  # Minimum   \mu_1,\mu_2
mu_res      = 2e1                                                                # Auflösung \mu_1,\mu_2
mu_1        = seq(mu_min, mu_max, len = mu_res)                                  # \mu_1
mu_2        = seq(mu_min, mu_max, len = mu_res)                                  # \mu_2


# kritischer Wert Iterationen
for(k in k_all){
  q_phi       = matrix(rep(NaN, mu_res*mu_res), nrow = mu_res)                   # q_\phi Array
  for(i in seq_along(mu_1)){                                                     # \mu_1 Iterationen
    for(j in seq_along(mu_2)){                                                   # \mu_2 Iterationen
      d           = (mu_1[i] - mu_2[j])/sqrt(sigsqr)                             # Nichtzentralitätsparameter \delta
      df          = n_1 + n_2 - 2                                                # Freiheitsgradparameter
      q_phi[i,j]  = 1-pt(k,df,d)+pt(-k,df,d)                                     # q_\phi
    }
  }
  persp(
  mu_1,
  mu_2,
  q_phi,
  d           = 1,
  col         = "gray90",
  theta       = 20,
  phi         = 30,
  lwd         = .5,
  scale       = T,
  ticktype    = "detailed",
  r           = 1.5,
  zlim        = c(0,1),
  main        = paste("k =", k))
}
dev.copy2pdf(
file        = file.path(fdir, "alm_9_t_test_q_phi_zweistichproben.pdf"),
width       = 6,
height      = 2)

```

```{r, echo = FALSE, out.width = "100%"}
knitr::include_graphics("9_Abbildungen/alm_9_t_test_q_phi_zweistichproben.pdf")
```
\vfill

# \small Modellevaluation
\noindent (6) Testumfangkontrolle
\vfill
\small
\begin{theorem}[Testumfangkontrolle]
\justifying
\normalfont
$\phi$ sei der im obigen Testszenario definierte Test. Dann ist $\phi$ ein
Level-$\alpha_0$-Test mit Testumfang $\alpha_0$, wenn der kritische Wert
definiert ist durch
\begin{equation}
k_{\alpha_0} := \psi^{-1}\left(1 - \frac{\alpha_0}{2}; n_1 + n_2 - 2 \right),
\end{equation}
wobei $\psi^{-1}(\cdot; n_1+n_2-2)$ die inverse KVF der $t$-Verteilung mit
$n_1+n_2-2$ Freiheitsgraden ist.
\end{theorem}

Bemerkungen

* Das Resultat folgt in Analogie zum Einstichproben-T-Test.
* Im Vergleich zum Einstichproben-T-Testfall gilt lediglich
\begin{equation}
n - 1 \hookrightarrow n_1 + n_2 - 2.
\end{equation}
\vfill

# Modellevaluation
\noindent (6) Testumfangkontrolle

\small
Praktisches Vorgehen
\footnotesize

\begin{itemize}
\itemsep1mm
\justifying

\item Man nimmt an, dass die Daten zweier Gruppen $\upsilon_{11},...,\upsilon_{1n_1}$
und $\upsilon_{21},...,\upsilon_{2n_2}$ Realisationen von
$y_{1j} \sim N(\mu_1,\sigma^2) \mbox{ u.i.v.  für } j = 1,...,n_1$ und
$y_{2j} \sim N(\mu_2,\sigma^2) \mbox{ u.i.v.  für } j = 1,...,n_2$
mit unbekannten Parametern $\mu_1,\mu_2,\sigma^2$ sind.

\item Man möchte entscheiden, ob eher $H_0 : \mu_1 - \mu_2 = \mu_0$ oder
$H_1: \mu_1 - \mu_2 \neq \mu_0$ zutrifft.

\item Man wählt ein Signifikanzniveau $\alpha_0$ und bestimmt den zugehörigen
Freiheitsgradparameter-abhängigen kritischen Wert $k_{\alpha_0}$. Zum Beispiel
gilt bei Wahl von $\alpha_0  := 0.05$ und $n_1=12, n_2 = 12$, also
Freiheitsgradparameter 12+12-2 = 22, dass $k_{0.05}=\psi^{-1}(1-0.05/2; 22)
\approx 2.07$ ist.

\item Anhand von $n_1,n_2,\bar{\upsilon}_1,\bar{\upsilon}_2$ und der gepoolten
Stichprobenstandardabweichung $s_{12}$ berechnet man die Realisierung der
Zweistichproben-T-Teststatistik
\begin{equation}
t := \sqrt{\frac{n_1n_2}{n_1+n_2}}\left(\frac{\bar{\upsilon}_1-\bar{\upsilon}_2}{s_{12}}\right)
\end{equation}

\item Wenn $t$ größer-gleich $k_{\alpha_0}$ ist oder wenn $t$ kleiner-
gleich $-k_{\alpha_0}$ ist, lehnt man die Nullhypothese ab, andernfalls lehnt
man sie nicht ab.

\item Die oben entwickelte Theorie des Zweistichproben-T-Tests garantiert dann,
dass man in höchstens $\alpha_0 \cdot 100$ von $100$ Fällen die Nullhypothese
fälschlicherweise ablehnt.
\end{itemize}

# Modellevaluation
(7) p-Werte

\small
Bestimmung des p-Wertes
\vspace{2mm}

\footnotesize
* \itemsep2mm \justifying \small Per Definition ist der p-Wert das kleinste
Signifikanzlevel $\alpha_0$, bei welchem man die Nullhypothese basierend auf
einem vorliegendem Wert der Teststatistik ablehnen würde.

* Bei $T = t$ würde $H_0$ für jedes $\alpha_0$ mit $|t|\ge\psi^{-1}(1-\alpha_0/2; n_1 + n_2-2)$
abgelehnt werden. Für diese $\alpha_0$ gilt, wie bereits mehrfach gezeigt,
\begin{equation}
\alpha_0 \ge 2 \mathbb{P}(T \ge |t|).
\end{equation}

* Das kleinste $\alpha_0 \in [0,1]$ mit $\alpha_0 \ge 2 \mathbb{P}(T \ge |t|)$ ist
dann $\alpha_0 = 2 \mathbb{P}(T \ge |t|)$, also folgt
\begin{equation}
\mbox{p-Wert} =  2 \mathbb{P}(T \ge |t|) = 2(1 - \psi(|t|;n_1 + n_2 - 2)).
\end{equation}

* Im Vergleich zum Einstichprobenfall gilt lediglich $n \hookrightarrow n_1 + n_2 -2$.


# Modellevaluation
\vspace{1mm}
\small
\textcolor{darkblue}{Anwendungszenario}
\vspace{1mm}
\setstretch{.8}
\tiny
```{r}
# Dateneinlesen
fname      = file.path(getwd(), "9_Daten", "data_9_t_tests.csv")  # Dateiname
D          = read.table(fname, sep = ",", header = TRUE)          # Dataframe
y_1        = D$BDI[D$Condition == "F2F"]                          # BDI Differenzwerte in der F2F Gruppe
y_2        = D$BDI[D$Condition == "ONL"]                          # BDI Differenzwerte in der ONL Gruppe

# Modellformulierung
n_1        = length(y_1)                                          # Anzahl Datenpunkte Gruppe 1 (F2F)
n_2        = length(y_1)                                          # Anzahl Datenpunkte Gruppe 2 (ONL)
n          = n_1 + n_2                                            # Gesamtanzahl Datenpunkte
y          = matrix(c(y_1, y_2), nrow = n)                        # Datenvektor
p          = 2                                                    # Anzahl Betaparameter
X          = matrix(c(rep(1,n_1), rep(0,n_1),                     # Designmatrix
                      rep(0,n_2), rep(1,n_2)),
                      nrow  = n)

# Modellschätzung
beta_hat   = solve(t(X) %*% X) %*% t(X) %*% y                     # Betaparameterschätzer
eps_hat    = y - X %*% beta_hat                                   # Residuenvektor
sigsqr_hat = (t(eps_hat) %*% eps_hat) /(n-p)                      # Varianzparameterschätzer

# Modellevaluation
c          = matrix(c(1,-1), nrow = 2)                            # Kontrastgewichtsvektor
mu_0       = 0                                                    # Nullhypothese H_0
alpha_0    = 0.05                                                 # Signifikanzniveau
k_alpha_0  = qt(1 - (alpha_0/2), n-1)                             # kritischer Wert
t_num      = t(c) %*% beta_hat - mu_0                             # T-Teststatistik Zähler
t_den      = sqrt(sigsqr_hat*t(c) %*% solve(t(X) %*% X)%*%c)      # T-Teststatistik Nenner
t          = t_num/t_den                                          # T-Teststatistik
if(abs(t) >= k_alpha_0){                                          # Test 1_{|T(X) >= k_alpha_0|}
    phi = 1                                                       # Ablehnen von H_0
} else {
    phi = 0                                                       # Nicht Ablehnen von H_0
}
pval      = 2*(1-pt(abs(t), n_1+n_2-2))                           # p-Wert
```
\vspace{-1mm}
```{r, echo = F}
cat("fg        = "  , n_1 + n_2 - 2,                               # Ausgabe
    "\nt         = ", t,
    "\nalpha_0   = ", alpha_0,
    "\nk_alpha_0 = ", k_alpha_0,
    "\nphi       = ", phi,
    "\np-Wert    = ", pval)
```
# Modellevaluation
\vspace{1mm}
\small
\textcolor{darkblue}{Anwendungszenario}
\vspace{1mm}
\setstretch{1}
\tiny
```{r}
# Automatischer Zweistichproben-T-Test
varphi    = t.test(                           # ?t.test für Details
            y_1,                              # Datensatz y_1
            y_2,                              # Datensatz y_2
            var.equal   = TRUE,               # \sigma_1^2 = \sigma_2^2
            alternative = c("two.sided"),     # H_1: \mu_1 \neq \mu_2
            conf.level  = 1-alpha_0)          # \delta = 1 - \alpha_0 (sic!)

# Ausgabe
print(varphi)

# Genauere Ausgabe t
paste(varphi[1])

# Genauere Ausgabe p
paste(varphi[3])
```



# Modellevaluation
\noindent (8) Analyse der Powerfunktion

\small
Wir betrachten die Testgütefunktion
\begin{multline}
q_{\phi} : \mathbb{R}^2 \to [0,1],
(\mu_1, \mu_2) \mapsto q_{\phi}(\mu_1, \mu_2)
\\ := 1 - \psi(k;\delta,n_1+n_2-2) + \psi(-k;\delta,n_1+n_2-2)
\end{multline}
als Funktion des Nichtzentralitätsparameters $\delta := \sqrt{\frac{n_1n_2}{n_1+n_2}}\frac{\mu_1-\mu_2}{\sigma}$ 
und der Summe der Stichprobenumfänge $n := n_1 + n_2$ bei kontrolliertem Testumfang, 
also für $k_{\alpha_0} := \psi^{-1}(1-\alpha_0/2;n-2)$ mit festem $\alpha_0$.
Es ergibt sich die multivariate reellwertige Funktion
\begin{multline}
\pi : \mathbb{R} \times \mathbb{N} \to [0,1],
(\delta,n) \mapsto
\pi(\delta,n) := 1-\psi(k_{\alpha_0};\delta,n-2)+\psi(-k_{\alpha_0}; \delta,n-2)
\end{multline}
Bei festgelegten $\alpha_0$ hängt die Powerfunktion des zweiseitigen T-Tests
mit einfacher Nullhypothese also vom unbekannten Wert $\delta$ und von der Summe der
Stichprobengrößen $n$ ab. De-facto handelt es sich also um die gleiche
Powerfunktion wie beim zweiseitigen Einstichproben-T-Test mit dem einzigen
Unterschied, dass für den Freiheitsgradparameter $n-2$ anstelle von $n-1$ gilt.
Wir verzichten auf eine erneute Visualisierung.
\vfill

# Modellevaluation

\noindent (8) Analyse der Powerfunktion

\setstretch{1.1}
\small

Praktisches Vorgehen

Mit größerem $n = n_1 + n_2$ steigt die Powerfunktion des Tests an

* Ein großer Stichprobenumfang ist besser als ein kleiner Stichprobenumfang.

* Kosten für die Erhöhung des Stichprobenumfangs werden aber nicht berücksichtigt.

* \justifying Ungleichgewichte zwischen $n_1$ und $n_2$ werden durch die Tatsache ausglichen,
dass Datenpunkte einer Stichproben auch zur Varianzschätzung in der anderen
Stichprobe beitragen, da eine identische Varianz vorausgesetzt wurde.

\vspace{1mm}

Die Powerfunktion hängt vom wahren, aber unbekannten, Wert $\delta = \sqrt{\frac{n_1n_2}{n_1+n_2}}\frac{\mu_1-\mu_2}{\sigma}$ ab.

$\Rightarrow$ Wenn man $\delta$ schon kennen würde, würde man den Test nicht durchführen.

\vspace{1mm}

Generell wird folgendes Vorgehen favorisiert

* Man legt das Signifikanzniveau $\alpha_0$ fest und evaluiert die Powerfunktion.

* Man wählt einen Mindestparameterwert $\delta^*$, den man mit $\pi(\delta,n) = b$ detektieren möchte.

* Ein konventioneller Wert ist $b= 0.8$.

* Man liest die für $\pi(\delta = \delta^*,n) = b$ nötige Stichprobengröße $n$ ab.


# Modellevaluation

\noindent (8) Analyse der Powerfunktion

\small
Praktisches Vorgehen
\vspace{5mm}

```{r, echo = F, eval = F}

# Szenariospezifikation
sigma     = 1                                                       # bekanntes \sigma
mu_0      = 0                                                       # einfache Nullhypothese
n_min     = 3                                                       # n = n_1 + n_2 Minimum
n_max     = 20                                                      # n = n_1 + n_2 Maximum
n_res     = 1e2                                                     # n Auflösung
n         = seq(n_min,n_max, len = n_res)                           # n Raum
alpha_0   = 0.05                                                    # Signifikanzniveau

# Poweranalyse
d_fix     = 3                                                       # fester Nichtzentralitätsparameter
k_alpha_0 = qt(1-alpha_0/2, n-2)                                    # kritische Werte
pi_n      = 1-pt(k_alpha_0, n-2, d_fix)+pt(-k_alpha_0, n-2, d_fix)  # Powerfunktion
beta      = 0.8                                                     # gewünschter Powerfunktionswert
i         = 1                                                       # Indexinitialisierung
n_min     = NaN                                                     # minimales n Initialisierung
while(pi_n[i] < beta){                                              # Solange \pi(d*,n) < \beta
    n_min = n[i]                                                    # Aufnahme des minimal nötigen ns
    i     = i + 1                                                   # und Erhöhung des Indexes
}
cat("Minimal nötiges n =", ceiling(n_min))                          # Ausgabe

```

```{r, echo = F, eval = F}
par(
family      = "sans",
mfcol       = c(1,1),
pty         = "m",
bty         = "l",
lwd         = 1,
las         = 1,
xaxs        = "i",
yaxs        = "i",
font.main   = 1,
cex         = 1.2,
cex.main    = 1.2)

plot(
n,
pi_n,
type        = "l",
lwd         = 2,
ylab        = " ",
ylim        = c(0,1),
xlab        = TeX("$n$"),
main        = TeX("$\\pi(\\delta = 3,n)\\, für \\,\\alpha_0 = 0.05"))

lines(
3,
beta,
type        = "p",
pch         = 16,
xpd         = TRUE)

lines(
n_min,
0,
type        = "p",
pch         = 16,
xpd         = TRUE)

arrows(
x0          = min(n),
y0          = beta,
x1          = n_min,
y1          = beta,
col         = "darkorange",
angle       = 20,
length      = .1)

arrows(
x0          = n_min,
y0          = beta,
x1          = n_min,
y1          = 0,
col         = "darkorange",
angle       = 20,
length      = .1)

text(3.5 , 0.85 , TeX("$b$") ,xpd = TRUE, cex = 1.2)
text(18  ,.05   , TeX("$n_{opt}") ,xpd = TRUE, cex = 1.2)

dev.copy2pdf(
file        = file.path(fdir, "alm_9_t_test_zweistichproben_umfang.pdf"),
width       = 8,
height      = 5)

```

```{r, echo = FALSE, out.width = "80%"}
knitr::include_graphics("9_Abbildungen/alm_9_t_test_zweistichproben_umfang.pdf")
```

# Selbstkontrollfragen
\footnotesize
\setstretch{1.2}
\begin{enumerate}
\justifying
\itemsep0mm
\item Erläutern Sie die Extremszenarien im Kontinuum von ALM Designs.
\item Erläutern Sie die Begriffe der faktoriellen und parametrischen ALM Designs.
\item Nennen Sie Beispiele für faktorielle, parametrische, und faktoriell-parametrische ALM Designs.
\item Erläutern Sie das Anwendungsszenario eines Einstichproben-T-Tests.
\item Erläutern Sie mögliche Hypothesenszenarien eines Einstichproben-T-Tests.
\item Geben Sie die Definition des Einstichproben-T-Test Modells wieder.
\item Geben Sie das Theorem zur Parameterschätzung im Einstichproben-T-Test Modell wieder.
\item Geben Sie das Theorem zur T-Teststatistik des Einstichproben-T-Tests wieder.
\item Geben Sie die Definition des zweiseitigen Einstichproben-T-Tests (mit ungerichteter Hypothese) wieder.
\item Skizzieren Sie die Testgütefunktion des zweiseitigen Einstichproben-T-Tests.
\item Geben Sie das Theorem zur Testumfangkontrolle im zweiseitigen Level-$\alpha_0$-Einstichproben-T-Test wieder.
\item Erläutern Sie das praktische Vorgehen bei Durchführung eines zweiseitigen Level-$\alpha_0$-Einstichproben-T-Tests.
\item Geben Sie die Definition des p-Wertes Werts für einen zweiseitigen Einstichproben-T-Test wieder.
\item Von welchen Werten hängt die Powerfunktion eines zweiseitigen Einstichproben-T-Tests ab?
\item Skizzieren Sie die Powerfunktion des zweiseitigen Einstichproben-T-Tests bei fester Stichprobengröße.
\item Skizzieren Sie die Powerfunktion des zweiseitigen Einstichproben-T-Tests bei festem Nichtzentralitätsparameter.
\item Betrachten Sie die PostBDI-PreBDI Differenzwertdaten der Waitlist Control Bedingung im Beispieldatensatz. Erstellen
Sie ein Histogramm dieser Daten und evaluieren Sie Ihnen bekannte deskriptive Statistiken zu diesen Daten. Führen Sie
einen zweiseitigen Einstichproben-T-Test mit Nullhypothesenparameter $\mu_0 = 0$ durch. Dokumentieren Sie Ihre Ergebnisse.
Was folgern Sie aus den sich ergebenen Resultaten?
\end{enumerate}


# Selbstkontrollfragen
\footnotesize
\setstretch{1.2}
\begin{enumerate}
\justifying
\itemsep0mm
\setcounter{enumi}{17}
\item Erläutern Sie das Anwendungsszenario eines Zweistichproben-T-Tests.
\item Geben Sie die Definition des Zweistichproben-T-Test Modells wieder.
\item Geben Sie das Theorem zur Parameterschätzung im Zweistichproben-T-Test Modell wieder.
\item Geben Sie das Theorem zur T-Teststatistik des Zweistichproben-T-Tests wieder.
\item Erläutern Sie mögliche Hypothesenszenarien eines Zweistichproben-T-Tests.
\item Geben Sie die Definition des zweiseitigen Zweistichproben-T-Tests (mit ungerichteter Hypothese) wieder.
\item Skizzieren Sie die Testgütefunktion des zweiseitigen Zweistichproben-T-Tests.
\item Geben Sie das Theorem zur Testumfangkontrolle im zweiseitigen Level-$\alpha_0$-Zweistichproben-T-Test wieder.
\item Erläutern Sie das praktische Vorgehen bei Durchführung eines zweiseitigen Level-$\alpha_0$-Zweistichproben-T-Tests.
\item Geben Sie die Definition des p-Wertes Werts für einen zweiseitigen Zweistichproben-T-Test wieder.
\item Von welchen Werten hängt die Powerfunktion eines zweiseitigen Zweistichproben-T-Tests ab?
\item Skizzieren Sie die Powerfunktion des zweiseitigen Zweistichproben-T-Tests bei fester Stichprobengröße.
\item Skizzieren Sie die Powerfunktion des zweiseitigen Zweistichproben-T-Tests bei festem Nichtzentralitätsparameter.
\item Betrachten Sie die Daten zum Alter der Patient:innen in der Face-to-Face und Online Therapie Bedingung im Beispieldatensatz. 
Erstellen gruppenspezifische Histogramme dieser Daten und evaluieren Sie gruppenspezifische deskriptive Statistiken zu diesen Daten. Führen Sie
einen zweiseitigen Zweistichproben-T-Test mit Nullhypothesenparameter $\mu_0 = 0$ durch. Dokumentieren Sie Ihre Ergebnisse.
Was folgern Sie aus den sich ergebenen Resultaten?
\end{enumerate}


# References
\footnotesize
